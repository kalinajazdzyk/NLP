{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "de66669d",
      "metadata": {
        "id": "de66669d"
      },
      "source": [
        "# KAIST AI605 Assignment 5: Language Modelling\n",
        "\n",
        "## Rubric\n",
        "\n",
        "### Deadline\n",
        "The deadline for this assignment is: Friday 2nd December 2022 (Week 14) 11:59pm\n",
        "\n",
        "### Submission\n",
        "Please submit your assignment via [KLMS](https://klms.kaist.ac.kr). You must submit both (1) a PDF of your solutions and (2) the Jupyter Notebook file (.ipynb).\n",
        "\n",
        "Use in-line LaTeX for mathematical expressions.\n",
        "\n",
        "### Collaboration\n",
        "This assignment is not a group assignment so make sure your answer and code are your own.\n",
        "\n",
        "### Grading\n",
        "The total number of marks avaiable is 30 points.\n",
        "\n",
        "### Environment\n",
        "This assignment will mostly use the transformers library from huggingface.\n",
        "\n",
        "The use of a GPU will be beneficial for this assignment.\n",
        "\n",
        "If you do not have a GPU on your laptop, it is acceptable to use [Google Colab (free)](https://colab.research.google.com) or the departmental subscription of [VESSL](https://vessl.ai),\n",
        "**please contact me ASAP to be added if you are from a different department**.\n",
        "\n",
        "\n",
        "The required environment for this is Python 3.9. Run the following cell to set up the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8d8ab12",
      "metadata": {
        "id": "c8d8ab12"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy torch tqdm transformers matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df37c986",
      "metadata": {
        "id": "df37c986"
      },
      "source": [
        "# Problem 0 - Load The Data\n",
        "The data for Problems 1, 2 and 3 can be downloaded from KLMS. Each line in the file is an instance is a JSON dictioanary of a Wikipedia. For this assignment only the **text** field is required.\n",
        "\n",
        "* Reserve 10% of the pages for validation data\n",
        "* Use any other portion of the data for training\n",
        "\n",
        "`{\"title\": \"the title of the Wikipedia page\",  \"text\":\"the text in the Wikipedia page\"}`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSlKnjuPKM5p",
        "outputId": "7884a699-65db-4301-bc92-2ee90b64d796"
      },
      "id": "LSlKnjuPKM5p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.7.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYbRfqjwJ7-y",
        "outputId": "da292a69-ab7a-4283-81b2-2795f10d0e7a"
      },
      "id": "nYbRfqjwJ7-y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94yDHrzQJ8FL",
        "outputId": "1bb7928d-da76-4136-d202-bf721751dced"
      },
      "id": "94yDHrzQJ8FL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.8/dist-packages (0.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1287085",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1287085",
        "outputId": "dfae8918-a0b0-4f80-d371-fa688f655136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5946ac2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5946ac2",
        "outputId": "aa5b7112-26c3-42ed-cae3-50250536b23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "from torch import nn\n",
        "import json\n",
        "from nltk import word_tokenize\n",
        "from collections import defaultdict, Counter\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "from datasets import *\n",
        "from transformers import *\n",
        "from tokenizers import *\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls 'drive/MyDrive/nlp'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HERfdShdrQ3",
        "outputId": "3ac55ac2-8ad2-4d52-dc1b-ed52b7bdfddd"
      },
      "id": "_HERfdShdrQ3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.json\tsnli_1.0_dev.jsonl   snli_1.0_train.jsonl  train.json\n",
            "model_small.pt\tsnli_1.0_test.jsonl  test.json\t\t   wiki.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR2hPP7Eeclq",
        "outputId": "62e76fe3-a187-4ed6-d517-b9373ac90567"
      },
      "id": "nR2hPP7Eeclq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "022a25c8",
      "metadata": {
        "id": "022a25c8"
      },
      "outputs": [],
      "source": [
        "def load_instances(filename):\n",
        "    with open(filename) as f:\n",
        "        for line in f:\n",
        "            inst = json.loads(line)\n",
        "            text = inst['text']\n",
        "            yield word_tokenize(text)\n",
        "all_inst = list(load_instances(\"drive/MyDrive/nlp/wiki.jsonl\"))\n",
        "# print(all_inst[0])\n",
        "n = len(all_inst)\n",
        "print(f'All data: {n}')\n",
        "train_instances, dev_instances = all_inst[:int(n*0.9)], all_inst[int(n*0.9):]\n",
        "print(f'Train lenght: {len(train_instances)}')\n",
        "print(f'Test lenght: {len(dev_instances)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "849714ef",
      "metadata": {
        "id": "849714ef"
      },
      "source": [
        "# Problem 1 - Features of Language (6 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fee757d1",
      "metadata": {
        "id": "fee757d1"
      },
      "source": [
        "## Problem 1.1 (4 points) - Zipfs Law\n",
        "\n",
        "Zipfs law (introduced in Lecture 1) indicates a reverse exponential relationship between the frequency of a token $w$, $f_w$, and its rank of frequency $r_w$ (where rank is the position with respect to frequency in comparison to other words).\n",
        "\n",
        "$$\n",
        "f_w \\approx \\frac{k}{r_w^\\alpha}\n",
        "$$\n",
        "\n",
        "\n",
        "* Find the frequencies of all unique tokens in the dataset and rank them\n",
        "\n",
        "* Plot the frequency vs rank graph for the highest 10,000 ranked tokens with a log-log scale\n",
        "\n",
        "* Plot a line of best fit and estimate the values of $k$ and $\\alpha$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311af4b9",
      "metadata": {
        "id": "311af4b9",
        "outputId": "d4e1395c-4f3d-4517-b19d-ca29a04996ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: ('the', 869431),\n",
              " 2: (',', 858193),\n",
              " 3: ('.', 574493),\n",
              " 4: ('of', 477376),\n",
              " 5: ('and', 423298),\n",
              " 6: ('in', 319390),\n",
              " 7: ('to', 307820),\n",
              " 8: ('a', 264721),\n",
              " 9: ('was', 154621),\n",
              " 10: ('The', 131163),\n",
              " 11: (\"'s\", 115968),\n",
              " 12: ('that', 114943),\n",
              " 13: ('as', 114408),\n",
              " 14: (')', 113762),\n",
              " 15: ('(', 113746),\n",
              " 16: ('for', 102230),\n",
              " 17: ('``', 99072),\n",
              " 18: ('by', 97725),\n",
              " 19: ('with', 96947),\n",
              " 20: ('on', 95504),\n",
              " 21: ('is', 94711),\n",
              " 22: (\"''\", 93799),\n",
              " 23: ('from', 74246),\n",
              " 24: ('his', 67246),\n",
              " 25: ('were', 61886),\n",
              " 26: ('at', 60693),\n",
              " 27: ('it', 54504),\n",
              " 28: ('which', 49433),\n",
              " 29: ('had', 49041),\n",
              " 30: ('an', 48956),\n",
              " 31: ('are', 48228),\n",
              " 32: ('he', 45792),\n",
              " 33: (';', 43640),\n",
              " 34: ('be', 41782),\n",
              " 35: ('In', 40613),\n",
              " 36: (':', 38625),\n",
              " 37: ('have', 38461),\n",
              " 38: ('or', 35965),\n",
              " 39: ('not', 35631),\n",
              " 40: ('but', 34690),\n",
              " 41: ('been', 33255),\n",
              " 42: ('its', 32761),\n",
              " 43: ('their', 32222),\n",
              " 44: ('her', 28214),\n",
              " 45: ('also', 27907),\n",
              " 46: ('has', 27283),\n",
              " 47: ('this', 25112),\n",
              " 48: ('first', 24762),\n",
              " 49: ('they', 23334),\n",
              " 50: ('who', 23275),\n",
              " 51: ('one', 23269),\n",
              " 52: ('other', 23219),\n",
              " 53: ('more', 21693),\n",
              " 54: ('two', 20449),\n",
              " 55: ('than', 19694),\n",
              " 56: ('would', 19469),\n",
              " 57: ('into', 18929),\n",
              " 58: ('It', 18420),\n",
              " 59: ('after', 18384),\n",
              " 60: ('He', 17437),\n",
              " 61: ('A', 17055),\n",
              " 62: ('most', 16976),\n",
              " 63: ('such', 16863),\n",
              " 64: ('about', 16772),\n",
              " 65: ('time', 16105),\n",
              " 66: ('species', 15804),\n",
              " 67: ('when', 15734),\n",
              " 68: ('only', 15210),\n",
              " 69: ('between', 15120),\n",
              " 70: ('years', 14725),\n",
              " 71: ('she', 14533),\n",
              " 72: ('some', 14405),\n",
              " 73: ('all', 14327),\n",
              " 74: ('during', 13924),\n",
              " 75: ('used', 13814),\n",
              " 76: (\"'\", 13620),\n",
              " 77: ('I', 13517),\n",
              " 78: ('over', 13378),\n",
              " 79: ('him', 13298),\n",
              " 80: ('found', 13166),\n",
              " 81: ('later', 13126),\n",
              " 82: ('can', 12682),\n",
              " 83: ('may', 12641),\n",
              " 84: ('film', 12617),\n",
              " 85: ('new', 12399),\n",
              " 86: ('This', 12368),\n",
              " 87: ('while', 12129),\n",
              " 88: ('including', 12019),\n",
              " 89: ('work', 11912),\n",
              " 90: ('them', 11784),\n",
              " 91: ('New', 11674),\n",
              " 92: ('known', 11659),\n",
              " 93: ('made', 11648),\n",
              " 94: ('many', 11610),\n",
              " 95: ('there', 10987),\n",
              " 96: ('up', 10902),\n",
              " 97: ('where', 10768),\n",
              " 98: ('three', 10720),\n",
              " 99: ('no', 10702),\n",
              " 100: ('became', 10641),\n",
              " 101: ('these', 10610),\n",
              " 102: ('early', 10104),\n",
              " 103: ('both', 9977),\n",
              " 104: ('out', 9965),\n",
              " 105: ('could', 9769),\n",
              " 106: ('before', 9596),\n",
              " 107: ('being', 9558),\n",
              " 108: ('several', 9510),\n",
              " 109: ('through', 9306),\n",
              " 110: ('part', 9208),\n",
              " 111: ('did', 9096),\n",
              " 112: ('year', 9084),\n",
              " 113: ('large', 8845),\n",
              " 114: ('so', 8667),\n",
              " 115: ('well', 8544),\n",
              " 116: ('American', 8513),\n",
              " 117: ('then', 8499),\n",
              " 118: ('people', 8446),\n",
              " 119: ('United', 8300),\n",
              " 120: ('$', 7994),\n",
              " 121: ('began', 7844),\n",
              " 122: ('around', 7780),\n",
              " 123: ('use', 7756),\n",
              " 124: ('music', 7737),\n",
              " 125: ('because', 7692),\n",
              " 126: ('until', 7691),\n",
              " 127: ('million', 7687),\n",
              " 128: ('described', 7589),\n",
              " 129: ('wrote', 7571),\n",
              " 130: ('called', 7527),\n",
              " 131: ('under', 7522),\n",
              " 132: ('They', 7518),\n",
              " 133: ('century', 7502),\n",
              " 134: ('%', 7484),\n",
              " 135: ('same', 7449),\n",
              " 136: ('name', 7321),\n",
              " 137: ('John', 7274),\n",
              " 138: ('number', 7235),\n",
              " 139: ('On', 7196),\n",
              " 140: ('said', 7072),\n",
              " 141: ('those', 7005),\n",
              " 142: ('often', 6964),\n",
              " 143: ('area', 6944),\n",
              " 144: ('series', 6937),\n",
              " 145: ('small', 6915),\n",
              " 146: ('As', 6898),\n",
              " 147: (']', 6859),\n",
              " 148: ('[', 6857),\n",
              " 149: ('much', 6837),\n",
              " 150: ('any', 6823),\n",
              " 151: ('each', 6818),\n",
              " 152: ('family', 6817),\n",
              " 153: ('States', 6813),\n",
              " 154: ('long', 6661),\n",
              " 155: ('ISBN', 6633),\n",
              " 156: ('British', 6504),\n",
              " 157: ('–', 6499),\n",
              " 158: ('After', 6463),\n",
              " 159: ('published', 6455),\n",
              " 160: ('album', 6453),\n",
              " 161: ('London', 6266),\n",
              " 162: ('since', 6261),\n",
              " 163: ('...', 6229),\n",
              " 164: ('water', 6211),\n",
              " 165: ('group', 6192),\n",
              " 166: ('second', 6169),\n",
              " 167: ('although', 6157),\n",
              " 168: ('four', 6135),\n",
              " 169: ('life', 6114),\n",
              " 170: ('York', 6058),\n",
              " 171: ('She', 5937),\n",
              " 172: ('National', 5852),\n",
              " 173: ('like', 5842),\n",
              " 174: ('what', 5780),\n",
              " 175: ('high', 5761),\n",
              " 176: ('considered', 5760),\n",
              " 177: ('city', 5757),\n",
              " 178: ('September', 5747),\n",
              " 179: ('own', 5740),\n",
              " 180: ('death', 5736),\n",
              " 181: ('along', 5727),\n",
              " 182: ('within', 5681),\n",
              " 183: ('end', 5678),\n",
              " 184: ('if', 5646),\n",
              " 185: ('very', 5586),\n",
              " 186: ('m', 5569),\n",
              " 187: ('book', 5554),\n",
              " 188: ('University', 5533),\n",
              " 189: ('included', 5528),\n",
              " 190: ('against', 5513),\n",
              " 191: ('government', 5482),\n",
              " 192: ('state', 5462),\n",
              " 193: ('form', 5415),\n",
              " 194: ('near', 5377),\n",
              " 195: ('1', 5360),\n",
              " 196: ('now', 5355),\n",
              " 197: ('left', 5330),\n",
              " 198: ('due', 5328),\n",
              " 199: ('works', 5315),\n",
              " 200: ('took', 5300),\n",
              " 201: ('similar', 5286),\n",
              " 202: ('public', 5259),\n",
              " 203: ('following', 5253),\n",
              " 204: ('day', 5174),\n",
              " 205: ('common', 5166),\n",
              " 206: ('released', 5113),\n",
              " 207: ('based', 5088),\n",
              " 208: ('At', 5066),\n",
              " 209: ('period', 5049),\n",
              " 210: ('include', 5049),\n",
              " 211: ('late', 5027),\n",
              " 212: ('original', 5019),\n",
              " 213: ('do', 5013),\n",
              " 214: ('another', 5006),\n",
              " 215: ('October', 5002),\n",
              " 216: ('South', 4975),\n",
              " 217: ('among', 4971),\n",
              " 218: ('received', 4970),\n",
              " 219: ('set', 4969),\n",
              " 220: ('back', 4926),\n",
              " 221: ('North', 4889),\n",
              " 222: ('August', 4878),\n",
              " 223: ('even', 4864),\n",
              " 224: ('However', 4848),\n",
              " 225: ('few', 4834),\n",
              " 226: ('though', 4833),\n",
              " 227: ('band', 4809),\n",
              " 228: ('will', 4797),\n",
              " 229: ('These', 4782),\n",
              " 230: ('Although', 4781),\n",
              " 231: ('storm', 4766),\n",
              " 232: ('still', 4757),\n",
              " 233: ('When', 4742),\n",
              " 234: ('major', 4705),\n",
              " 235: ('named', 4702),\n",
              " 236: ('less', 4691),\n",
              " 237: ('May', 4673),\n",
              " 238: ('His', 4671),\n",
              " 239: ('show', 4658),\n",
              " 240: ('ft', 4617),\n",
              " 241: ('English', 4612),\n",
              " 242: ('days', 4603),\n",
              " 243: ('led', 4588),\n",
              " 244: ('de', 4581),\n",
              " 245: ('production', 4579),\n",
              " 246: ('role', 4576),\n",
              " 247: ('There', 4553),\n",
              " 248: ('last', 4482),\n",
              " 249: ('June', 4477),\n",
              " 250: ('system', 4474),\n",
              " 251: ('further', 4472),\n",
              " 252: ('produced', 4466),\n",
              " 253: ('areas', 4457),\n",
              " 254: ('July', 4447),\n",
              " 255: ('members', 4447),\n",
              " 256: ('different', 4424),\n",
              " 257: ('January', 4423),\n",
              " 258: ('local', 4405),\n",
              " 259: ('continued', 4399),\n",
              " 260: ('By', 4378),\n",
              " 261: ('William', 4366),\n",
              " 262: ('World', 4348),\n",
              " 263: ('2', 4342),\n",
              " 264: ('November', 4335),\n",
              " 265: ('population', 4332),\n",
              " 266: ('without', 4326),\n",
              " 267: ('March', 4311),\n",
              " 268: ('world', 4291),\n",
              " 269: ('become', 4273),\n",
              " 270: ('War', 4272),\n",
              " 271: ('recorded', 4247),\n",
              " 272: ('five', 4213),\n",
              " 273: ('building', 4195),\n",
              " 274: ('December', 4194),\n",
              " 275: ('down', 4184),\n",
              " 276: ('make', 4147),\n",
              " 277: ('French', 4143),\n",
              " 278: ('children', 4099),\n",
              " 279: ('body', 4076),\n",
              " 280: ('place', 4073),\n",
              " 281: ('April', 4053),\n",
              " 282: ('study', 4047),\n",
              " 283: ('given', 4035),\n",
              " 284: ('moved', 4020),\n",
              " 285: ('&', 4001),\n",
              " 286: ('white', 3996),\n",
              " 287: ('birds', 3967),\n",
              " 288: ('land', 3955),\n",
              " 289: ('During', 3918),\n",
              " 290: ('thought', 3884),\n",
              " 291: ('built', 3875),\n",
              " 292: ('died', 3873),\n",
              " 293: ('home', 3872),\n",
              " 294: ('house', 3870),\n",
              " 295: ('For', 3864),\n",
              " 296: ('reported', 3858),\n",
              " 297: ('Park', 3856),\n",
              " 298: ('young', 3854),\n",
              " 299: ('range', 3837),\n",
              " 300: ('River', 3836),\n",
              " 301: ('written', 3830),\n",
              " 302: ('km', 3820),\n",
              " 303: ('having', 3795),\n",
              " 304: ('single', 3793),\n",
              " 305: ('character', 3792),\n",
              " 306: ('just', 3790),\n",
              " 307: ('3', 3784),\n",
              " 308: ('England', 3775),\n",
              " 309: ('next', 3739),\n",
              " 310: ('design', 3728),\n",
              " 311: ('short', 3727),\n",
              " 312: ('using', 3722),\n",
              " 313: ('seen', 3721),\n",
              " 314: ('story', 3717),\n",
              " 315: ('held', 3714),\n",
              " 316: ('power', 3706),\n",
              " 317: ('10', 3700),\n",
              " 318: ('February', 3692),\n",
              " 319: ('across', 3684),\n",
              " 320: ('off', 3659),\n",
              " 321: ('age', 3653),\n",
              " 322: ('men', 3643),\n",
              " 323: ('history', 3636),\n",
              " 324: ('black', 3633),\n",
              " 325: ('way', 3632),\n",
              " 326: ('America', 3602),\n",
              " 327: ('never', 3602),\n",
              " 328: ('south', 3590),\n",
              " 329: ('least', 3569),\n",
              " 330: ('rather', 3566),\n",
              " 331: ('north', 3562),\n",
              " 332: ('site', 3544),\n",
              " 333: ('little', 3544),\n",
              " 334: ('women', 3542),\n",
              " 335: ('Press', 3537),\n",
              " 336: ('again', 3531),\n",
              " 337: ('head', 3531),\n",
              " 338: ('side', 3517),\n",
              " 339: ('US', 3508),\n",
              " 340: ('important', 3501),\n",
              " 341: ('main', 3499),\n",
              " 342: ('modern', 3495),\n",
              " 343: ('developed', 3489),\n",
              " 344: ('caused', 3484),\n",
              " 345: ('came', 3476),\n",
              " 346: ('months', 3472),\n",
              " 347: ('One', 3461),\n",
              " 348: ('According', 3435),\n",
              " 349: ('school', 3429),\n",
              " 350: ('great', 3423),\n",
              " 351: ('country', 3422),\n",
              " 352: ('writing', 3422),\n",
              " 353: ('region', 3417),\n",
              " 354: ('lower', 3415),\n",
              " 355: ('feet', 3413),\n",
              " 356: ('20', 3408),\n",
              " 357: ('played', 3406),\n",
              " 358: ('half', 3403),\n",
              " 359: ('style', 3367),\n",
              " 360: ('six', 3346),\n",
              " 361: ('war', 3340),\n",
              " 362: ('suggested', 3332),\n",
              " 363: ('example', 3330),\n",
              " 364: ('King', 3323),\n",
              " 365: ('genus', 3321),\n",
              " 366: ('appeared', 3320),\n",
              " 367: ('James', 3319),\n",
              " 368: ('evidence', 3304),\n",
              " 369: ('others', 3285),\n",
              " 370: ('George', 3273),\n",
              " 371: ('take', 3267),\n",
              " 372: ('support', 3262),\n",
              " 373: ('per', 3259),\n",
              " 374: ('should', 3248),\n",
              " 375: ('throughout', 3244),\n",
              " 376: ('popular', 3235),\n",
              " 377: ('size', 3226),\n",
              " 378: ('remained', 3224),\n",
              " 379: ('generally', 3221),\n",
              " 380: ('5', 3220),\n",
              " 381: ('Some', 3217),\n",
              " 382: ('food', 3213),\n",
              " 383: ('political', 3205),\n",
              " 384: ('season', 3203),\n",
              " 385: ('how', 3200),\n",
              " 386: ('formed', 3163),\n",
              " 387: ('4', 3159),\n",
              " 388: ('making', 3154),\n",
              " 389: ('himself', 3149),\n",
              " 390: ('result', 3128),\n",
              " 391: ('usually', 3120),\n",
              " 392: ('you', 3116),\n",
              " 393: ('tropical', 3111),\n",
              " 394: ('times', 3093),\n",
              " 395: ('former', 3091),\n",
              " 396: ('song', 3091),\n",
              " 397: ('30', 3087),\n",
              " 398: ('various', 3087),\n",
              " 399: ('however', 3085),\n",
              " 400: ('larger', 3078),\n",
              " 401: ('almost', 3076),\n",
              " 402: ('II', 3074),\n",
              " 403: ('created', 3073),\n",
              " 404: ('gave', 3069),\n",
              " 405: ('female', 3066),\n",
              " 406: ('play', 3064),\n",
              " 407: (\"n't\", 3056),\n",
              " 408: ('performance', 3054),\n",
              " 409: ('followed', 3053),\n",
              " 410: ('man', 3046),\n",
              " 411: ('record', 3043),\n",
              " 412: ('island', 3039),\n",
              " 413: ('noted', 3033),\n",
              " 414: ('novel', 3033),\n",
              " 415: ('House', 3029),\n",
              " 416: ('low', 3026),\n",
              " 417: ('established', 3025),\n",
              " 418: ('German', 3023),\n",
              " 419: ('old', 3017),\n",
              " 420: ('point', 3013),\n",
              " 421: ('father', 3007),\n",
              " 422: ('Europe', 2998),\n",
              " 423: ('third', 2995),\n",
              " 424: ('15', 2993),\n",
              " 425: ('Australia', 2990),\n",
              " 426: ('returned', 2987),\n",
              " 427: ('above', 2977),\n",
              " 428: ('particularly', 2968),\n",
              " 429: ('southern', 2965),\n",
              " 430: ('taken', 2963),\n",
              " 431: ('case', 2959),\n",
              " 432: ('final', 2958),\n",
              " 433: ('David', 2952),\n",
              " 434: ('too', 2946),\n",
              " 435: ('City', 2945),\n",
              " 436: ('we', 2929),\n",
              " 437: ('present', 2919),\n",
              " 438: ('sometimes', 2914),\n",
              " 439: ('material', 2905),\n",
              " 440: ('damage', 2903),\n",
              " 441: ('While', 2900),\n",
              " 442: ('cm', 2895),\n",
              " 443: ('success', 2892),\n",
              " 444: ('likely', 2879),\n",
              " 445: ('hurricane', 2877),\n",
              " 446: ('development', 2876),\n",
              " 447: ('stated', 2872),\n",
              " 448: ('art', 2866),\n",
              " 449: ('northern', 2861),\n",
              " 450: ('believed', 2856),\n",
              " 451: ('release', 2851),\n",
              " 452: ('either', 2845),\n",
              " 453: ('Robert', 2833),\n",
              " 454: ('miles', 2824),\n",
              " 455: ('sea', 2822),\n",
              " 456: ('sold', 2803),\n",
              " 457: ('earlier', 2795),\n",
              " 458: ('park', 2787),\n",
              " 459: ('groups', 2783),\n",
              " 460: ('U.S.', 2780),\n",
              " 461: ('songs', 2778),\n",
              " 462: ('company', 2776),\n",
              " 463: ('Thomas', 2775),\n",
              " 464: ('central', 2774),\n",
              " 465: ('probably', 2773),\n",
              " 466: ('12', 2770),\n",
              " 467: ('placed', 2767),\n",
              " 468: ('together', 2766),\n",
              " 469: ('away', 2763),\n",
              " 470: ('An', 2762),\n",
              " 471: ('son', 2758),\n",
              " 472: ('went', 2753),\n",
              " 473: ('instead', 2751),\n",
              " 474: ('coins', 2748),\n",
              " 475: ('West', 2738),\n",
              " 476: ('Charles', 2735),\n",
              " 477: ('sent', 2725),\n",
              " 478: ('best', 2710),\n",
              " 479: ('human', 2700),\n",
              " 480: ('largest', 2699),\n",
              " 481: ('100', 2698),\n",
              " 482: ('does', 2696),\n",
              " 483: ('parts', 2694),\n",
              " 484: ('reached', 2692),\n",
              " 485: ('close', 2686),\n",
              " 486: ('brought', 2684),\n",
              " 487: ('Island', 2680),\n",
              " 488: ('stage', 2680),\n",
              " 489: ('mm', 2655),\n",
              " 490: ('mi', 2649),\n",
              " 491: ('Other', 2635),\n",
              " 492: ('estimated', 2634),\n",
              " 493: ('once', 2629),\n",
              " 494: ('animals', 2620),\n",
              " 495: ('process', 2618),\n",
              " 496: ('order', 2608),\n",
              " 497: ('live', 2606),\n",
              " 498: ('able', 2604),\n",
              " 499: ('control', 2602),\n",
              " 500: ('possible', 2589),\n",
              " 501: ('remains', 2584),\n",
              " 502: ('west', 2579),\n",
              " 503: ('military', 2579),\n",
              " 504: ('increased', 2579),\n",
              " 505: ('male', 2568),\n",
              " 506: ('surface', 2566),\n",
              " 507: ('town', 2563),\n",
              " 508: ('television', 2554),\n",
              " 509: ('lost', 2552),\n",
              " 510: ('open', 2547),\n",
              " 511: ('2007', 2547),\n",
              " 512: ('right', 2546),\n",
              " 513: ('significant', 2543),\n",
              " 514: ('social', 2542),\n",
              " 515: ('musical', 2541),\n",
              " 516: ('east', 2540),\n",
              " 517: ('issue', 2522),\n",
              " 518: ('return', 2518),\n",
              " 519: ('especially', 2513),\n",
              " 520: ('national', 2511),\n",
              " 521: ('worked', 2509),\n",
              " 522: ('features', 2503),\n",
              " 523: ('provided', 2500),\n",
              " 524: ('western', 2497),\n",
              " 525: ('wife', 2493),\n",
              " 526: ('6', 2492),\n",
              " 527: ('far', 2485),\n",
              " 528: ('position', 2480),\n",
              " 529: ('project', 2477),\n",
              " 530: ('eastern', 2476),\n",
              " 531: ('related', 2475),\n",
              " 532: ('smaller', 2472),\n",
              " 533: ('2006', 2470),\n",
              " 534: ('might', 2470),\n",
              " 535: ('court', 2466),\n",
              " 536: ('whose', 2465),\n",
              " 537: ('performed', 2465),\n",
              " 538: ('winds', 2460),\n",
              " 539: ('Royal', 2454),\n",
              " 540: ('films', 2454),\n",
              " 541: ('mother', 2453),\n",
              " 542: ('version', 2452),\n",
              " 543: ('characters', 2448),\n",
              " 544: ('good', 2444),\n",
              " 545: ('total', 2437),\n",
              " 546: ('natural', 2437),\n",
              " 547: ('discovered', 2436),\n",
              " 548: ('required', 2429),\n",
              " 549: ('Street', 2426),\n",
              " 550: ('bird', 2426),\n",
              " 551: ('11', 2417),\n",
              " 552: ('front', 2417),\n",
              " 553: ('breeding', 2417),\n",
              " 554: ('every', 2411),\n",
              " 555: ('career', 2411),\n",
              " 556: ('2008', 2410),\n",
              " 557: ('Mint', 2406),\n",
              " 558: ('strong', 2404),\n",
              " 559: ('Henry', 2404),\n",
              " 560: ('Richard', 2399),\n",
              " 561: ('India', 2399),\n",
              " 562: ('my', 2395),\n",
              " 563: ('Its', 2391),\n",
              " 564: ('lead', 2389),\n",
              " 565: ('B.', 2383),\n",
              " 566: ('elements', 2378),\n",
              " 567: ('European', 2374),\n",
              " 568: ('general', 2371),\n",
              " 569: ('living', 2370),\n",
              " 570: ('red', 2365),\n",
              " 571: ('change', 2365),\n",
              " 572: ('ground', 2364),\n",
              " 573: ('To', 2358),\n",
              " 574: ('25', 2355),\n",
              " 575: ('length', 2352),\n",
              " 576: ('structure', 2350),\n",
              " 577: ('State', 2347),\n",
              " 578: ('magazine', 2340),\n",
              " 579: ('proposed', 2339),\n",
              " 580: ('leading', 2333),\n",
              " 581: ('allowed', 2332),\n",
              " 582: ('killed', 2327),\n",
              " 583: ('C.', 2325),\n",
              " 584: ('Mary', 2323),\n",
              " 585: ('member', 2320),\n",
              " 586: ('2009', 2315),\n",
              " 587: ('addition', 2310),\n",
              " 588: ('16', 2305),\n",
              " 589: ('upon', 2301),\n",
              " 590: ('upper', 2292),\n",
              " 591: ('interest', 2292),\n",
              " 592: ('wide', 2288),\n",
              " 593: ('2005', 2288),\n",
              " 594: ('13', 2284),\n",
              " 595: ('8', 2284),\n",
              " 596: ('A.', 2283),\n",
              " 597: ('working', 2279),\n",
              " 598: ('Indian', 2278),\n",
              " 599: ('2010', 2273),\n",
              " 600: ('longer', 2271),\n",
              " 601: ('eventually', 2265),\n",
              " 602: ('saw', 2265),\n",
              " 603: ('according', 2257),\n",
              " 604: ('Museum', 2247),\n",
              " 605: ('introduced', 2242),\n",
              " 606: ('average', 2242),\n",
              " 607: ('rock', 2241),\n",
              " 608: ('influence', 2240),\n",
              " 609: ('appear', 2239),\n",
              " 610: ('met', 2238),\n",
              " 611: ('soon', 2234),\n",
              " 612: ('towards', 2234),\n",
              " 613: ('Australian', 2227),\n",
              " 614: ('With', 2224),\n",
              " 615: ('felt', 2223),\n",
              " 616: ('line', 2219),\n",
              " 617: ('located', 2205),\n",
              " 618: ('Canada', 2205),\n",
              " 619: ('stories', 2202),\n",
              " 620: ('relationship', 2190),\n",
              " 621: ('Washington', 2189),\n",
              " 622: ('construction', 2187),\n",
              " 623: ('law', 2186),\n",
              " 624: ('Times', 2185),\n",
              " 625: ('18', 2182),\n",
              " 626: ('complete', 2176),\n",
              " 627: ('states', 2171),\n",
              " 628: ('Society', 2169),\n",
              " 629: ('books', 2169),\n",
              " 630: ('M.', 2168),\n",
              " 631: ('!', 2164),\n",
              " 632: ('California', 2157),\n",
              " 633: ('light', 2152),\n",
              " 634: ('All', 2152),\n",
              " 635: ('trees', 2152),\n",
              " 636: ('7', 2151),\n",
              " 637: ('born', 2146),\n",
              " 638: ('14', 2145),\n",
              " 639: ('coin', 2143),\n",
              " 640: ('movement', 2140),\n",
              " 641: ('help', 2138),\n",
              " 642: ('hours', 2137),\n",
              " 643: ('whom', 2133),\n",
              " 644: ('research', 2133),\n",
              " 645: ('Britain', 2131),\n",
              " 646: ('coast', 2121),\n",
              " 647: ('see', 2118),\n",
              " 648: ('numbers', 2114),\n",
              " 649: ('initially', 2111),\n",
              " 650: ('top', 2109),\n",
              " 651: ('associated', 2104),\n",
              " 652: ('latter', 2104),\n",
              " 653: ('2011', 2101),\n",
              " 654: ('opened', 2099),\n",
              " 655: ('East', 2099),\n",
              " 656: ('involved', 2097),\n",
              " 657: ('told', 2095),\n",
              " 658: ('level', 2081),\n",
              " 659: ('lived', 2080),\n",
              " 660: ('Western', 2079),\n",
              " 661: ('County', 2078),\n",
              " 662: ('Great', 2077),\n",
              " 663: ('church', 2076),\n",
              " 664: ('available', 2075),\n",
              " 665: ('tour', 2074),\n",
              " 666: ('higher', 2072),\n",
              " 667: ('director', 2071),\n",
              " 668: ('enough', 2068),\n",
              " 669: ('buildings', 2067),\n",
              " 670: ('Many', 2059),\n",
              " 671: ('shows', 2058),\n",
              " 672: ('decided', 2052),\n",
              " 673: ('lack', 2052),\n",
              " 674: ('originally', 2049),\n",
              " 675: ('successful', 2049),\n",
              " 676: ('added', 2043),\n",
              " 677: ('effects', 2043),\n",
              " 678: ('outside', 2037),\n",
              " 679: ('completed', 2036),\n",
              " 680: ('critics', 2034),\n",
              " 681: ('served', 2033),\n",
              " 682: ('asked', 2033),\n",
              " 683: ('No', 2031),\n",
              " 684: ('Court', 2030),\n",
              " 685: ('passed', 2029),\n",
              " 686: ('previous', 2027),\n",
              " 687: ('2012', 2026),\n",
              " 688: ('Hall', 2022),\n",
              " 689: ('view', 2020),\n",
              " 690: ('Best', 2020),\n",
              " 691: ('weeks', 2020),\n",
              " 692: ('50', 2016),\n",
              " 693: ('events', 2013),\n",
              " 694: ('complex', 2010),\n",
              " 695: ('mostly', 2007),\n",
              " 696: ('designed', 2006),\n",
              " 697: ('P.', 2004),\n",
              " 698: ('struck', 2004),\n",
              " 699: ('heavy', 2003),\n",
              " 700: ('plant', 2002),\n",
              " 701: ('pieces', 2000),\n",
              " 702: ('appearance', 1999),\n",
              " 703: ('percent', 1996),\n",
              " 704: ('full', 1996),\n",
              " 705: ('School', 1994),\n",
              " 706: ('Most', 1993),\n",
              " 707: ('animal', 1991),\n",
              " 708: ('type', 1984),\n",
              " 709: ('specimen', 1984),\n",
              " 710: ('forms', 1983),\n",
              " 711: ('title', 1982),\n",
              " 712: ('fire', 1976),\n",
              " 713: ('changes', 1974),\n",
              " 714: ('Paul', 1967),\n",
              " 715: ('Despite', 1965),\n",
              " 716: ('km/h', 1965),\n",
              " 717: ('base', 1963),\n",
              " 718: ('Africa', 1955),\n",
              " 719: ('cause', 1949),\n",
              " 720: ('air', 1949),\n",
              " 721: ('Lake', 1948),\n",
              " 722: ('whether', 1946),\n",
              " 723: ('studies', 1946),\n",
              " 724: ('France', 1945),\n",
              " 725: ('produce', 1945),\n",
              " 726: ('specimens', 1943),\n",
              " 727: ('bill', 1941),\n",
              " 728: ('put', 1941),\n",
              " 729: ('party', 1941),\n",
              " 730: ('opera', 1940),\n",
              " 731: ('2004', 1937),\n",
              " 732: ('piece', 1935),\n",
              " 733: ('language', 1934),\n",
              " 734: ('rest', 1933),\n",
              " 735: ('spent', 1929),\n",
              " 736: ('compared', 1928),\n",
              " 737: ('teeth', 1925),\n",
              " 738: ('nearly', 1923),\n",
              " 739: ('wanted', 1920),\n",
              " 740: ('find', 1917),\n",
              " 741: ('2013', 1915),\n",
              " 742: ('Act', 1912),\n",
              " 743: ('History', 1912),\n",
              " 744: ('silver', 1912),\n",
              " 745: ('highly', 1910),\n",
              " 746: ('itself', 1908),\n",
              " 747: ('police', 1908),\n",
              " 748: ('replaced', 1906),\n",
              " 749: ('occurred', 1906),\n",
              " 750: ('seven', 1905),\n",
              " 751: ('ever', 1904),\n",
              " 752: ('status', 1901),\n",
              " 753: ('official', 1898),\n",
              " 754: ('studio', 1895),\n",
              " 755: ('me', 1893),\n",
              " 756: ('gold', 1890),\n",
              " 757: ('scene', 1890),\n",
              " 758: ('effect', 1889),\n",
              " 759: ('tail', 1889),\n",
              " 760: ('issued', 1888),\n",
              " 761: ('mph', 1888),\n",
              " 762: ('featured', 1887),\n",
              " 763: ('must', 1886),\n",
              " 764: ('announced', 1881),\n",
              " 765: ('Creek', 1879),\n",
              " 766: ('Chinese', 1878),\n",
              " 767: ('woman', 1876),\n",
              " 768: ('collection', 1875),\n",
              " 769: ('From', 1872),\n",
              " 770: ('identified', 1867),\n",
              " 771: ('nature', 1865),\n",
              " 772: ('summer', 1865),\n",
              " 773: ('won', 1863),\n",
              " 774: ('letter', 1859),\n",
              " 775: ('field', 1851),\n",
              " 776: ('friend', 1851),\n",
              " 777: ('ago', 1851),\n",
              " 778: ('quickly', 1850),\n",
              " 779: ('office', 1849),\n",
              " 780: ('ten', 1849),\n",
              " 781: ('relatively', 1843),\n",
              " 782: ('turned', 1842),\n",
              " 783: ('provide', 1840),\n",
              " 784: ('Two', 1839),\n",
              " 785: ('International', 1839),\n",
              " 786: ('money', 1838),\n",
              " 787: ('Award', 1838),\n",
              " 788: ('artist', 1836),\n",
              " 789: ('previously', 1836),\n",
              " 790: ('Edward', 1834),\n",
              " 791: ('Company', 1832),\n",
              " 792: ('eight', 1828),\n",
              " 793: ('report', 1826),\n",
              " 794: ('difficult', 1826),\n",
              " 795: ('Music', 1826),\n",
              " 796: ('writer', 1825),\n",
              " 797: ('S.', 1822),\n",
              " 798: ('24', 1821),\n",
              " 799: ('Her', 1821),\n",
              " 800: ('Roman', 1820),\n",
              " 801: ('service', 1817),\n",
              " 802: ('better', 1817),\n",
              " 803: ('Union', 1815),\n",
              " 804: ('includes', 1814),\n",
              " 805: ('agreed', 1813),\n",
              " 806: ('beginning', 1813),\n",
              " 807: ('metal', 1810),\n",
              " 808: ('9', 1809),\n",
              " 809: ('mainly', 1807),\n",
              " 810: ('plants', 1807),\n",
              " 811: ('limited', 1806),\n",
              " 812: ('populations', 1805),\n",
              " 813: ('idea', 1804),\n",
              " 814: ('already', 1798),\n",
              " 815: ('below', 1796),\n",
              " 816: ('individuals', 1795),\n",
              " 817: ('President', 1794),\n",
              " 818: ('UK', 1792),\n",
              " 819: ('space', 1788),\n",
              " 820: ('skull', 1788),\n",
              " 821: ('subspecies', 1787),\n",
              " 822: ('contains', 1785),\n",
              " 823: ('2003', 1784),\n",
              " 824: ('?', 1784),\n",
              " 825: ('largely', 1780),\n",
              " 826: ('showed', 1780),\n",
              " 827: ('2014', 1778),\n",
              " 828: ('Congress', 1772),\n",
              " 829: ('Spanish', 1772),\n",
              " 830: ('San', 1772),\n",
              " 831: ('historian', 1771),\n",
              " 832: ('run', 1769),\n",
              " 833: ('subject', 1769),\n",
              " 834: ('activity', 1769),\n",
              " 835: ('17', 1768),\n",
              " 836: ('rights', 1767),\n",
              " 837: ('students', 1760),\n",
              " 838: ('observed', 1755),\n",
              " 839: ('love', 1754),\n",
              " 840: ('covered', 1752),\n",
              " 841: ('cast', 1752),\n",
              " 842: ('tree', 1750),\n",
              " 843: ('response', 1749),\n",
              " 844: ('ship', 1746),\n",
              " 845: ('Michael', 1745),\n",
              " 846: ('destroyed', 1743),\n",
              " 847: ('themselves', 1743),\n",
              " 848: ('date', 1742),\n",
              " 849: ('night', 1741),\n",
              " 850: ('act', 1741),\n",
              " 851: ('Church', 1740),\n",
              " 852: ('Sir', 1739),\n",
              " 853: ('particular', 1734),\n",
              " 854: ('shown', 1731),\n",
              " 855: ('individual', 1731),\n",
              " 856: ('typically', 1731),\n",
              " 857: ('2015', 1729),\n",
              " 858: ('Johnson', 1729),\n",
              " 859: ('separate', 1728),\n",
              " 860: ('come', 1728),\n",
              " 861: ('Greek', 1725),\n",
              " 862: ('thus', 1725),\n",
              " 863: ('prey', 1725),\n",
              " 864: ('names', 1722),\n",
              " 865: ('intended', 1719),\n",
              " 866: ('2000', 1717),\n",
              " 867: ('Pacific', 1717),\n",
              " 868: ('variety', 1716),\n",
              " 869: ('claimed', 1715),\n",
              " 870: ('2001', 1714),\n",
              " 871: ('increase', 1713),\n",
              " 872: ('suggests', 1713),\n",
              " 873: ('painting', 1712),\n",
              " 874: ('presence', 1710),\n",
              " 875: ('conditions', 1710),\n",
              " 876: ('appears', 1709),\n",
              " 877: ('private', 1706),\n",
              " 878: ('river', 1704),\n",
              " 879: ('behind', 1703),\n",
              " 880: ('issues', 1701),\n",
              " 881: ('joined', 1698),\n",
              " 882: ('composer', 1696),\n",
              " 883: ('widely', 1695),\n",
              " 884: ('Peter', 1688),\n",
              " 885: ('forest', 1688),\n",
              " 886: ('cells', 1684),\n",
              " 887: ('Mexico', 1680),\n",
              " 888: ('2016', 1679),\n",
              " 889: ('traditional', 1679),\n",
              " 890: ('started', 1678),\n",
              " 891: ('St', 1673),\n",
              " 892: ('ice', 1670),\n",
              " 893: ('referred', 1664),\n",
              " 894: ('Germany', 1661),\n",
              " 895: ('despite', 1660),\n",
              " 896: ('fish', 1658),\n",
              " 897: ('First', 1655),\n",
              " 898: ('king', 1655),\n",
              " 899: ('trade', 1655),\n",
              " 900: ('changed', 1653),\n",
              " 901: ('bones', 1652),\n",
              " 902: ('yet', 1651),\n",
              " 903: ('give', 1650),\n",
              " 904: ('words', 1647),\n",
              " 905: ('face', 1646),\n",
              " 906: ('supported', 1646),\n",
              " 907: ('stone', 1646),\n",
              " 908: ('source', 1643),\n",
              " 909: ('Paris', 1640),\n",
              " 910: ('Florida', 1638),\n",
              " 911: ('married', 1637),\n",
              " 912: ('blood', 1637),\n",
              " 913: ('males', 1634),\n",
              " 914: ('event', 1632),\n",
              " 915: ('closely', 1632),\n",
              " 916: ('cover', 1632),\n",
              " 917: ('nest', 1630),\n",
              " 918: ('greater', 1628),\n",
              " 919: ('entire', 1617),\n",
              " 920: ('list', 1617),\n",
              " 921: ('21', 1614),\n",
              " 922: ('E.', 1610),\n",
              " 923: ('daughter', 1610),\n",
              " 924: ('approximately', 1609),\n",
              " 925: ('personal', 1606),\n",
              " 926: ('special', 1605),\n",
              " 927: ('team', 1604),\n",
              " 928: ('cases', 1603),\n",
              " 929: ('Oxford', 1603),\n",
              " 930: ('accepted', 1600),\n",
              " 931: ('action', 1597),\n",
              " 932: ('crew', 1596),\n",
              " 933: ('room', 1595),\n",
              " 934: ('raised', 1594),\n",
              " 935: ('eggs', 1594),\n",
              " 936: ('our', 1592),\n",
              " 937: ('sound', 1591),\n",
              " 938: ('China', 1589),\n",
              " 939: ('attempt', 1588),\n",
              " 940: ('deep', 1587),\n",
              " 941: ('create', 1586),\n",
              " 942: ('dollar', 1586),\n",
              " 943: ('feature', 1585),\n",
              " 944: ('Both', 1584),\n",
              " 945: ('active', 1584),\n",
              " 946: ('opening', 1583),\n",
              " 947: ('pressure', 1582),\n",
              " 948: ('winter', 1582),\n",
              " 949: ('brother', 1581),\n",
              " 950: ('St.', 1581),\n",
              " 951: ('notes', 1581),\n",
              " 952: ('2002', 1578),\n",
              " 953: ('records', 1578),\n",
              " 954: ('education', 1578),\n",
              " 955: ('edition', 1576),\n",
              " 956: ('community', 1576),\n",
              " 957: ('critic', 1576),\n",
              " 958: ('commercial', 1575),\n",
              " 959: ('center', 1574),\n",
              " 960: ('40', 1573),\n",
              " 961: ('always', 1573),\n",
              " 962: ('brown', 1573),\n",
              " 963: ('General', 1572),\n",
              " 964: ('H.', 1568),\n",
              " 965: ('force', 1567),\n",
              " 966: ('person', 1566),\n",
              " 967: ('22', 1565),\n",
              " 968: ('2017', 1562),\n",
              " 969: ('fact', 1561),\n",
              " 970: ('fiction', 1561),\n",
              " 971: ('nearby', 1560),\n",
              " 972: ('science', 1559),\n",
              " 973: ('growth', 1557),\n",
              " 974: ('arrived', 1556),\n",
              " 975: ('child', 1556),\n",
              " 976: ('future', 1554),\n",
              " 977: ('rate', 1554),\n",
              " 978: ('slightly', 1552),\n",
              " 979: ('critical', 1549),\n",
              " 980: ('2020', 1546),\n",
              " 981: ('J.', 1545),\n",
              " 982: ('failed', 1545),\n",
              " 983: ('society', 1544),\n",
              " 984: ('adult', 1543),\n",
              " 985: ('means', 1542),\n",
              " 986: ('reduced', 1542),\n",
              " 987: ('native', 1541),\n",
              " 988: ('Kingdom', 1539),\n",
              " 989: ('religious', 1539),\n",
              " 990: ('attention', 1539),\n",
              " 991: ('go', 1539),\n",
              " 992: ('20th', 1538),\n",
              " 993: ('additional', 1537),\n",
              " 994: ('2019', 1536),\n",
              " 995: ('numerous', 1533),\n",
              " 996: ('2021', 1533),\n",
              " 997: ('recording', 1533),\n",
              " 998: ('location', 1532),\n",
              " 999: ('helped', 1532),\n",
              " 1000: ('If', 1530),\n",
              " ...}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_counter = Counter()\n",
        "for text in all_inst:\n",
        "    vocab_counter.update(text)\n",
        "vocab_counter = dict(sorted(vocab_counter.items(), key=lambda item: item[1], reverse = True))\n",
        "vocab_counter = {i + 1: (token, frequency) for i, (token, frequency) in enumerate(vocab_counter.items())}\n",
        "# most_common = {math.log(i): math.log(items[1]) for i, items in vocab_counter.items() if items[1]>=10000}\n",
        "most_common = {i: items[1] for j, (i, items) in enumerate(vocab_counter.items()) if j>=10000}\n",
        "vocab_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32bf8bf8",
      "metadata": {
        "id": "32bf8bf8",
        "outputId": "07aecdb8-8524-44f0-a072-af45ebbdab6a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(most_common.values(),most_common.keys())\n",
        "plt.ylabel('frequency')\n",
        "plt.xlabel('rank')\n",
        "plt.title(\"frequency vs rank graph\")\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85578208",
      "metadata": {
        "id": "85578208"
      },
      "outputs": [],
      "source": [
        "# normalized frequency\n",
        "alpha = 0.1\n",
        "k = 3.65\n",
        "y = k / (np.array([*most_common.values()])**alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "502c466e",
      "metadata": {
        "id": "502c466e"
      },
      "outputs": [],
      "source": [
        "#find line of best fit\n",
        "x = np.array([*most_common.values()])\n",
        "y = np.array([*most_common.keys()])\n",
        "a, b, c = np.polyfit(1/y, x, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a4e5c54",
      "metadata": {
        "id": "9a4e5c54",
        "outputId": "fac9580a-014e-49a7-8b8a-5a0ae8999958"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.62038332e+10, 1.62038332e+10, 1.62038332e+10, ...,\n",
              "       1.03707837e+06, 1.03707837e+06, 1.03707837e+06])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = a*x**2 + b*x + c\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24262320",
      "metadata": {
        "id": "24262320"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import curve_fit\n",
        "\n",
        "def f(x, A, B):\n",
        "    return A/(x**B)\n",
        "\n",
        "popt, pcov = curve_fit(f, x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c98d347",
      "metadata": {
        "scrolled": true,
        "id": "3c98d347",
        "outputId": "80cdcf1c-f51f-4192-d2e5-70c3cdf5a769"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(x,y, color = 'red')\n",
        "plt.plot(x, f(x, *popt))\n",
        "plt.ylabel('frequency')\n",
        "plt.xlabel('rank')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b528f97b",
      "metadata": {
        "id": "b528f97b"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c110a89a",
      "metadata": {
        "id": "c110a89a"
      },
      "source": [
        "## Problem 1.2 (2 points) - Contextual Embeddings\n",
        "\n",
        "[Deep contextualized word representations (Peters et al., 2018)](https://arxiv.org/pdf/1802.05365.pdf) uses an LSTM-based architecture to generate meaning representations of tokens.\n",
        "\n",
        "Using the linked paper as reference, highlight the differences between using static word embeddings and contextual representations and suggest two reasons how the language-modelling objective helps other NLP tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eff24273",
      "metadata": {
        "id": "eff24273"
      },
      "source": [
        "Static word emmbeddings are using finite large number of vocab words to emmbed the meaning of each token.\n",
        "\n",
        "The LSTM-based architecture (to be exact the one intrduce in paper biLM is trying to capture deeper sense of the word (like part of speech). It's using the subwords units and character convolutions. The model is learning the linear combination of the vectors stacked above each input word for each end task.\n",
        "\n",
        "As mentioned in the article previous approaches allowed a single context independent representation for each word."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06258eed",
      "metadata": {
        "id": "06258eed"
      },
      "source": [
        "# Problem 2 - BERT-style Language Models (14 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c8ea71",
      "metadata": {
        "id": "f7c8ea71"
      },
      "source": [
        "## Problem 2.1 (8 points) - BERT Language Model\n",
        "Using the provided data, train a language model with the [BERT]((https://aclanthology.org/N19-1423.pdf) masked language model objective (NSP prediction task is not reuqired). Select appropriate model size and hyperparameters.\n",
        "\n",
        "* Make the training data yourself\n",
        "\n",
        "* Print a sample of training instances (both the model inputs and expected outputs)\n",
        "\n",
        "* Plot the loss regularly (e.g. after an epoch or fixed number of training steps) on a graph. Report the loss for both the training data and validation data.\n",
        "\n",
        "* Use the `transformers` library implementation of a suitable tokenizer and model for language modelling with BERT. But do not use a pre-trained language model (i.e. start with a randomly initialized model).  \n",
        "\n",
        "Hint: you can use [BERTConfig](https://huggingface.co/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig) to configure your language model, and use [BERTForMaskedLM](https://huggingface.co/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForMaskedLM) which is a pre-configured language model.\n",
        "\n",
        "Hint: You should use the [AdamW optimizer](https://huggingface.co/docs/transformers/v4.24.0/en/main_classes/optimizer_schedules#transformers.AdamW)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for this task was inspired by many different tutorials about transformers, I don't know how without using some tutorials and documenattion were we supposed to finish this task."
      ],
      "metadata": {
        "id": "BdqcYf3TO8J9"
      },
      "id": "BdqcYf3TO8J9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc2b0713",
      "metadata": {
        "id": "fc2b0713",
        "outputId": "1194cd78-6366-4679-bcc3-3a9d00ed780d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "965a3bc2e6004536b87096dc2440cadc",
            "e0dfebd69a5c482f83b0a992ff6b9945",
            "4102dd376af34b4aaff56e6893d7b0de",
            "7df6cfd6efbd4febba796d248cd995a8",
            "407628bc09bb436c97db177e59819b24",
            "b29aed98ccbb4b949734ad8ffbc9bfbb",
            "de150e41e08a4fecafced2d69815fb80",
            "3eb44cadf64f4ccab86272f31a9ccc52",
            "06951032226c4ba1be372fbaedf36aff",
            "ceaf2151eebd437c8d107aca8678a2bb",
            "c61643c98a79490696676479260dd7bf",
            "bcde37bc306542ea9108f496668e23f3",
            "a8f8cc18b8e94bfda18d21e3a3f38ac8",
            "1537907694084a3d837c896b3ac2d7ae",
            "d1a340a20aa246d8900edfb141e0f127",
            "cf98c2062f8a490d9377f5060674ca14",
            "354a4f9610064a27b7bc0af9028e8a14",
            "4af826a8fda84722b90281837f0bfcdf",
            "6fb8891131284fc689101ce697738754",
            "7d6da47868384332a957757117add452",
            "716723626ea644de8d4341b0f7db111b",
            "5e71f650631b4aa7b20d8fe3ff59ff43",
            "b8b01ef72bea4eb68742b44a7ef0ed77",
            "cc84b37d04c144608544a26ab3a41989",
            "4331bf6aa3d44ac2aef08f2d9333205e",
            "fd15027eff234730b1e58a64a63cf068",
            "6a88780aa662459781070dc10f8f924d",
            "8e4c54d9d33d4a8393b0ad5ea4e5e84e",
            "1e55f3783676438689c50e3426ee5757",
            "570b7e2a420b486a89b7fd460aa3c98a",
            "75dd256da3204c449a4cb84552796a8a",
            "adece1b0a16d4aaa86fda120bbf98882",
            "d2f0055eb85f4598a25c87575745bf0e",
            "5676f8c6052643a884b9ee1021762c62",
            "7792d13d256f4af4a0b131f7e806effe",
            "04ca75419cc24ab5a0c428cd3f8d2bb7",
            "f4fb010216cd4e0cbdc3b66c2d772ff2",
            "4fd329328c2349658123e3e9484b652f",
            "1e8cb8e2beab4f28b8fd266b4239bf29",
            "3b54139ff01a4bce88033b456603b8b6",
            "ae864b6fe330406bb7a426b523a1dc0f",
            "4c14b860d47a44b8beb97fd08e3bee38",
            "040517e19e8c4f20bd7d3b6686c285d7",
            "0e287a5900b840008887b95f8d1fd3e0"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "965a3bc2e6004536b87096dc2440cadc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcde37bc306542ea9108f496668e23f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8b01ef72bea4eb68742b44a7ef0ed77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5676f8c6052643a884b9ee1021762c62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67239dac",
      "metadata": {
        "id": "67239dac"
      },
      "outputs": [],
      "source": [
        "\n",
        "files = [\"drive/MyDrive/nlp/wiki.jsonl\"]\n",
        "model_path = \"drive/MyDrive/nlp/pretrained-bert\"\n",
        "\n",
        "# 30,522 vocab is BERT's default vocab size\n",
        "vocab_size = 30_522\n",
        "# maximum sequence length, lowering will result to faster training (when increasing batch size)\n",
        "max_length = 512\n",
        "# whether to truncate\n",
        "truncate_longer_samples = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f40a1fb",
      "metadata": {
        "id": "1f40a1fb",
        "outputId": "6897394a-3ee3-411e-99cf-8899e8021976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default-7825f0c8f3143c3e\n",
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/json/default-7825f0c8f3143c3e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset('json', data_files=files, split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ca5dd2",
      "metadata": {
        "id": "81ca5dd2",
        "outputId": "e7cb8562-d083-44ef-fd96-133f93da104f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'7 World Trade Center (7 WTC, WTC-7, or Tower 7) refers to two buildings that have existed at the same location within the World Trade Center site in Lower Manhattan, New York City. The original structure, part of the original World Trade Center, was completed in 1987 and was destroyed in the September 11 attacks in 2001. The current structure opened in May 2006. Both buildings were developed by Larry Silverstein, who holds a ground lease for the site from the Port Authority of New York and New Jersey.\\nThe original 7 World Trade Center was 47 stories tall, clad in red granite masonry, and occupied a trapezoidal footprint. An elevated walkway spanning Vesey Street connected the building to the World Trade Center plaza. The building was situated above a Consolidated Edison power substation, which imposed unique structural design constraints. When the building opened in 1987, Silverstein had difficulties attracting tenants. Salomon Brothers signed a long-term lease in 1988 and became the anchor tenant of 7 WTC.\\nOn September 11, 2001, the structure was substantially damaged by debris when the nearby North Tower of the World Trade Center collapsed. The debris ignited fires on multiple lower floors of the building, which continued to burn uncontrolled throughout the afternoon. The building\\'s internal fire suppression system lacked water pressure to fight the fires. The collapse began when a critical internal column buckled and triggered cascading failure of nearby columns throughout, which was first visible from the exterior with the crumbling of a rooftop penthouse structure at 5:20:33 pm. This initiated progressive collapse of the entire building at 5:21:10 pm, according to FEMA,:\\u200a23\\u200a while the 2008 NIST study placed the final collapse time at 5:20:52 pm.:\\u200a19,\\u200a21,\\u200a50–51\\u200a The collapse made the old 7 World Trade Center the first steel skyscraper known to have collapsed primarily due to uncontrolled fires.Construction of the new 7 World Trade Center began in 2002 and was completed in 2006. The building is 52 stories tall (plus one underground floor), making it the 28th-tallest in New York. It is built on a smaller footprint than the original, and is bounded by Greenwich, Vesey, Washington, and Barclay Streets on the east, south, west, and north, respectively. A small park across Greenwich Street occupies space that was part of the original building\\'s footprint. The current building\\'s design emphasizes safety, with a reinforced concrete core, wider stairways, and thicker fireproofing on steel columns. It also incorporates numerous green design features. The building was the first commercial office building in New York City to receive the U.S. Green Building Council\\'s Leadership in Energy and Environmental Design (LEED) certification, where it won a gold rating. It was also one of the first projects accepted to be part of the council\\'s pilot program for Leadership in Energy and Environmental Design – Core and Shell Development (LEED-CS).\\n\\n\\n\\n\\n\\nThe original 7 World Trade Center was a 47-story building, designed by Emery Roth & Sons, with a red granite facade. The building was 610 feet (190 m) tall, with a trapezoidal footprint that was 330 ft (100 m) long and 140 ft (43 m) wide. Tishman Realty & Construction managed construction of the building. The ground-breaking ceremony was hosted on October 2, 1984. The building opened in May 1987, becoming the seventh structure of the World Trade Center.7 World Trade Center was constructed above a two-story Con Edison substation that had been located on the site since 1967. The substation had a caisson foundation designed to carry the weight of a future building of 25 stories containing 600,000 sq ft (56,000 m2). However, the final design for 7 World Trade Center was for a much larger building than originally planned when the substation was built.:\\u200axxxviii\\u200a The structural design of 7 World Trade Center therefore included a system of gravity column transfer trusses and girders, located between floors 5 and 7, to transfer loads to the smaller foundation.:\\u200a5\\u200a Existing caissons installed in 1967 were used, along with new ones, to accommodate the building. The 5th floor functioned as a structural diaphragm, providing lateral stability and distribution of loads between the new and old caissons. Above the 7th floor,  the building\\'s structure was a typical tube-frame design, with columns in the core and on the perimeter, and lateral loads resisted by perimeter moment frames.A shipping and receiving ramp, which served the entire World Trade Center complex, occupied the eastern quarter of the 7 World Trade Center footprint. The building was open below the 3rd floor, providing space for truck clearance on the shipping ramp. The spray-on fireproofing for structural steel elements was gypsum-based Monokote, which had a two-hour fire rating for steel beams, girders and trusses, and a three-hour rating for columns.:\\u200a11\\u200aMechanical equipment was installed on floors four through seven, including 12 transformers on the 5th floor. Several emergency generators installed in the building were used by the New York City Office of Emergency Management, Salomon Smith Barney, and other tenants.:\\u200a13\\u200a In order to supply the generators, 24,000 gallons (91,000 L) of diesel fuel were stored below ground level. Diesel fuel distribution components were located at ground level, up to the ninth floor.:\\u200a35\\u200a After the World Trade Center bombings of February 26, 1993, New York City mayor Rudy Giuliani decided to situate the emergency command center and associated fuel tanks at 7 World Trade Center. Although this decision was criticized in light of the events of 9/11, the fuel in the building is today not believed to have contributed to the collapse of the building.:\\u200a2\\u200a The roof of the building included a small west penthouse and a larger east mechanical penthouse.Each floor had 47,000 sq ft (4,400 m2) of rentable office space, which made the building\\'s floor plans considerably larger than most office buildings in the city. In all, 7 World Trade Center had 1,868,000 sq ft (173,500 m2) of office space.:\\u200a1\\u200a Two pedestrian bridges connected the main World Trade Center complex, across Vesey Street, to the third floor of 7 World Trade Center. The lobby of 7 World Trade Center held three murals by artist Al Held: The Third Circle, Pan North XII, and Vorces VII.\\n\\n\\n\\nIn June 1986, before construction was completed, developer Larry Silverstein signed Drexel Burnham Lambert as a tenant to lease the entire 7 World Trade Center building for $3 billion over a term of 30 years.\\nIn December 1986, after the Boesky insider-trading scandal, Drexel Burnham Lambert canceled the lease, leaving Silverstein to find other tenants.\\nSpicer & Oppenheim agreed to lease 14 percent of the space, but for more than a year, as Black Monday and other factors adversely affected the Lower Manhattan real estate market, Silverstein was unable to find tenants for the remaining space. By April 1988, he had lowered the rent and made other concessions.In November 1988, Salomon Brothers withdrew from plans to build a large new complex at Columbus Circle in Midtown, instead agreeing to a 20-year lease for the top 19 floors of 7 World Trade Center. The building was extensively renovated in 1989 to accommodate Salomon Brothers, and 7 World Trade Center alternatively became known as the Salomon Brothers building. Most of the three existing floors were removed as tenants continued to occupy other stories, and more than 350 tons (U.S.) of steel were added to construct three double-height trading floors. Nine diesel generators were installed on the 5th floor as part of a backup power station. \"Essentially, Salomon is constructing a building within a building – and it\\'s an occupied building, which complicates the situation\", said a district manager of Silverstein Properties. According to Larry Silverstein, the unusual task was possible because it could allow \"entire portions of floors to be removed without affecting the building\\'s structural integrity, on the assumption that someone might need double-height floors.\"At the time of the September 11, 2001, attacks, Salomon Smith Barney was by far the largest tenant in 7 World Trade Center, occupying 1,202,900 sq ft (111,750 m2) (64 percent of the building) which included floors 28–45.:\\u200a2\\u200a Other major tenants included ITT Hartford Insurance Group (122,590 sq ft/11,400 m2), American Express Bank International (106,117 sq ft/9,900 m2), Standard Chartered Bank (111,398 sq ft/10,350 m2), and the Securities and Exchange Commission (106,117 sq ft/9,850 m2). Smaller tenants included the Internal Revenue Service Regional Council (90,430 sq ft/8,400 m2) and the United States Secret Service (85,343 sq ft/7,900 m2). The smallest tenants included the New York City Office of Emergency Management, National Association of Insurance Commissioners, Federal Home Loan Bank of New York, First State Management Group Inc., Provident Financial Management, and the Immigration and Naturalization Service. The Department of Defense (DOD) and Central Intelligence Agency (CIA) shared the 25th floor with the IRS.:\\u200a2\\u200a (The clandestine CIA office was revealed only after the 9/11 attacks.)  Floors 46–47 were mechanical floors, as were the bottom six floors and part of the seventh floor.:\\u200a2\\u200a\\n\\n\\n\\n\\nAs the North Tower collapsed on September 11, 2001, heavy debris hit 7 World Trade Center, damaging the south face of the building:\\u200a18 (PDF p. 22)\\u200a and starting fires that continued to burn throughout the afternoon.:\\u200a16,\\u200a18\\u200a The collapse also caused damage to the southwest corner between floors 7 and 17 and on the south face between Floor 44 and the roof; other possible structural damage included a large vertical gash near the center of the south face between Floors 24 and 41.:\\u200a17\\u200a The building was equipped with a sprinkler system, but had many single-point vulnerabilities for failure: the sprinkler system required manual initiation of the electrical fire pumps, rather than being a fully automatic system; the floor-level controls had a single connection to the sprinkler water riser, and the sprinkler system required some power for the fire pump to deliver water.:\\u200a11\\u200a Additionally, water pressure was low, with little or no water to feed sprinklers.:\\u200a23–30\\u200aAfter the North Tower collapsed, some firefighters entered 7 World Trade Center to search the building. They attempted to extinguish small pockets of fire, but low water pressure hindered their efforts. Over the course of the day, fires burned out of control on several floors of 7 World Trade Center, the flames visible on the east side of the building. During the afternoon, the fire was also seen on floors 6–10, 13–14, 19–22, and 29–30.:\\u200a24 (PDF p. 28)\\u200a In particular, the fires on floors 7 through 9 and 11 through 13 continued to burn out of control during the afternoon. At approximately 2:00 pm, firefighters noticed a bulge in the southwest corner of 7 World Trade Center between the 10th and 13th floors, a sign that the building was unstable and might collapse. During the afternoon, firefighters also heard creaking sounds coming from the building. Around 3:30 pm, FDNY Chief of Operations Daniel A. Nigro decided to halt rescue operations, surface removal, and searches along the surface of the debris near 7 World Trade Center and evacuate the area due to concerns for the safety of personnel.The fire expanded the girders of the building, causing some to collapse. This led to the northeast corner core column (Column 79), which was especially large, to buckle below the 13th floor. This caused the floors above it to collapse to the transfer floor at the fifth level. The structure also developed cracks in the facade just before the entire building started to fall.:\\u200a21\\u200a According to FEMA, this collapse started at 5:20:33 pm EDT when the east mechanical penthouse started crumbling.:\\u200a23\\u200a Differing times are given as to what time the building completely collapsed: at 5:21:10 pm EDT according to FEMA,:\\u200a23\\u200a and at 5:20:52 pm EDT according to NIST.:\\u200a19,\\u200a21,\\u200a50–51\\u200aThere were no casualties associated with the collapse. NIST found no evidence to support conspiracy theories such as the collapse being the result of explosives; it found that a combination of factors including physical damage, fire, and the building\\'s unusual construction set off a chain-reaction collapse.\\n\\n\\n\\nIn May 2002, the Federal Emergency Management Agency (FEMA) issued a report on the collapse based on a preliminary investigation conducted jointly with the Structural Engineering Institute of the American Society of Civil Engineers under the leadership of Dr. W. Gene Corley, P.E. FEMA made preliminary findings that the collapse was not primarily caused by actual impact damage from the collapse of 1 WTC and 2 WTC but by fires on multiple stories ignited by debris from the other two towers that continued burning unabated due to lack of water for sprinklers or manual firefighting. The report did not reach conclusions about the cause of the collapse and called for further investigation.:\\u200a3\\u200aSubsequently, the National Institute of Standards and Technology (NIST) was authorized to lead an investigation into the structural failure and collapse of the World Trade Center Twin Towers and 7 World Trade Center. The investigation, led by Dr S. Shyam Sunder, drew upon in-house technical expertise as well as the knowledge of several outside private institutions, including the Structural Engineering Institute of the American Society of Civil Engineers (SEI/ASCE); the Society of Fire Protection Engineers (SFPE); the National Fire Protection Association (NFPA); the American Institute of Steel Construction (AISC); the Council on Tall Buildings and Urban Habitat (CTBUH); and the Structural Engineers Association of New York (SEAoNY).\\n\\nThe bulk of the investigation of 7 World Trade Center was delayed until after reports were completed on the Twin Towers. In the meantime, NIST provided a preliminary report about 7 WTC in June 2004, and thereafter released occasional updates on the investigation. According to NIST, the investigation of 7 World Trade Center was delayed for a number of reasons, including that NIST staff who had been working on 7 World Trade Center were assigned full-time from June 2004 to September 2005 to work on the investigation of the collapse of the Twin Towers. In June 2007, Shyam Sunder explained, We are proceeding as quickly as possible while rigorously testing and evaluating a wide range of scenarios to reach the most definitive conclusion possible. The 7 WTC investigation is in some respects just as challenging, if not more so than the study of the towers. However, the current study does benefit greatly from the significant technological advances achieved and lessons learned from our work on the towers.\\n\\nIn November 2008, NIST released its final report on the causes of the collapse of 7 World Trade Center. This followed NIST\\'s August 21, 2008, draft report which included a period for public comments, and was followed in 2012 by a peer-reviewed summary in the Journal of Structural Engineering. In its investigation, NIST utilized ANSYS to model events leading up to collapse initiation and LS-DYNA models to simulate the global response to the initiating events.:\\u200a6–7\\u200a NIST determined that diesel fuel did not play an important role, nor did the structural damage from the collapse of the Twin Towers or the transfer elements (trusses, girders, and cantilever overhangs). The lack of water to fight the fire was an important factor. The fires burned out of control during the afternoon, causing floor beams near column 79 to expand and push a key girder off its seat, triggering the floors to fail around column 79 on Floors 8 to 14. With a loss of lateral support across nine floors, column 79 buckled – pulling the east penthouse and nearby columns down with it. With the buckling of these critical columns, the collapse then progressed east-to-west across the core, ultimately overloading the perimeter support, which buckled between Floors 7 and 17, causing the remaining portion of the building above to fall down as a single unit. The fires, which were fueled by office contents and burned for 7 hours, along with the lack of water, were the key reasons for the collapse.:\\u200a21–22\\u200a At the time, this made the old 7 WTC the only steel skyscraper to have collapsed from fire.When 7 WTC collapsed, debris caused substantial damage and contamination to the Borough of Manhattan Community College\\'s Fiterman Hall building, located adjacent at 30 West Broadway, to the extent that the building was not salvageable. A revised plan called for demolition in 2009 and completion of the new Fiterman Hall in 2012, at a cost of $325 million. The Verizon Building, an art deco building located directly to the west, had extensive damage to its eastern facade from the collapse of 7 World Trade Center, though it was later restored at a cost of US$1.4 billion.\\n\\nFiles relating to numerous federal investigations had been housed in 7 World Trade Center. The Equal Employment Opportunity Commission estimated over 10,000 of its cases were affected. Investigative files in the Secret Service\\'s largest field office were lost, with one Secret Service agent saying, \"All the evidence that we stored at 7 World Trade, in all our cases, went down with the building.\" Copies of emails in connection with the WorldCom scandal that were later requested by the SEC from Salomon Brothers, a subsidiary of Citigroup housed in the building, were also destroyed.The NIST report found no evidence supporting the conspiracy theories that 7 World Trade Center was brought down by controlled demolition. Specifically, the window breakage pattern and blast sounds that would have resulted from the use of explosives were not observed.:\\u200a26–28\\u200a The suggestion that an incendiary material such as thermite was used instead of explosives was considered unlikely by NIST because of the building\\'s structural response to the fire, the nature of the fire, and the unlikelihood that a sufficient amount of thermite could be planted without discovery. Based on its investigation, NIST reiterated several recommendations it had made in its earlier report on the collapse of the Twin Towers.:\\u200a63–73\\u200a It urged immediate action on a further recommendation: that fire resistance should be evaluated under the assumption that sprinklers are unavailable;:\\u200a65–66\\u200a and that the effects of thermal expansion on floor support systems be considered.:\\u200a65,\\u200a69\\u200a  Recognizing that current building codes are drawn to prevent loss of life rather than building collapse, the main point of NIST\\'s recommendations was that buildings should not collapse from fire even if sprinklers are unavailable.:\\u200a63–73\\u200a\\n\\n\\n\\nThe new 7 World Trade Center has 52 stories and is 741 ft (226 m) tall. The building has 42 floors of leasable space, starting at the 11th floor, and a total of 1.7 million sq ft (160,000 m2) of office space. The first ten floors house an electrical substation which provides power to much of Lower Manhattan. The office tower has a narrower footprint at ground level than did its predecessor, so the course of Greenwich Street could be restored to reunite TriBeCa and the Financial District. The original building, on the other hand, had bordered West Broadway on the east, necessitating the destruction of Greenwich Street between Barclay Street and the northern border of the World Trade Center superblock.\\n\\n\\nDavid Childs of Skidmore, Owings and Merrill worked in conjunction with glass artist and designer James Carpenter to create a design that uses ultra-clear, low-iron glass to provide reflectivity and light, with stainless-steel spandrels behind the glass to help reflect sunlight. Stainless steel used in the building façade is molybdenum-containing Type 316, which provides improved resistance to corrosion. To enclose the power substation and improve its aesthetics, the base of the building has a curtain wall with stainless steel louvers that provide ventilation for the machinery. During the day, the curtain wall reflects light, while at night it is illuminated with blue LED lights. The curtain wall around the lobby uses heavily laminated, heat-strengthened glass that meets high standards for blast resistance. At night, a large cube of light above the lobby also emanates blue light, while during the day it provides white light to the lobby, and at dusk, it transitions to violet and back to blue. Inside the main lobby, artist Jenny Holzer created a large light installation with glowing text moving across wide plastic panels. The entire wall, which is 65 ft (20 m) wide and 14 ft (4.3 m) tall, changes color according to the time of day. Holzer worked with Klara Silverstein, the wife of Larry Silverstein, to select poetry for the art installation. The wall is structurally fortified as a security measure.The building is being promoted as the safest skyscraper in the U.S. According to Silverstein Properties, the owner of the building, it \"incorporate[s] a host of life-safety enhancements that will become the prototype for new high-rise construction.\" The building has 2-foot-thick (0.61 m) reinforced-concrete and fireproofed elevator and stairway access shafts. The original building used only drywall to line these shafts. The stairways are wider than in the original building to permit faster egress.7 World Trade Center is equipped with Otis destination elevators. After pressing a destination floor number on a lobby keypad, passengers are grouped and directed to specific elevators that will stop at the selected floor (there are no buttons to press inside the elevators). This system is designed to reduce elevator waiting and travel times. The elevator system is integrated with the lobby turnstile and card reader system that identifies the floor on which a person works as he or she enters and can automatically call the elevator for that floor.Nearly 30 percent of structural steel used in the building consists of recycled steel. Rainwater is collected and used for irrigation of the park and to cool the building. Along with other sustainable design features, the building is designed to allow in plenty of natural light, power is metered to tenants to encourage them to conserve energy, the heating steam is reused to generate some power for the building, and recycled materials are used for insulation and interior materials. WSP Cantor Seinuk served as structural engineer on the project, while Jaros, Baum & Bolles was the MEP engineer.\\n\\n\\n\\nThe construction phase of the new 7 World Trade Center began on May 7, 2002, with the installation of a fence around the construction site. Tishman Construction Corporation of New York began work at the new 7 World Trade Center in 2002, soon after the site was cleared of debris. Restoring the Con Ed electrical substation was an urgent priority to meet power demands of Lower Manhattan. Because 7 World Trade Center is separate from the main 16-acre (6.5 ha) World Trade Center site, Larry Silverstein required approval from only the Port Authority, and rebuilding was able to proceed quickly.Once construction of the power substation was completed in October 2003, work proceeded on building the office tower. An unusual approach was used in constructing the building; erecting the steel frame before adding the concrete core. This approach allowed the construction schedule to be shortened by a few months. Construction was completed in 2006 at a cost of $700 million. Though Silverstein received $861 million from insurance on the old building, he owed more than $400 million on its mortgage. Costs to rebuild were covered by $475 million in Liberty Bonds, which provide tax-exempt financing to help stimulate rebuilding in Lower Manhattan and insurance money that remained after other expenses.A 15,000 sq ft (1,400 m2) triangular park was created between the extended Greenwich Street and West Broadway by David Childs with Ken Smith and his colleague, Annie Weinmayr, of Ken Smith Landscape Architect. The park comprises an open central plaza with a fountain and flanking groves of sweetgum trees and boxwood shrubs. At the center of the fountain, sculptor Jeff Koons created Balloon Flower (Red), whose mirror-polished stainless steel represents a twisted balloon in the shape of a flower.\\n\\n\\n\\n\\nThe building was officially opened at noon on May 23, 2006, with a free concert featuring Suzanne Vega, Citizen Cope, Bill Ware Vibes, Brazilian Girls, Ollabelle, Pharaoh\\'s Daughter, Ronan Tynan (of the Irish Tenors), and special guest Lou Reed. Prior to opening, in March 2006, the new 7 World Trade Center frontage and lobby were used in scenes for the movie Perfect Stranger with Halle Berry and Bruce Willis.After the building opened, several unleased upper floors were used for events such as charity lunches, fashion shows, and black-tie galas. Silverstein Properties allowed space in the new building to be used for these events as a means to draw people to see the building. From September 8 to October 7, 2006, the work of photographer Jonathan Hyman was displayed in \"An American Landscape\", a free exhibit hosted by the World Trade Center Memorial Foundation at 7 World Trade Center. The photographs captured the response of people in New York City and across the United States after the September 11, 2001, attacks. The exhibit took place on the 45th floor while space remained available for lease.\\n\\nBy March 2007, 60 percent of the building had been leased. In September 2006, Moody\\'s signed a 20-year lease to rent 15 floors of 7 World Trade Center. Other tenants that had signed leases in 7 World Trade Center, as of May 2007, included ABN AMRO, Ameriprise Financial Inc., law firm Wilmer Hale, publisher Mansueto Ventures, and the New York Academy of Sciences. Silverstein Properties also has offices and the Silver Suites executive office suites in 7 World Trade Center, along with office space used by the architectural and engineering firms working on 1 World Trade Center, 150 Greenwich Street, 175 Greenwich Street, and 200 Greenwich Street. After AMN AMRO was acquired by the Royal Bank of Scotland, forex services provider FXDD subleased some of the Royal Bank of Scotland\\'s space in 2009.The space occupied by Mansueto Ventures has been designed to use the maximum amount of natural light and has an open floor plan. The space used by the New York Academy of Sciences on the 40th floor, designed by H3 Hardy Collaboration Architecture, works with the parallelogram shape of the building. Keeping with the green design of the building, the NYAS uses recycled materials in many of the office furnishings, has zoned heating and cooling, and motion-detecting lights, which activate automatically when people are present, and adjust according to incoming sunlight.\\n\\n\\nThe building became fully leased in September 2011 after MSCI agreed to occupy 125,000 square feet (11,600 m2) on the top floor. Following this, Silverstein announced in 2012 that he would refinance the building with a $452.8 million Liberty bond issue and a $125 million commercial mortgage-backed security loan. At the time, the building was valued at $940 million, in large part because it was fully occupied. FXDD subleased its space to engineering company Permasteelisa in 2015 and artificial intelligence firm IPsoft in 2016. The building was 94.8 percent occupied by 2017. At the time, roughly three-quarters of the space was occupied by four tenants, including Moody\\'s, the Royal Bank of Scotland, and Wilmer Hale.Wedding planning company Zola and the building\\'s own architecture firm Skidmore, Owings & Merrill both leased space at 7 WTC in early 2019. This was followed in July 2019 by luxury drink brand Moët Hennessy and media company AccuWeather. After publisher Mansueto Ventures and three other firms took space at 7 WTC in April 2022, the building was 97 percent occupied. Shortly afterward, Silverstein Properties refinanced the property with a $458 million loan from Goldman Sachs.\\n\\n\\n\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dataset['text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edda14c7",
      "metadata": {
        "id": "edda14c7",
        "outputId": "90365a58-ef9a-4323-c395-6f5327c08ba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['title', 'text'],\n",
              "     num_rows: 2622\n",
              " }), Dataset({\n",
              "     features: ['title', 'text'],\n",
              "     num_rows: 292\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# split the dataset into training (90%) and testing (10%)\n",
        "d = dataset.train_test_split(test_size=0.1)\n",
        "d[\"train\"], d[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from https://www.thepythoncode.com/article/pretraining-bert-huggingface-transformers-in-python\n",
        "def encode_with_truncation(examples):\n",
        "    \"\"\"Mapping function to tokenize the sentences passed with truncation\"\"\"\n",
        "    return bert_tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\",\n",
        "                   max_length=max_length, return_special_tokens_mask=True)\n",
        "\n",
        "def encode_without_truncation(examples):\n",
        "    \"\"\"Mapping function to tokenize the sentences passed without truncation\"\"\"\n",
        "    return bert_tokenizer(examples[\"text\"], return_special_tokens_mask=True)\n"
      ],
      "metadata": {
        "id": "XLSX2QZWw_Jz"
      },
      "id": "XLSX2QZWw_Jz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b1b149f",
      "metadata": {
        "id": "7b1b149f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "74a9a3f7ea0b412ebda8dc0fd775c0e6",
            "ea5a5c1544f344e5bbbe8970e9cf480d",
            "ca7b8613e824480d905bb1328166cbf0",
            "1972370d9c134d7fb540ba64b3660440",
            "d3fb8f60ab6344a1b83a23907db4f6fb",
            "0e13c39f071a4b238f091ad6aa3293c2",
            "2c20c4900bc5480e8be5c9781c5699fd",
            "d6dbc5dea531493e8fe82b5c369e2621",
            "ddaf6c5f182b480d87fa8b52cc916c3a",
            "d1b87bddee074717a9c72ef9e6b2625a",
            "9c0224d3b7ba4bb9814f565203ab6795",
            "50b7899050c1403e9fadc0ddf5171c70",
            "1ac1344912d64370b94885abd7838d6e",
            "ad0e0c374f254a0880f084b0f2926636",
            "acb24e75f65c462aa1fc899527635b3d",
            "213b44e16c384b0aad4039f926f3f340",
            "42f892a6c18a4aa39dff118ded73ffbb",
            "ad8f602cfc4b4d8b913117548838c57d",
            "bfa96b053b164cbcb5387a14a0c4318a",
            "cc3ae126c4bd466ea83696b60a1ded37",
            "10c0553dba354eadad3a924d642a1049",
            "f2e19180a5854c409d41badd8d6231e1"
          ]
        },
        "outputId": "d1e56ab4-a592-487d-f4ab-ad272f9be851"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74a9a3f7ea0b412ebda8dc0fd775c0e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50b7899050c1403e9fadc0ddf5171c70"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# the encode function will depend on the truncate_longer_samples variable\n",
        "encode = encode_with_truncation if truncate_longer_samples else encode_without_truncation\n",
        "# tokenizing the train dataset\n",
        "train_dataset = d[\"train\"].map(encode, batched=True)\n",
        "# tokenizing the testing dataset\n",
        "test_dataset = d[\"test\"].map(encode, batched=True)\n",
        "if truncate_longer_samples:\n",
        "    # remove other columns and set input_ids and attention_mask as PyTorch tensors\n",
        "    train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "    test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "else:\n",
        "    # remove other columns, and remain them as Python lists\n",
        "    test_dataset.set_format(columns=[\"input_ids\", \"attention_mask\", \"special_tokens_mask\"])\n",
        "    train_dataset.set_format(columns=[\"input_ids\", \"attention_mask\", \"special_tokens_mask\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3729e38",
      "metadata": {
        "id": "a3729e38"
      },
      "outputs": [],
      "source": [
        "from itertools import chain\n",
        "# from: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
        "def group_texts(examples):\n",
        "    # concatenate all texts\n",
        "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "\n",
        "    if total_length >= max_length:\n",
        "        total_length = (total_length // max_length) * max_length\n",
        "    # spliting by max_length\n",
        "    result = {\n",
        "        k: [t[i : i + max_length] for i in range(0, total_length, max_length)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    return result\n",
        "\n",
        "# https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map\n",
        "if not truncate_longer_samples:\n",
        "  #for train dataset and test separately\n",
        "    train_dataset = train_dataset.map(group_texts, batched=True,\n",
        "                                    desc=f\"Grouping texts in chunks of {max_length}\")\n",
        "    test_dataset = test_dataset.map(group_texts, batched=True,\n",
        "                                  desc=f\"Grouping texts in chunks of {max_length}\")\n",
        "    # converting them from lists to torch tensors\n",
        "    train_dataset.set_format(\"torch\")\n",
        "    test_dataset.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c8a9815",
      "metadata": {
        "id": "5c8a9815",
        "outputId": "7972c823-2f28-40a9-de7f-a88ee1600fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2622, 292)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(train_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c56b1b",
      "metadata": {
        "id": "52c56b1b"
      },
      "outputs": [],
      "source": [
        "# initialize the model with the config\n",
        "model_config = BertConfig(vocab_size=vocab_size, max_position_embeddings=max_length)\n",
        "model = BertForMaskedLM(config=model_config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=1e-2)"
      ],
      "metadata": {
        "id": "2OhjYA0tWwP4"
      },
      "id": "2OhjYA0tWwP4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96c670ee",
      "metadata": {
        "id": "96c670ee"
      },
      "outputs": [],
      "source": [
        "# initialize the data collator, randomly masking 20% (default is 15%) of the tokens for the Masked Language\n",
        "# Modeling (MLM) task\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=bert_tokenizer, mlm=True, mlm_probability=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30d2ee1c",
      "metadata": {
        "id": "30d2ee1c",
        "outputId": "80081719-5dc5-4f07-e0c8-1714abde3251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 100\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=model_path,          # output directory to where save model checkpoint\n",
        "    evaluation_strategy=\"steps\",    # evaluate each `logging_steps` steps\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=10,            # number of training epochs, feel free to tweak\n",
        "    per_device_train_batch_size=4, # the training batch size, put it as high as your GPU memory fits\n",
        "    gradient_accumulation_steps=8,  # accumulating the gradients before updating the weights\n",
        "    per_device_eval_batch_size=32,  # evaluation batch size\n",
        "    logging_steps=100,             # evaluate, log and save model checkpoints every 1000 step\n",
        "    save_steps=1000,\n",
        "    # load_best_model_at_end=True,  # whether to load the best model (in terms of loss) at the end of training\n",
        "    save_total_limit=3,           # space limitation you let only x model weights saved in the disk\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9e206b7",
      "metadata": {
        "id": "e9e206b7"
      },
      "outputs": [],
      "source": [
        "# initialize the trainer and pass everything to it\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c076d38",
      "metadata": {
        "id": "1c076d38",
        "outputId": "6ccad844-7e52-41fa-fc1d-7837d01ee14b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 2622\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 820\n",
            "  Number of trainable parameters = 109514298\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='820' max='820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [820/820 50:47, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>7.168100</td>\n",
              "      <td>7.033569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.959800</td>\n",
              "      <td>6.902548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>6.875200</td>\n",
              "      <td>6.865242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.829200</td>\n",
              "      <td>6.795207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.769000</td>\n",
              "      <td>6.754650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.735000</td>\n",
              "      <td>6.708695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>6.713400</td>\n",
              "      <td>6.745007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.702900</td>\n",
              "      <td>6.681800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=820, training_loss=6.840327788562309, metrics={'train_runtime': 3051.428, 'train_samples_per_second': 8.593, 'train_steps_per_second': 0.269, 'total_flos': 6901230191616000.0, 'train_loss': 6.840327788562309, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Opening JSON file\n",
        "f = open(\"drive/MyDrive/nlp/pretrained-bert/trained_model/trainer_state.json\")\n",
        "train_loss = []\n",
        "# returns JSON object as\n",
        "# a dictionary\n",
        "data = json.load(f)\n",
        "for i in data['log_history']:\n",
        "  try:\n",
        "    print(i['eval_loss'])\n",
        "    train_loss.append(i['eval_loss'])\n",
        "  except:\n",
        "    pass\n",
        "# Closing file\n",
        "f.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYi4LCH_cbB8",
        "outputId": "52aa633c-2f12-46ea-9ee5-62ea4a9cbd07"
      },
      "id": "ZYi4LCH_cbB8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.645091533660889\n",
            "6.5709075927734375\n",
            "6.557473659515381\n",
            "6.5397114753723145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pylab import plt\n",
        "from numpy import arange\n",
        "\n",
        "# Generate a sequence of integers to represent the epoch numbers\n",
        "epochs = range(1,len(train_loss)+1)\n",
        "\n",
        "# Plot and label the training and validation loss values\n",
        "plt.plot(epochs, train_loss, label='Validation Loss')\n",
        "\n",
        "# Add in a title and axes labels\n",
        "plt.title('Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Display the plot\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "BA1U9iSdcSYv",
        "outputId": "bd139ef6-0e68-4f95-ef23-cd8d577b67bc"
      },
      "id": "BA1U9iSdcSYv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.save(model, '/model')\n",
        "\n",
        "saved_model = torch.load('/model')"
      ],
      "metadata": {
        "id": "XXGghxYsWp13"
      },
      "id": "XXGghxYsWp13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15235351",
      "metadata": {
        "id": "15235351",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1671c698-e978-4bf7-e17c-fc629ece3049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file pretrained-bert/checkpoint-4000/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pretrained-bert/checkpoint-4000/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
            "\n",
            "All the weights of BertForMaskedLM were initialized from the model checkpoint at pretrained-bert/checkpoint-4000.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# load the model checkpoint\n",
        "model = BertForMaskedLM.from_pretrained(os.path.join(\"pretrained-bert/checkpoint-4000\")) #model_path,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773ee1c8",
      "metadata": {
        "id": "773ee1c8"
      },
      "outputs": [],
      "source": [
        "fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=bert_tokenizer) # form documatation and tutorials from Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform predictions\n",
        "# examples taken from internet\n",
        "examples = [\n",
        "  \"Today's most trending hashtags on [MASK] is Donald Trump\",\n",
        "  \"The [MASK] was cloudy yesterday, but today it's rainy.\",\n",
        "  \"The capital of France is [MASK].\"\n",
        "]\n",
        "for example in examples:\n",
        "  for prediction in fill_mask(example):\n",
        "    print(f\"{prediction['sequence']}, confidence: {prediction['score']}\")\n",
        "  print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zHKkwqYLsxL",
        "outputId": "367e1ba9-3f87-4fa2-8f36-4386a2239e52"
      },
      "id": "5zHKkwqYLsxL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "today's most trending hashtags on s is donald trump, confidence: 0.08419137448072433\n",
            "today's most trending hashtags on'is donald trump, confidence: 0.052732113748788834\n",
            "today's most trending hashtags on, is donald trump, confidence: 0.04283653199672699\n",
            "today's most trending hashtags on the is donald trump, confidence: 0.03841094672679901\n",
            "today's most trending hashtags on. is donald trump, confidence: 0.036555215716362\n",
            "==================================================\n",
            "the the was cloudy yesterday, but today it's rainy., confidence: 0.05472173914313316\n",
            "the'was cloudy yesterday, but today it's rainy., confidence: 0.04944892227649689\n",
            "the s was cloudy yesterday, but today it's rainy., confidence: 0.04753046855330467\n",
            "the. was cloudy yesterday, but today it's rainy., confidence: 0.040619831532239914\n",
            "the, was cloudy yesterday, but today it's rainy., confidence: 0.03043619729578495\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e269307d",
      "metadata": {
        "id": "e269307d"
      },
      "source": [
        "## Problem 2.2 (2 points) - Hyperparameters\n",
        "Experiment with changing model 3-4 of the model hyperparameters (e.g. sequence length, number of attention heads, hidden dimension, number of layers, etc). How do these change the training behaviour and loss of your model and why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd455102",
      "metadata": {
        "id": "cd455102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1ad22ffc73d94051b43acea8382df344",
            "f5684dd020604f7286bb1ed4ac2f1d8f",
            "078b11ec8b4d404fab4c33146140b7a4",
            "640766c1360b49b7b7dd5cbfc07f33b4",
            "b61d87fb1d5f46e1bac69b67d8e4a809",
            "ca3f0a21344748d0934d61872f602e56",
            "3e89a647bbbf4884b5df6364ae672336",
            "b34ace5395944a3d9341f8f2c66a29b5",
            "b33d0a9dc15a461a974f0faf85cb20de",
            "78a266b15cbd4c4c8c593beaf624b0b7",
            "98b380c8395f49378fa975334b584348",
            "f2e1ed8150704273943f25c81553ef39",
            "145c50a9763c4d3e95f294c531660af5",
            "0c2dda271bfd439285f2d81aba68c541",
            "3b5084748ca44faba05244bec047f8d3",
            "70a6af54a8934bed91d0dfb098365a49",
            "3da46f793ced4abca13472f9ea767ac7",
            "659f9071586941bea3f2384ee7e58f11",
            "8ed3e73492a54d42961e51415f00eaa8",
            "d5635808d3814a2f87734571f678b107",
            "83dc6cee2fbf4039a59fd7a9c72a10aa",
            "183dad64294947968337130117adb99c"
          ]
        },
        "outputId": "222172d0-2b9e-4b4b-d2de-3907bc4bc480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ad22ffc73d94051b43acea8382df344"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2e1ed8150704273943f25c81553ef39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 2622\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 820\n",
            "  Number of trainable parameters = 109279290\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='820' max='820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [820/820 20:45, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>8.086800</td>\n",
              "      <td>7.255520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>7.115100</td>\n",
              "      <td>7.044553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>6.946600</td>\n",
              "      <td>6.954809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.898200</td>\n",
              "      <td>6.870529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.833300</td>\n",
              "      <td>6.888351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.795600</td>\n",
              "      <td>6.782452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>6.755900</td>\n",
              "      <td>6.826094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.743600</td>\n",
              "      <td>6.778284</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=820, training_loss=7.015343735857708, metrics={'train_runtime': 1247.3093, 'train_samples_per_second': 21.021, 'train_steps_per_second': 0.657, 'total_flos': 2776666834908000.0, 'train_loss': 7.015343735857708, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "files = [\"drive/MyDrive/nlp/wiki.jsonl\"]\n",
        "model_path = \"drive/MyDrive/nlp/pretrained-bert\"\n",
        "\n",
        "# 30,522 vocab is BERT's default vocab size, feel free to tweak\n",
        "vocab_size = 30_522\n",
        "# maximum sequence length, lowering will result to faster training (when increasing batch size)\n",
        "max_length = 206\n",
        "# whether to truncate\n",
        "truncate_longer_samples = True\n",
        "\n",
        "# the encode function will depend on the truncate_longer_samples variable\n",
        "encode = encode_with_truncation if truncate_longer_samples else encode_without_truncation\n",
        "# tokenizing the train dataset\n",
        "train_dataset = d[\"train\"].map(encode, batched=True)\n",
        "# tokenizing the testing dataset\n",
        "test_dataset = d[\"test\"].map(encode, batched=True)\n",
        "if truncate_longer_samples:\n",
        "    # remove other columns and set input_ids and attention_mask as PyTorch tensors\n",
        "    train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "    test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "else:\n",
        "    # remove other columns, and remain them as Python lists\n",
        "    test_dataset.set_format(columns=[\"input_ids\", \"attention_mask\"])\n",
        "    train_dataset.set_format(columns=[\"input_ids\", \"attention_mask\"])\n",
        "\n",
        "if not truncate_longer_samples:\n",
        "    train_dataset = train_dataset.map(group_texts, batched=True,\n",
        "                                    desc=f\"Grouping texts in chunks of {max_length}\")\n",
        "    test_dataset = test_dataset.map(group_texts, batched=True,\n",
        "                                  desc=f\"Grouping texts in chunks of {max_length}\")\n",
        "    # convert them from lists to torch tensors\n",
        "    train_dataset.set_format(\"torch\")\n",
        "    test_dataset.set_format(\"torch\")\n",
        "\n",
        "# initialize the model with the config\n",
        "model_config = BertConfig(vocab_size=vocab_size, max_position_embeddings=max_length)\n",
        "model = BertForMaskedLM(config=model_config)\n",
        "\n",
        "# initialize the data collator, randomly masking 20% (default is 15%) of the tokens for the Masked Language\n",
        "# Modeling (MLM) task\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=bert_tokenizer, mlm=True, mlm_probability=0.2\n",
        ")\n",
        "\n",
        "# initialize the trainer and pass everything to it\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shortening the sentence is making model learn less form each part and as a consequences the loss is dereasing slower but its increasing the speed of learning. Since the task is to find out the behaviour of the model after changing only one parameter I did not increase the batch size (it's a very common trick to preserve the loss)."
      ],
      "metadata": {
        "id": "IqLi9pdwgcFJ"
      },
      "id": "IqLi9pdwgcFJ"
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=model_path,          # output directory to where save model checkpoint\n",
        "    evaluation_strategy=\"steps\",    # evaluate each `logging_steps` steps\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,            # number of training epochs, feel free to tweak\n",
        "    per_device_train_batch_size=4, # the training batch size, put it as high as your GPU memory fits\n",
        "    gradient_accumulation_steps=8,  # accumulating the gradients before updating the weights\n",
        "    per_device_eval_batch_size=32,  # evaluation batch size\n",
        "    logging_steps=50,             # evaluate, log and save model checkpoints every 1000 step\n",
        "    # save_steps=1000,\n",
        "    # load_best_model_at_end=True,  # whether to load the best model (in terms of loss) at the end of training\n",
        "    # save_total_limit=3,           # whether you don't have much space so you let only 3 model weights saved in the disk\n",
        "    report_to=\"wandb\"              # for ploting loss curve\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2dGNyophIwM",
        "outputId": "0d411f31-8d23-4f81-eeed-633e354200d7"
      },
      "id": "K2dGNyophIwM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 50\n",
            "PyTorch: setting up devices\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for num in [2,4,6]:\n",
        "  bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "  model_path = \"drive/MyDrive/nlp/pretrained-bert\"\n",
        "\n",
        "  # the encode function will depend on the truncate_longer_samples variable\n",
        "  encode = encode_with_truncation if truncate_longer_samples else encode_without_truncation\n",
        "  # tokenizing the train dataset\n",
        "  train_dataset = d[\"train\"].map(encode, batched=True)\n",
        "  # tokenizing the testing dataset\n",
        "  test_dataset = d[\"test\"].map(encode, batched=True)\n",
        "  if truncate_longer_samples:\n",
        "      # remove other columns and set input_ids and attention_mask as PyTorch tensors\n",
        "      train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "      test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "  else:\n",
        "      # remove other columns, and remain them as Python lists\n",
        "      test_dataset.set_format(columns=[\"input_ids\", \"attention_mask\"])\n",
        "      train_dataset.set_format(columns=[\"input_ids\", \"attention_mask\"])\n",
        "\n",
        "  if not truncate_longer_samples:\n",
        "      train_dataset = train_dataset.map(group_texts, batched=True,\n",
        "                                      desc=f\"Grouping texts in chunks of {max_length}\")\n",
        "      test_dataset = test_dataset.map(group_texts, batched=True,\n",
        "                                    desc=f\"Grouping texts in chunks of {max_length}\")\n",
        "      # convert them from lists to torch tensors\n",
        "      train_dataset.set_format(\"torch\")\n",
        "      test_dataset.set_format(\"torch\")\n",
        "\n",
        "  # initialize the model with the config\n",
        "  model_config = BertConfig(vocab_size=vocab_size, max_position_embeddings=max_length,num_attention_heads = num)\n",
        "  model = BertForMaskedLM(config=model_config)\n",
        "  # masking data\n",
        "  data_collator = DataCollatorForLanguageModeling(\n",
        "      tokenizer=bert_tokenizer, mlm=True, mlm_probability=0.2\n",
        "  )\n",
        "\n",
        "  # initialize the trainer and pass everything to it\n",
        "  trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      data_collator=data_collator,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=test_dataset,\n",
        "  )\n",
        "\n",
        "  # train the model\n",
        "  trainer.train()\n",
        "\n",
        "# # post-training analysis, testing, other logged code\n",
        "# wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "df906bccf6454bc6b74a830ed813d149",
            "bbfab18faad448118f8074ba7cca3530",
            "5a44a80bc11042c9b8645c5a2e0240d0",
            "576a59290257482dbcb9ed2adc36017a",
            "41883a26218042f08a7e56008c0fe8f6",
            "e62ba4046b4d4c2db191a99588fca4a7",
            "82c6557a1c23467c97b7496d8ae97ae3",
            "e78793ea9e4a4c59a1d585e0336f557f",
            "024165ad30fe4990b4fabd7a9bd0bd5e",
            "facd27ed7c1f47a4ab534574bced4631",
            "0fd26ef36b704a81a839bff1b22266a2"
          ]
        },
        "id": "unQF7Ms5fH0K",
        "outputId": "460c372b-d679-4a0e-c148-edadcb463fb2"
      },
      "id": "unQF7Ms5fH0K",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7825f0c8f3143c3e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-fb86491b1b4e65eb.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df906bccf6454bc6b74a830ed813d149"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 2622\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 82\n",
            "  Number of trainable parameters = 109514298\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkalinajazdzyk\u001b[0m (\u001b[33mnlp_k\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221203_080511-2bh5zx0a</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/nlp_k/huggingface/runs/2bh5zx0a\" target=\"_blank\">drive/MyDrive/nlp/pretrained-bert</a></strong> to <a href=\"https://wandb.ai/nlp_k/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [82/82 04:36, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>8.724800</td>\n",
              "      <td>8.135065</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7825f0c8f3143c3e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-fb86491b1b4e65eb.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7825f0c8f3143c3e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-975f23f3a1f75743.arrow\n",
            "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 2622\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 82\n",
            "  Number of trainable parameters = 109514298\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [82/82 04:42, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>8.639500</td>\n",
              "      <td>8.056652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7825f0c8f3143c3e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-fb86491b1b4e65eb.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7825f0c8f3143c3e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-975f23f3a1f75743.arrow\n",
            "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 2622\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 82\n",
            "  Number of trainable parameters = 109514298\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [82/82 04:45, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>8.640700</td>\n",
              "      <td>8.057430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7825f0c8f3143c3e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-fb86491b1b4e65eb.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7825f0c8f3143c3e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-975f23f3a1f75743.arrow\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ece6bd7efbdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;31m# initialize the model with the config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_position_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_attention_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForMaskedLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# initialize the data collator, randomly masking 20% (default is 15%) of the tokens for the Masked Language\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             )\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_pooling_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertOnlyMLMHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertPooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0madd_pooling_layer\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBertLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBertLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cross_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cross_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, position_embedding_type)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_embedding_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertSelfAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_embedding_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_embedding_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertSelfOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruned_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, position_embedding_type)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"embedding_size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0;34mf\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;34mf\"heads ({config.num_attention_heads})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The hidden size (768) is not a multiple of the number of attention heads (10)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Num of attention head | Validation loss\n",
        "--- | ---\n",
        "2 | 8.135065\n",
        "4 | 8.056652\n",
        "6 | 8.057430\n",
        "12 | 7.033569\n",
        "\n",
        "Increasing the num of attention head will increase the model accuracy and performence. Due to long trainig the experiments were performed only on one epoch.\n",
        "\n"
      ],
      "metadata": {
        "id": "vBUOFDoKQv4t"
      },
      "id": "vBUOFDoKQv4t"
    },
    {
      "cell_type": "markdown",
      "source": [
        "hidden dimension:"
      ],
      "metadata": {
        "id": "cWNdV7UM0tTi"
      },
      "id": "cWNdV7UM0tTi"
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=model_path,          # output directory to where save model checkpoint\n",
        "    evaluation_strategy=\"steps\",    # evaluate each `logging_steps` steps\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=2,            # number of training epochs, feel free to tweak\n",
        "    per_device_train_batch_size=4, # the training batch size, put it as high as your GPU memory fits\n",
        "    gradient_accumulation_steps=8,  # accumulating the gradients before updating the weights\n",
        "    per_device_eval_batch_size=32,  # evaluation batch size\n",
        "    logging_steps=50,             # evaluate, log and save model checkpoints every 1000 step\n",
        "    # save_steps=1000,\n",
        "    # load_best_model_at_end=True,  # whether to load the best model (in terms of loss) at the end of training\n",
        "    # save_total_limit=3,           # whether you don't have much space so you let only 3 model weights saved in the disk\n",
        "    report_to=\"wandb\"              # for ploting loss curve\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWjWk-wI0ssX",
        "outputId": "98cfc223-2c64-4d8b-a47e-b41358235e22"
      },
      "id": "EWjWk-wI0ssX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 50\n",
            "PyTorch: setting up devices\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "# # 30,522 vocab is BERT's default vocab size, feel free to tweak\n",
        "# vocab_size = 30_522\n",
        "# # maximum sequence length, lowering will result to faster training (when increasing batch size)\n",
        "# max_length = 512\n",
        "# # whether to truncate\n",
        "# truncate_longer_samples = True\n",
        "\n",
        "# # the encode function will depend on the truncate_longer_samples variable\n",
        "# encode = encode_with_truncation if truncate_longer_samples else encode_without_truncation\n",
        "# # tokenizing the train dataset\n",
        "# train_dataset = d[\"train\"].map(encode, batched=True)\n",
        "# # tokenizing the testing dataset\n",
        "# test_dataset = d[\"test\"].map(encode, batched=True)\n",
        "# if truncate_longer_samples:\n",
        "#     # remove other columns and set input_ids and attention_mask as PyTorch tensors\n",
        "#     train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "#     test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "# else:\n",
        "#     # remove other columns, and remain them as Python lists\n",
        "#     test_dataset.set_format(columns=[\"input_ids\", \"attention_mask\"])\n",
        "#     train_dataset.set_format(columns=[\"input_ids\", \"attention_mask\"])\n",
        "\n",
        "# if not truncate_longer_samples:\n",
        "#     train_dataset = train_dataset.map(group_texts, batched=True,\n",
        "#                                     desc=f\"Grouping texts in chunks of {max_length}\")\n",
        "#     test_dataset = test_dataset.map(group_texts, batched=True,\n",
        "#                                   desc=f\"Grouping texts in chunks of {max_length}\")\n",
        "#     # convert them from lists to torch tensors\n",
        "#     train_dataset.set_format(\"torch\")\n",
        "#     test_dataset.set_format(\"torch\")\n"
      ],
      "metadata": {
        "id": "t7suohgT2Ow3"
      },
      "id": "t7suohgT2Ow3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ZRSFJIw2_vol"
      },
      "id": "ZRSFJIw2_vol",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for hid_size in [144,240,480]:\n",
        "  # initialize the model with the config\n",
        "  model_config = BertConfig(vocab_size=vocab_size, max_position_embeddings=max_length, hidden_size = hid_size)\n",
        "  model = BertForMaskedLM(config=model_config)\n",
        "\n",
        "  data_collator = DataCollatorForLanguageModeling(\n",
        "      tokenizer=bert_tokenizer, mlm=True, mlm_probability=0.2\n",
        "  )\n",
        "\n",
        "  # initialize the trainer and pass everything to it\n",
        "  trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      data_collator=data_collator,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=test_dataset,\n",
        "  )\n",
        "\n",
        "  # train the model\n",
        "  trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AB9NPdCYiMfF",
        "outputId": "bec6f33b-2abc-4c98-b64b-be398e552d82"
      },
      "id": "AB9NPdCYiMfF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 2622\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 164\n",
            "  Number of trainable parameters = 16185738\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [164/164 03:55, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>9.982400</td>\n",
              "      <td>9.799538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>9.690800</td>\n",
              "      <td>9.590857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>9.539700</td>\n",
              "      <td>9.499054</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 2622\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 164\n",
            "  Number of trainable parameters = 28060266\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [164/164 04:33, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>9.740000</td>\n",
              "      <td>9.439717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>9.260200</td>\n",
              "      <td>9.095019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>9.015500</td>\n",
              "      <td>8.949517</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 2622\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 164\n",
            "  Number of trainable parameters = 61697946\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [164/164 07:11, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>9.149400</td>\n",
              "      <td>8.608430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>8.298400</td>\n",
              "      <td>8.031805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>7.899700</td>\n",
              "      <td>7.804163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text, special_tokens_mask, title. If text, special_tokens_mask, title are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden dimension size | Validation loss (final) | Number of trainable parameters\n",
        "--- | --- | ---\n",
        "144 | 9.499054 |16185738\n",
        "240 | 8.949517 |28060266\n",
        "480 | 7.804163 |61697946\n",
        "\n",
        "Hidden dimension size is clearly correlated to the size of a whole model so increasing this parameter will give us better performance of course it will also slow down trainig significantly."
      ],
      "metadata": {
        "id": "n73AdLAXSKxr"
      },
      "id": "n73AdLAXSKxr"
    },
    {
      "cell_type": "markdown",
      "id": "3225de77",
      "metadata": {
        "id": "3225de77"
      },
      "source": [
        "## Problem 2.3 (4 points) - BERT vs RoBERTa\n",
        "Identifiy the key similarities and differences between the BERT and RoBERTa language models and discuss how these contribute to RoBERTa being a stronger language model\n",
        "\n",
        "* [BERT](https://aclanthology.org/N19-1423.pdf)\n",
        "* [RoBERTa](https://arxiv.org/abs/1907.11692)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2b62a84",
      "metadata": {
        "id": "b2b62a84"
      },
      "source": [
        "The preapering for masking is different between those two models. In BERT model masking is performed only once during the data preparation and RoBERTa is masking during the training proces. We can have multiple verions of masking sentence since it's not prepared before. That's why RoBERTa is more robust, it's not bounted by the static masks like BERT. RoBERTa removes the Next Sentence Prediction (NSP) task from BERT’s pre-training. RoBERTa also uses more data as it was trained on BERT data plus some additional text data.\n",
        "\n",
        "\n",
        "Both model has teh same key task which is masked language model task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cbea40d",
      "metadata": {
        "id": "9cbea40d"
      },
      "source": [
        "# Problem 3 - Sequence-to-sequence-language models (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7421423a",
      "metadata": {
        "id": "7421423a"
      },
      "source": [
        "## Problem 3.1 (4 points) - seq2seq LM training objective\n",
        "Compare the pre-training objectives listed in the [BART](https://aclanthology.org/2020.acl-main.703.pdf) paper and give examples of model inputs and outputs. With these pre-training objectives, compare their effects on downstream NLP tasks.\n",
        "\n",
        "Note: coding is not required for this question"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89b9abfa",
      "metadata": {
        "id": "89b9abfa"
      },
      "source": [
        "BERT contains an additional part in it's architecture a decoder. In some articles we can find the sentence that the BART model is considered to be the BERT model plus an autoregressive Decoder.  \n",
        "As a result of having a Decoder the BART model has more flexibility in how it can formulate the pre-training objectives.\n",
        "The high-level overview of how BART is trained is as follows. 1) Corrupt the input sentence. 2) Encode it with BERT. 3) Decode the BERT output 4) Compare decoding to ground truth sentence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebab868b",
      "metadata": {
        "id": "ebab868b"
      },
      "source": [
        "## Problem 3.2 (6 points) - Infilling Language Model\n",
        "Using the provided data, train a language model with the [BART](https://aclanthology.org/2020.acl-main.703.pdf) **text infilling** objective (other types of pre-training objectives are not reuqired). Select appropriate model size and hyperparameters.\n",
        "\n",
        "* Make the training data yourself\n",
        "\n",
        "* Print a sample of training instances (both the model inputs and expected outputs)\n",
        "\n",
        "* Plot the loss regularly (e.g. after an epoch or fixed number of training steps). Report the loss for both the training data and validation data\n",
        "\n",
        "* Use the `transformers` library implementation of a suitable tokenizer and model for language modelling with BART. But do not use a pre-trained language model (i.e. start with a randomly initialized model).  \n",
        "\n",
        "* It is only required to show convergence of your model for a few epochs\n",
        "\n",
        "Hint: you can sample sequence lengths from the Poisson distribution using the random library in [Numpy](https://numpy.org/doc/stable/reference/random/generated/numpy.random.poisson.html).  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from torch import nn\n",
        "import json\n",
        "from nltk import word_tokenize\n",
        "from collections import defaultdict, Counter\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "from datasets import *\n",
        "from transformers import *\n",
        "from tokenizers import *\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import nltk"
      ],
      "metadata": {
        "id": "dZJCn_SRKeZG"
      },
      "id": "dZJCn_SRKeZG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from transformers import BartTokenizer, BartConfig, BartModel"
      ],
      "metadata": {
        "id": "ZS5JNHM7KDgM"
      },
      "id": "ZS5JNHM7KDgM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bart_tokenizer =  AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") #BartTokenizer.from_pretrained(\"facebook/bart-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV7ZHhQwt-4i",
        "outputId": "b445e317-a8ca-43bf-8c35-48a4cdeadca9"
      },
      "id": "VV7ZHhQwt-4i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from https://www.thepythoncode.com/article/pretraining-bert-huggingface-transformers-in-python\n",
        "def encode_with_truncation(examples):\n",
        "    \"\"\"Mapping function to tokenize the sentences passed with truncation\"\"\"\n",
        "    return bart_tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\",\n",
        "                   max_length=max_length)\n"
      ],
      "metadata": {
        "id": "sfMPimOg7vyk"
      },
      "id": "sfMPimOg7vyk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [\"drive/MyDrive/nlp/wiki.jsonl\"]\n",
        "model_path = \"drive/MyDrive/nlp/pretrained-bart\"\n",
        "\n",
        "vocab_size = 30522\n",
        "\n",
        "max_length = 512 #1024\n",
        "\n",
        "# tokenizing the train dataset\n",
        "train_dataset = d[\"train\"].map(encode_with_truncation, batched=True)\n",
        "# tokenizing the testing dataset\n",
        "test_dataset = d[\"test\"].map(encode_with_truncation, batched=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "2a69322eb8274c7aa8280d77167023fb",
            "0df2d23f382b40a6844a1d2b21bed0cb",
            "d489020e43e5462f980356dd3c368c0e",
            "a515d5f9d58048808f83373600e76a37",
            "3113df99cc694e40ba7f3e99825dcdc4",
            "5507d8103ded431899c2f4b972cfb5c8",
            "7da5a200e61e481492be77fbe0c65ea1",
            "66363a90b0c04679b539dee9ea63e722",
            "e19ed20d008746938e6ae4cc7b5ad6d1",
            "133777ecf837469c8ea54f4acb36c832",
            "5618f2669ae744b39cd1774edb7a0af7",
            "48bc621dc2c349fba337f29d8f6d2e2a",
            "0923da5a069a41f98bfdf80d94950b94",
            "875db4b4dc1c4148b111fc2c29a69f47",
            "bbca0941c72a4ac8bccc734471ad9885",
            "fdd1b99cf1984c8b905c493de9a4a8e1",
            "3cd46c2c043d4edab6b6ac76a279cb2c",
            "44d6894cb4654787a9012c810a1b4967",
            "0a6973bb62584d7e8704ae20b194b3fe",
            "48047aae221043779f882c5ac03d6c31",
            "f02cd38108674a7a8ef0e9639f8224a5",
            "21e3144528914a56bd31ba29250ba884"
          ]
        },
        "id": "WGwY3qJZ_D1I",
        "outputId": "9d033944-5c77-4e37-c5e6-b9b4d2784ccf"
      },
      "id": "WGwY3qJZ_D1I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a69322eb8274c7aa8280d77167023fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48bc621dc2c349fba337f29d8f6d2e2a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
      ],
      "metadata": {
        "id": "yzS73Q2V-7xE"
      },
      "id": "yzS73Q2V-7xE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=model_path,          # output directory to where save model checkpoint\n",
        "    evaluation_strategy=\"steps\",    # evaluate each `logging_steps` steps\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=2,            # number of training epochs, feel free to tweak\n",
        "    per_device_train_batch_size=4, # the training batch size, put it as high as your GPU memory fits\n",
        "    gradient_accumulation_steps=8,  # accumulating the gradients before updating the weights\n",
        "    per_device_eval_batch_size=32,  # evaluation batch size\n",
        "    logging_steps=50,             # evaluate, log and save model checkpoints every 1000 step\n",
        "    save_steps=50,\n",
        "    # load_best_model_at_end=True,  # whether to load the best model (in terms of loss) at the end of training\n",
        "    save_total_limit=1,           # whether you don't have much space so you let only 3 model weights saved in the disk\n",
        "    debug=\"underflow_overflow\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2TocjbCLn0E",
        "outputId": "08c35e52-9ad2-480c-9a59-476dd7037f44"
      },
      "id": "b2TocjbCLn0E",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 50\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model with the config\n",
        "model_config = BartConfig(vocab_size=vocab_size, max_position_embeddings=max_length)\n",
        "model = model = BartForConditionalGeneration(config=model_config) #BartModel(config=model_config)\n",
        "\n",
        "# initialize the data collator, randomly masking 20% (default is 15%) of the tokens for the Masked Language\n",
        "# Modeling (MLM) task\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=bart_tokenizer, mlm=True, mlm_probability=0.2\n",
        ")\n"
      ],
      "metadata": {
        "id": "R6cm6XHu-Lgb"
      },
      "id": "R6cm6XHu-Lgb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the trainer and pass everything to it\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "JfoBjtEdNbse",
        "outputId": "0ab7a008-a6d4-4a7d-9326-13e39071c13f"
      },
      "id": "JfoBjtEdNbse",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: text, title. If text, title are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 2622\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 164\n",
            "  Number of trainable parameters = 385026048\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [164/164 47:33, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>8.159500</td>\n",
              "      <td>7.537156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>7.390700</td>\n",
              "      <td>7.353963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>7.302900</td>\n",
              "      <td>7.313214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: text, title. If text, title are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: text, title. If text, title are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: text, title. If text, title are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=164, training_loss=7.588349412127239, metrics={'train_runtime': 2869.529, 'train_samples_per_second': 1.827, 'train_steps_per_second': 0.057, 'total_flos': 5682148266737664.0, 'train_loss': 7.588349412127239, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the trainer and pass everything to it\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "kjROvehnmE8p",
        "outputId": "948939ed-62b9-431d-aa31-ca8c3dbb910e"
      },
      "id": "kjROvehnmE8p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: text, title. If text, title are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 2622\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 164\n",
            "  Number of trainable parameters = 385026048\n",
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [164/164 48:36, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>8.166100</td>\n",
              "      <td>7.546317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>7.404300</td>\n",
              "      <td>7.341160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>7.298800</td>\n",
              "      <td>7.329587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: text, title. If text, title are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to drive/MyDrive/nlp/pretrained-bart/checkpoint-50\n",
            "Configuration saved in drive/MyDrive/nlp/pretrained-bart/checkpoint-50/config.json\n",
            "Model weights saved in drive/MyDrive/nlp/pretrained-bart/checkpoint-50/pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: text, title. If text, title are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to drive/MyDrive/nlp/pretrained-bart/checkpoint-100\n",
            "Configuration saved in drive/MyDrive/nlp/pretrained-bart/checkpoint-100/config.json\n",
            "Model weights saved in drive/MyDrive/nlp/pretrained-bart/checkpoint-100/pytorch_model.bin\n",
            "Deleting older checkpoint [drive/MyDrive/nlp/pretrained-bart/checkpoint-50] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: text, title. If text, title are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 292\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to drive/MyDrive/nlp/pretrained-bart/checkpoint-150\n",
            "Configuration saved in drive/MyDrive/nlp/pretrained-bart/checkpoint-150/config.json\n",
            "Model weights saved in drive/MyDrive/nlp/pretrained-bart/checkpoint-150/pytorch_model.bin\n",
            "Deleting older checkpoint [drive/MyDrive/nlp/pretrained-bart/checkpoint-100] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=164, training_loss=7.594940650753859, metrics={'train_runtime': 2932.8253, 'train_samples_per_second': 1.788, 'train_steps_per_second': 0.056, 'total_flos': 5682148266737664.0, 'train_loss': 7.594940650753859, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python program to read\n",
        "# json file\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "# Opening JSON file\n",
        "f = open(\"drive/MyDrive/nlp/pretrained-bart/checkpoint-150/trainer_state.json\")\n",
        "train_loss = []\n",
        "# returns JSON object as\n",
        "# a dictionary\n",
        "data = json.load(f)\n",
        "for i in data['log_history']:\n",
        "  try:\n",
        "    print(i['eval_loss'])\n",
        "    train_loss.append(i['eval_loss'])\n",
        "  except:\n",
        "    pass\n",
        "# Closing file\n",
        "f.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr2GHSTcBWSw",
        "outputId": "8cac13aa-420e-462b-a69c-00ac15df6ab6"
      },
      "id": "Gr2GHSTcBWSw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.546317100524902\n",
            "7.341159820556641\n",
            "7.329587459564209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pylab import plt\n",
        "from numpy import arange\n",
        "\n",
        "# Generate a sequence of integers to represent the epoch numbers\n",
        "epochs = range(1,4)\n",
        "\n",
        "# Plot and label the training and validation loss values\n",
        "plt.plot(epochs, train_loss, label='Validation Loss')\n",
        "\n",
        "# Add in a title and axes labels\n",
        "plt.title('Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Display the plot\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "evtbuAzfBs5E",
        "outputId": "6bfd131a-adba-4912-cd92-1d82627eb1bd"
      },
      "id": "evtbuAzfBs5E",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ad22ffc73d94051b43acea8382df344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5684dd020604f7286bb1ed4ac2f1d8f",
              "IPY_MODEL_078b11ec8b4d404fab4c33146140b7a4",
              "IPY_MODEL_640766c1360b49b7b7dd5cbfc07f33b4"
            ],
            "layout": "IPY_MODEL_b61d87fb1d5f46e1bac69b67d8e4a809"
          }
        },
        "f5684dd020604f7286bb1ed4ac2f1d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca3f0a21344748d0934d61872f602e56",
            "placeholder": "​",
            "style": "IPY_MODEL_3e89a647bbbf4884b5df6364ae672336",
            "value": "100%"
          }
        },
        "078b11ec8b4d404fab4c33146140b7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b34ace5395944a3d9341f8f2c66a29b5",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b33d0a9dc15a461a974f0faf85cb20de",
            "value": 3
          }
        },
        "640766c1360b49b7b7dd5cbfc07f33b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78a266b15cbd4c4c8c593beaf624b0b7",
            "placeholder": "​",
            "style": "IPY_MODEL_98b380c8395f49378fa975334b584348",
            "value": " 3/3 [00:54&lt;00:00, 16.64s/ba]"
          }
        },
        "b61d87fb1d5f46e1bac69b67d8e4a809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3f0a21344748d0934d61872f602e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e89a647bbbf4884b5df6364ae672336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b34ace5395944a3d9341f8f2c66a29b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b33d0a9dc15a461a974f0faf85cb20de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78a266b15cbd4c4c8c593beaf624b0b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b380c8395f49378fa975334b584348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2e1ed8150704273943f25c81553ef39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_145c50a9763c4d3e95f294c531660af5",
              "IPY_MODEL_0c2dda271bfd439285f2d81aba68c541",
              "IPY_MODEL_3b5084748ca44faba05244bec047f8d3"
            ],
            "layout": "IPY_MODEL_70a6af54a8934bed91d0dfb098365a49"
          }
        },
        "145c50a9763c4d3e95f294c531660af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3da46f793ced4abca13472f9ea767ac7",
            "placeholder": "​",
            "style": "IPY_MODEL_659f9071586941bea3f2384ee7e58f11",
            "value": "100%"
          }
        },
        "0c2dda271bfd439285f2d81aba68c541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ed3e73492a54d42961e51415f00eaa8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5635808d3814a2f87734571f678b107",
            "value": 1
          }
        },
        "3b5084748ca44faba05244bec047f8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83dc6cee2fbf4039a59fd7a9c72a10aa",
            "placeholder": "​",
            "style": "IPY_MODEL_183dad64294947968337130117adb99c",
            "value": " 1/1 [00:04&lt;00:00,  4.24s/ba]"
          }
        },
        "70a6af54a8934bed91d0dfb098365a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3da46f793ced4abca13472f9ea767ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "659f9071586941bea3f2384ee7e58f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ed3e73492a54d42961e51415f00eaa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5635808d3814a2f87734571f678b107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83dc6cee2fbf4039a59fd7a9c72a10aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "183dad64294947968337130117adb99c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df906bccf6454bc6b74a830ed813d149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbfab18faad448118f8074ba7cca3530",
              "IPY_MODEL_5a44a80bc11042c9b8645c5a2e0240d0",
              "IPY_MODEL_576a59290257482dbcb9ed2adc36017a"
            ],
            "layout": "IPY_MODEL_41883a26218042f08a7e56008c0fe8f6"
          }
        },
        "bbfab18faad448118f8074ba7cca3530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e62ba4046b4d4c2db191a99588fca4a7",
            "placeholder": "​",
            "style": "IPY_MODEL_82c6557a1c23467c97b7496d8ae97ae3",
            "value": "100%"
          }
        },
        "5a44a80bc11042c9b8645c5a2e0240d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e78793ea9e4a4c59a1d585e0336f557f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_024165ad30fe4990b4fabd7a9bd0bd5e",
            "value": 1
          }
        },
        "576a59290257482dbcb9ed2adc36017a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_facd27ed7c1f47a4ab534574bced4631",
            "placeholder": "​",
            "style": "IPY_MODEL_0fd26ef36b704a81a839bff1b22266a2",
            "value": " 1/1 [00:04&lt;00:00,  4.17s/ba]"
          }
        },
        "41883a26218042f08a7e56008c0fe8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e62ba4046b4d4c2db191a99588fca4a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82c6557a1c23467c97b7496d8ae97ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e78793ea9e4a4c59a1d585e0336f557f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "024165ad30fe4990b4fabd7a9bd0bd5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "facd27ed7c1f47a4ab534574bced4631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd26ef36b704a81a839bff1b22266a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "965a3bc2e6004536b87096dc2440cadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0dfebd69a5c482f83b0a992ff6b9945",
              "IPY_MODEL_4102dd376af34b4aaff56e6893d7b0de",
              "IPY_MODEL_7df6cfd6efbd4febba796d248cd995a8"
            ],
            "layout": "IPY_MODEL_407628bc09bb436c97db177e59819b24"
          }
        },
        "e0dfebd69a5c482f83b0a992ff6b9945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b29aed98ccbb4b949734ad8ffbc9bfbb",
            "placeholder": "​",
            "style": "IPY_MODEL_de150e41e08a4fecafced2d69815fb80",
            "value": "Downloading: 100%"
          }
        },
        "4102dd376af34b4aaff56e6893d7b0de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eb44cadf64f4ccab86272f31a9ccc52",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06951032226c4ba1be372fbaedf36aff",
            "value": 28
          }
        },
        "7df6cfd6efbd4febba796d248cd995a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceaf2151eebd437c8d107aca8678a2bb",
            "placeholder": "​",
            "style": "IPY_MODEL_c61643c98a79490696676479260dd7bf",
            "value": " 28.0/28.0 [00:00&lt;00:00, 820B/s]"
          }
        },
        "407628bc09bb436c97db177e59819b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b29aed98ccbb4b949734ad8ffbc9bfbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de150e41e08a4fecafced2d69815fb80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3eb44cadf64f4ccab86272f31a9ccc52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06951032226c4ba1be372fbaedf36aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ceaf2151eebd437c8d107aca8678a2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c61643c98a79490696676479260dd7bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcde37bc306542ea9108f496668e23f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8f8cc18b8e94bfda18d21e3a3f38ac8",
              "IPY_MODEL_1537907694084a3d837c896b3ac2d7ae",
              "IPY_MODEL_d1a340a20aa246d8900edfb141e0f127"
            ],
            "layout": "IPY_MODEL_cf98c2062f8a490d9377f5060674ca14"
          }
        },
        "a8f8cc18b8e94bfda18d21e3a3f38ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_354a4f9610064a27b7bc0af9028e8a14",
            "placeholder": "​",
            "style": "IPY_MODEL_4af826a8fda84722b90281837f0bfcdf",
            "value": "Downloading: 100%"
          }
        },
        "1537907694084a3d837c896b3ac2d7ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fb8891131284fc689101ce697738754",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d6da47868384332a957757117add452",
            "value": 570
          }
        },
        "d1a340a20aa246d8900edfb141e0f127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_716723626ea644de8d4341b0f7db111b",
            "placeholder": "​",
            "style": "IPY_MODEL_5e71f650631b4aa7b20d8fe3ff59ff43",
            "value": " 570/570 [00:00&lt;00:00, 20.0kB/s]"
          }
        },
        "cf98c2062f8a490d9377f5060674ca14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "354a4f9610064a27b7bc0af9028e8a14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4af826a8fda84722b90281837f0bfcdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fb8891131284fc689101ce697738754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6da47868384332a957757117add452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "716723626ea644de8d4341b0f7db111b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e71f650631b4aa7b20d8fe3ff59ff43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8b01ef72bea4eb68742b44a7ef0ed77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc84b37d04c144608544a26ab3a41989",
              "IPY_MODEL_4331bf6aa3d44ac2aef08f2d9333205e",
              "IPY_MODEL_fd15027eff234730b1e58a64a63cf068"
            ],
            "layout": "IPY_MODEL_6a88780aa662459781070dc10f8f924d"
          }
        },
        "cc84b37d04c144608544a26ab3a41989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e4c54d9d33d4a8393b0ad5ea4e5e84e",
            "placeholder": "​",
            "style": "IPY_MODEL_1e55f3783676438689c50e3426ee5757",
            "value": "Downloading: 100%"
          }
        },
        "4331bf6aa3d44ac2aef08f2d9333205e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_570b7e2a420b486a89b7fd460aa3c98a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75dd256da3204c449a4cb84552796a8a",
            "value": 231508
          }
        },
        "fd15027eff234730b1e58a64a63cf068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adece1b0a16d4aaa86fda120bbf98882",
            "placeholder": "​",
            "style": "IPY_MODEL_d2f0055eb85f4598a25c87575745bf0e",
            "value": " 232k/232k [00:00&lt;00:00, 1.38MB/s]"
          }
        },
        "6a88780aa662459781070dc10f8f924d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e4c54d9d33d4a8393b0ad5ea4e5e84e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e55f3783676438689c50e3426ee5757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "570b7e2a420b486a89b7fd460aa3c98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75dd256da3204c449a4cb84552796a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adece1b0a16d4aaa86fda120bbf98882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2f0055eb85f4598a25c87575745bf0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5676f8c6052643a884b9ee1021762c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7792d13d256f4af4a0b131f7e806effe",
              "IPY_MODEL_04ca75419cc24ab5a0c428cd3f8d2bb7",
              "IPY_MODEL_f4fb010216cd4e0cbdc3b66c2d772ff2"
            ],
            "layout": "IPY_MODEL_4fd329328c2349658123e3e9484b652f"
          }
        },
        "7792d13d256f4af4a0b131f7e806effe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e8cb8e2beab4f28b8fd266b4239bf29",
            "placeholder": "​",
            "style": "IPY_MODEL_3b54139ff01a4bce88033b456603b8b6",
            "value": "Downloading: 100%"
          }
        },
        "04ca75419cc24ab5a0c428cd3f8d2bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae864b6fe330406bb7a426b523a1dc0f",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c14b860d47a44b8beb97fd08e3bee38",
            "value": 466062
          }
        },
        "f4fb010216cd4e0cbdc3b66c2d772ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_040517e19e8c4f20bd7d3b6686c285d7",
            "placeholder": "​",
            "style": "IPY_MODEL_0e287a5900b840008887b95f8d1fd3e0",
            "value": " 466k/466k [00:00&lt;00:00, 1.67MB/s]"
          }
        },
        "4fd329328c2349658123e3e9484b652f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e8cb8e2beab4f28b8fd266b4239bf29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b54139ff01a4bce88033b456603b8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae864b6fe330406bb7a426b523a1dc0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c14b860d47a44b8beb97fd08e3bee38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "040517e19e8c4f20bd7d3b6686c285d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e287a5900b840008887b95f8d1fd3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74a9a3f7ea0b412ebda8dc0fd775c0e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea5a5c1544f344e5bbbe8970e9cf480d",
              "IPY_MODEL_ca7b8613e824480d905bb1328166cbf0",
              "IPY_MODEL_1972370d9c134d7fb540ba64b3660440"
            ],
            "layout": "IPY_MODEL_d3fb8f60ab6344a1b83a23907db4f6fb"
          }
        },
        "ea5a5c1544f344e5bbbe8970e9cf480d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e13c39f071a4b238f091ad6aa3293c2",
            "placeholder": "​",
            "style": "IPY_MODEL_2c20c4900bc5480e8be5c9781c5699fd",
            "value": "100%"
          }
        },
        "ca7b8613e824480d905bb1328166cbf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6dbc5dea531493e8fe82b5c369e2621",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddaf6c5f182b480d87fa8b52cc916c3a",
            "value": 3
          }
        },
        "1972370d9c134d7fb540ba64b3660440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1b87bddee074717a9c72ef9e6b2625a",
            "placeholder": "​",
            "style": "IPY_MODEL_9c0224d3b7ba4bb9814f565203ab6795",
            "value": " 3/3 [00:41&lt;00:00, 12.80s/ba]"
          }
        },
        "d3fb8f60ab6344a1b83a23907db4f6fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e13c39f071a4b238f091ad6aa3293c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c20c4900bc5480e8be5c9781c5699fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6dbc5dea531493e8fe82b5c369e2621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddaf6c5f182b480d87fa8b52cc916c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1b87bddee074717a9c72ef9e6b2625a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c0224d3b7ba4bb9814f565203ab6795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50b7899050c1403e9fadc0ddf5171c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ac1344912d64370b94885abd7838d6e",
              "IPY_MODEL_ad0e0c374f254a0880f084b0f2926636",
              "IPY_MODEL_acb24e75f65c462aa1fc899527635b3d"
            ],
            "layout": "IPY_MODEL_213b44e16c384b0aad4039f926f3f340"
          }
        },
        "1ac1344912d64370b94885abd7838d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42f892a6c18a4aa39dff118ded73ffbb",
            "placeholder": "​",
            "style": "IPY_MODEL_ad8f602cfc4b4d8b913117548838c57d",
            "value": "100%"
          }
        },
        "ad0e0c374f254a0880f084b0f2926636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa96b053b164cbcb5387a14a0c4318a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc3ae126c4bd466ea83696b60a1ded37",
            "value": 1
          }
        },
        "acb24e75f65c462aa1fc899527635b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10c0553dba354eadad3a924d642a1049",
            "placeholder": "​",
            "style": "IPY_MODEL_f2e19180a5854c409d41badd8d6231e1",
            "value": " 1/1 [00:03&lt;00:00,  3.88s/ba]"
          }
        },
        "213b44e16c384b0aad4039f926f3f340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42f892a6c18a4aa39dff118ded73ffbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8f602cfc4b4d8b913117548838c57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfa96b053b164cbcb5387a14a0c4318a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc3ae126c4bd466ea83696b60a1ded37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10c0553dba354eadad3a924d642a1049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e19180a5854c409d41badd8d6231e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a69322eb8274c7aa8280d77167023fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0df2d23f382b40a6844a1d2b21bed0cb",
              "IPY_MODEL_d489020e43e5462f980356dd3c368c0e",
              "IPY_MODEL_a515d5f9d58048808f83373600e76a37"
            ],
            "layout": "IPY_MODEL_3113df99cc694e40ba7f3e99825dcdc4"
          }
        },
        "0df2d23f382b40a6844a1d2b21bed0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5507d8103ded431899c2f4b972cfb5c8",
            "placeholder": "​",
            "style": "IPY_MODEL_7da5a200e61e481492be77fbe0c65ea1",
            "value": "100%"
          }
        },
        "d489020e43e5462f980356dd3c368c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66363a90b0c04679b539dee9ea63e722",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e19ed20d008746938e6ae4cc7b5ad6d1",
            "value": 3
          }
        },
        "a515d5f9d58048808f83373600e76a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_133777ecf837469c8ea54f4acb36c832",
            "placeholder": "​",
            "style": "IPY_MODEL_5618f2669ae744b39cd1774edb7a0af7",
            "value": " 3/3 [00:43&lt;00:00, 12.95s/ba]"
          }
        },
        "3113df99cc694e40ba7f3e99825dcdc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5507d8103ded431899c2f4b972cfb5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da5a200e61e481492be77fbe0c65ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66363a90b0c04679b539dee9ea63e722": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e19ed20d008746938e6ae4cc7b5ad6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "133777ecf837469c8ea54f4acb36c832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5618f2669ae744b39cd1774edb7a0af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48bc621dc2c349fba337f29d8f6d2e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0923da5a069a41f98bfdf80d94950b94",
              "IPY_MODEL_875db4b4dc1c4148b111fc2c29a69f47",
              "IPY_MODEL_bbca0941c72a4ac8bccc734471ad9885"
            ],
            "layout": "IPY_MODEL_fdd1b99cf1984c8b905c493de9a4a8e1"
          }
        },
        "0923da5a069a41f98bfdf80d94950b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cd46c2c043d4edab6b6ac76a279cb2c",
            "placeholder": "​",
            "style": "IPY_MODEL_44d6894cb4654787a9012c810a1b4967",
            "value": "100%"
          }
        },
        "875db4b4dc1c4148b111fc2c29a69f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a6973bb62584d7e8704ae20b194b3fe",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48047aae221043779f882c5ac03d6c31",
            "value": 1
          }
        },
        "bbca0941c72a4ac8bccc734471ad9885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f02cd38108674a7a8ef0e9639f8224a5",
            "placeholder": "​",
            "style": "IPY_MODEL_21e3144528914a56bd31ba29250ba884",
            "value": " 1/1 [00:03&lt;00:00,  3.95s/ba]"
          }
        },
        "fdd1b99cf1984c8b905c493de9a4a8e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cd46c2c043d4edab6b6ac76a279cb2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d6894cb4654787a9012c810a1b4967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a6973bb62584d7e8704ae20b194b3fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48047aae221043779f882c5ac03d6c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f02cd38108674a7a8ef0e9639f8224a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21e3144528914a56bd31ba29250ba884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}