{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de66669d",
   "metadata": {},
   "source": [
    "# KAIST AI605 Assignment 5: Language Modelling\n",
    "\n",
    "## Rubric\n",
    "\n",
    "### Deadline \n",
    "The deadline for this assignment is: Friday 2nd December 2022 (Week 14) 11:59pm\n",
    "\n",
    "### Submission\n",
    "Please submit your assignment via [KLMS](https://klms.kaist.ac.kr). You must submit both (1) a PDF of your solutions and (2) the Jupyter Notebook file (.ipynb).\n",
    "\n",
    "Use in-line LaTeX for mathematical expressions. \n",
    "\n",
    "### Collaboration\n",
    "This assignment is not a group assignment so make sure your answer and code are your own. \n",
    "\n",
    "### Grading\n",
    "The total number of marks avaiable is 30 points.\n",
    "\n",
    "### Environment\n",
    "This assignment will mostly use the transformers library from huggingface.\n",
    "\n",
    "The use of a GPU will be beneficial for this assignment.\n",
    "\n",
    "If you do not have a GPU on your laptop, it is acceptable to use [Google Colab (free)](https://colab.research.google.com) or the departmental subscription of [VESSL](https://vessl.ai), \n",
    "**please contact me ASAP to be added if you are from a different department**.\n",
    "\n",
    "\n",
    "The required environment for this is Python 3.9. Run the following cell to set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d8ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy torch tqdm transformers matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37c986",
   "metadata": {},
   "source": [
    "# Problem 0 - Load The Data \n",
    "The data for Problems 1, 2 and 3 can be downloaded from KLMS. Each line in the file is an instance is a JSON dictioanary of a Wikipedia. For this assignment only the **text** field is required.\n",
    "\n",
    "* Reserve 10% of the pages for validation data\n",
    "* Use any other portion of the data for training\n",
    "\n",
    "`{\"title\": \"the title of the Wikipedia page\",  \"text\":\"the text in the Wikipedia page\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d1287085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b5946ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "from datasets import *\n",
    "from transformers import *\n",
    "from tokenizers import *\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "022a25c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data: 2914\n",
      "Train lenght: 2622\n",
      "Test lenght: 292\n"
     ]
    }
   ],
   "source": [
    "def load_instances(filename):\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            inst = json.loads(line)\n",
    "            text = inst['text']\n",
    "            yield word_tokenize(text)\n",
    "all_inst = list(load_instances(\"C:/Users/User/Desktop/NLP/ass5/wiki.jsonl\"))      \n",
    "# print(all_inst[0])\n",
    "n = len(all_inst)\n",
    "print(f'All data: {n}')\n",
    "train_instances, dev_instances = all_inst[:int(n*0.9)], all_inst[int(n*0.9):]\n",
    "print(f'Train lenght: {len(train_instances)}')\n",
    "print(f'Test lenght: {len(dev_instances)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849714ef",
   "metadata": {},
   "source": [
    "# Problem 1 - Features of Language (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee757d1",
   "metadata": {},
   "source": [
    "## Problem 1.1 (4 points) - Zipfs Law\n",
    "\n",
    "Zipfs law (introduced in Lecture 1) indicates a reverse exponential relationship between the frequency of a token $w$, $f_w$, and its rank of frequency $r_w$ (where rank is the position with respect to frequency in comparison to other words).\n",
    "\n",
    "$$\n",
    "f_w \\approx \\frac{k}{r_w^\\alpha}\n",
    "$$\n",
    "\n",
    "\n",
    "* Find the frequencies of all unique tokens in the dataset and rank them\n",
    "\n",
    "* Plot the frequency vs rank graph for the highest 10,000 ranked tokens with a log-log scale\n",
    "\n",
    "* Plot a line of best fit and estimate the values of $k$ and $\\alpha$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311af4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ('the', 869431),\n",
       " 2: (',', 858193),\n",
       " 3: ('.', 574493),\n",
       " 4: ('of', 477376),\n",
       " 5: ('and', 423298),\n",
       " 6: ('in', 319390),\n",
       " 7: ('to', 307820),\n",
       " 8: ('a', 264721),\n",
       " 9: ('was', 154621),\n",
       " 10: ('The', 131163),\n",
       " 11: (\"'s\", 115968),\n",
       " 12: ('that', 114943),\n",
       " 13: ('as', 114408),\n",
       " 14: (')', 113762),\n",
       " 15: ('(', 113746),\n",
       " 16: ('for', 102230),\n",
       " 17: ('``', 99072),\n",
       " 18: ('by', 97725),\n",
       " 19: ('with', 96947),\n",
       " 20: ('on', 95504),\n",
       " 21: ('is', 94711),\n",
       " 22: (\"''\", 93799),\n",
       " 23: ('from', 74246),\n",
       " 24: ('his', 67246),\n",
       " 25: ('were', 61886),\n",
       " 26: ('at', 60693),\n",
       " 27: ('it', 54504),\n",
       " 28: ('which', 49433),\n",
       " 29: ('had', 49041),\n",
       " 30: ('an', 48956),\n",
       " 31: ('are', 48228),\n",
       " 32: ('he', 45792),\n",
       " 33: (';', 43640),\n",
       " 34: ('be', 41782),\n",
       " 35: ('In', 40613),\n",
       " 36: (':', 38625),\n",
       " 37: ('have', 38461),\n",
       " 38: ('or', 35965),\n",
       " 39: ('not', 35631),\n",
       " 40: ('but', 34690),\n",
       " 41: ('been', 33255),\n",
       " 42: ('its', 32761),\n",
       " 43: ('their', 32222),\n",
       " 44: ('her', 28214),\n",
       " 45: ('also', 27907),\n",
       " 46: ('has', 27283),\n",
       " 47: ('this', 25112),\n",
       " 48: ('first', 24762),\n",
       " 49: ('they', 23334),\n",
       " 50: ('who', 23275),\n",
       " 51: ('one', 23269),\n",
       " 52: ('other', 23219),\n",
       " 53: ('more', 21693),\n",
       " 54: ('two', 20449),\n",
       " 55: ('than', 19694),\n",
       " 56: ('would', 19469),\n",
       " 57: ('into', 18929),\n",
       " 58: ('It', 18420),\n",
       " 59: ('after', 18384),\n",
       " 60: ('He', 17437),\n",
       " 61: ('A', 17055),\n",
       " 62: ('most', 16976),\n",
       " 63: ('such', 16863),\n",
       " 64: ('about', 16772),\n",
       " 65: ('time', 16105),\n",
       " 66: ('species', 15804),\n",
       " 67: ('when', 15734),\n",
       " 68: ('only', 15210),\n",
       " 69: ('between', 15120),\n",
       " 70: ('years', 14725),\n",
       " 71: ('she', 14533),\n",
       " 72: ('some', 14405),\n",
       " 73: ('all', 14327),\n",
       " 74: ('during', 13924),\n",
       " 75: ('used', 13814),\n",
       " 76: (\"'\", 13620),\n",
       " 77: ('I', 13517),\n",
       " 78: ('over', 13378),\n",
       " 79: ('him', 13298),\n",
       " 80: ('found', 13166),\n",
       " 81: ('later', 13126),\n",
       " 82: ('can', 12682),\n",
       " 83: ('may', 12641),\n",
       " 84: ('film', 12617),\n",
       " 85: ('new', 12399),\n",
       " 86: ('This', 12368),\n",
       " 87: ('while', 12129),\n",
       " 88: ('including', 12019),\n",
       " 89: ('work', 11912),\n",
       " 90: ('them', 11784),\n",
       " 91: ('New', 11674),\n",
       " 92: ('known', 11659),\n",
       " 93: ('made', 11648),\n",
       " 94: ('many', 11610),\n",
       " 95: ('there', 10987),\n",
       " 96: ('up', 10902),\n",
       " 97: ('where', 10768),\n",
       " 98: ('three', 10720),\n",
       " 99: ('no', 10702),\n",
       " 100: ('became', 10641),\n",
       " 101: ('these', 10610),\n",
       " 102: ('early', 10104),\n",
       " 103: ('both', 9977),\n",
       " 104: ('out', 9965),\n",
       " 105: ('could', 9769),\n",
       " 106: ('before', 9596),\n",
       " 107: ('being', 9558),\n",
       " 108: ('several', 9510),\n",
       " 109: ('through', 9306),\n",
       " 110: ('part', 9208),\n",
       " 111: ('did', 9096),\n",
       " 112: ('year', 9084),\n",
       " 113: ('large', 8845),\n",
       " 114: ('so', 8667),\n",
       " 115: ('well', 8544),\n",
       " 116: ('American', 8513),\n",
       " 117: ('then', 8499),\n",
       " 118: ('people', 8446),\n",
       " 119: ('United', 8300),\n",
       " 120: ('$', 7994),\n",
       " 121: ('began', 7844),\n",
       " 122: ('around', 7780),\n",
       " 123: ('use', 7756),\n",
       " 124: ('music', 7737),\n",
       " 125: ('because', 7692),\n",
       " 126: ('until', 7691),\n",
       " 127: ('million', 7687),\n",
       " 128: ('described', 7589),\n",
       " 129: ('wrote', 7571),\n",
       " 130: ('called', 7527),\n",
       " 131: ('under', 7522),\n",
       " 132: ('They', 7518),\n",
       " 133: ('century', 7502),\n",
       " 134: ('%', 7484),\n",
       " 135: ('same', 7449),\n",
       " 136: ('name', 7321),\n",
       " 137: ('John', 7274),\n",
       " 138: ('number', 7235),\n",
       " 139: ('On', 7196),\n",
       " 140: ('said', 7072),\n",
       " 141: ('those', 7005),\n",
       " 142: ('often', 6964),\n",
       " 143: ('area', 6944),\n",
       " 144: ('series', 6937),\n",
       " 145: ('small', 6915),\n",
       " 146: ('As', 6898),\n",
       " 147: (']', 6859),\n",
       " 148: ('[', 6857),\n",
       " 149: ('much', 6837),\n",
       " 150: ('any', 6823),\n",
       " 151: ('each', 6818),\n",
       " 152: ('family', 6817),\n",
       " 153: ('States', 6813),\n",
       " 154: ('long', 6661),\n",
       " 155: ('ISBN', 6633),\n",
       " 156: ('British', 6504),\n",
       " 157: ('–', 6499),\n",
       " 158: ('After', 6463),\n",
       " 159: ('published', 6455),\n",
       " 160: ('album', 6453),\n",
       " 161: ('London', 6266),\n",
       " 162: ('since', 6261),\n",
       " 163: ('...', 6229),\n",
       " 164: ('water', 6211),\n",
       " 165: ('group', 6192),\n",
       " 166: ('second', 6169),\n",
       " 167: ('although', 6157),\n",
       " 168: ('four', 6135),\n",
       " 169: ('life', 6114),\n",
       " 170: ('York', 6058),\n",
       " 171: ('She', 5937),\n",
       " 172: ('National', 5852),\n",
       " 173: ('like', 5842),\n",
       " 174: ('what', 5780),\n",
       " 175: ('high', 5761),\n",
       " 176: ('considered', 5760),\n",
       " 177: ('city', 5757),\n",
       " 178: ('September', 5747),\n",
       " 179: ('own', 5740),\n",
       " 180: ('death', 5736),\n",
       " 181: ('along', 5727),\n",
       " 182: ('within', 5681),\n",
       " 183: ('end', 5678),\n",
       " 184: ('if', 5646),\n",
       " 185: ('very', 5586),\n",
       " 186: ('m', 5569),\n",
       " 187: ('book', 5554),\n",
       " 188: ('University', 5533),\n",
       " 189: ('included', 5528),\n",
       " 190: ('against', 5513),\n",
       " 191: ('government', 5482),\n",
       " 192: ('state', 5462),\n",
       " 193: ('form', 5415),\n",
       " 194: ('near', 5377),\n",
       " 195: ('1', 5360),\n",
       " 196: ('now', 5355),\n",
       " 197: ('left', 5330),\n",
       " 198: ('due', 5328),\n",
       " 199: ('works', 5315),\n",
       " 200: ('took', 5300),\n",
       " 201: ('similar', 5286),\n",
       " 202: ('public', 5259),\n",
       " 203: ('following', 5253),\n",
       " 204: ('day', 5174),\n",
       " 205: ('common', 5166),\n",
       " 206: ('released', 5113),\n",
       " 207: ('based', 5088),\n",
       " 208: ('At', 5066),\n",
       " 209: ('period', 5049),\n",
       " 210: ('include', 5049),\n",
       " 211: ('late', 5027),\n",
       " 212: ('original', 5019),\n",
       " 213: ('do', 5013),\n",
       " 214: ('another', 5006),\n",
       " 215: ('October', 5002),\n",
       " 216: ('South', 4975),\n",
       " 217: ('among', 4971),\n",
       " 218: ('received', 4970),\n",
       " 219: ('set', 4969),\n",
       " 220: ('back', 4926),\n",
       " 221: ('North', 4889),\n",
       " 222: ('August', 4878),\n",
       " 223: ('even', 4864),\n",
       " 224: ('However', 4848),\n",
       " 225: ('few', 4834),\n",
       " 226: ('though', 4833),\n",
       " 227: ('band', 4809),\n",
       " 228: ('will', 4797),\n",
       " 229: ('These', 4782),\n",
       " 230: ('Although', 4781),\n",
       " 231: ('storm', 4766),\n",
       " 232: ('still', 4757),\n",
       " 233: ('When', 4742),\n",
       " 234: ('major', 4705),\n",
       " 235: ('named', 4702),\n",
       " 236: ('less', 4691),\n",
       " 237: ('May', 4673),\n",
       " 238: ('His', 4671),\n",
       " 239: ('show', 4658),\n",
       " 240: ('ft', 4617),\n",
       " 241: ('English', 4612),\n",
       " 242: ('days', 4603),\n",
       " 243: ('led', 4588),\n",
       " 244: ('de', 4581),\n",
       " 245: ('production', 4579),\n",
       " 246: ('role', 4576),\n",
       " 247: ('There', 4553),\n",
       " 248: ('last', 4482),\n",
       " 249: ('June', 4477),\n",
       " 250: ('system', 4474),\n",
       " 251: ('further', 4472),\n",
       " 252: ('produced', 4466),\n",
       " 253: ('areas', 4457),\n",
       " 254: ('July', 4447),\n",
       " 255: ('members', 4447),\n",
       " 256: ('different', 4424),\n",
       " 257: ('January', 4423),\n",
       " 258: ('local', 4405),\n",
       " 259: ('continued', 4399),\n",
       " 260: ('By', 4378),\n",
       " 261: ('William', 4366),\n",
       " 262: ('World', 4348),\n",
       " 263: ('2', 4342),\n",
       " 264: ('November', 4335),\n",
       " 265: ('population', 4332),\n",
       " 266: ('without', 4326),\n",
       " 267: ('March', 4311),\n",
       " 268: ('world', 4291),\n",
       " 269: ('become', 4273),\n",
       " 270: ('War', 4272),\n",
       " 271: ('recorded', 4247),\n",
       " 272: ('five', 4213),\n",
       " 273: ('building', 4195),\n",
       " 274: ('December', 4194),\n",
       " 275: ('down', 4184),\n",
       " 276: ('make', 4147),\n",
       " 277: ('French', 4143),\n",
       " 278: ('children', 4099),\n",
       " 279: ('body', 4076),\n",
       " 280: ('place', 4073),\n",
       " 281: ('April', 4053),\n",
       " 282: ('study', 4047),\n",
       " 283: ('given', 4035),\n",
       " 284: ('moved', 4020),\n",
       " 285: ('&', 4001),\n",
       " 286: ('white', 3996),\n",
       " 287: ('birds', 3967),\n",
       " 288: ('land', 3955),\n",
       " 289: ('During', 3918),\n",
       " 290: ('thought', 3884),\n",
       " 291: ('built', 3875),\n",
       " 292: ('died', 3873),\n",
       " 293: ('home', 3872),\n",
       " 294: ('house', 3870),\n",
       " 295: ('For', 3864),\n",
       " 296: ('reported', 3858),\n",
       " 297: ('Park', 3856),\n",
       " 298: ('young', 3854),\n",
       " 299: ('range', 3837),\n",
       " 300: ('River', 3836),\n",
       " 301: ('written', 3830),\n",
       " 302: ('km', 3820),\n",
       " 303: ('having', 3795),\n",
       " 304: ('single', 3793),\n",
       " 305: ('character', 3792),\n",
       " 306: ('just', 3790),\n",
       " 307: ('3', 3784),\n",
       " 308: ('England', 3775),\n",
       " 309: ('next', 3739),\n",
       " 310: ('design', 3728),\n",
       " 311: ('short', 3727),\n",
       " 312: ('using', 3722),\n",
       " 313: ('seen', 3721),\n",
       " 314: ('story', 3717),\n",
       " 315: ('held', 3714),\n",
       " 316: ('power', 3706),\n",
       " 317: ('10', 3700),\n",
       " 318: ('February', 3692),\n",
       " 319: ('across', 3684),\n",
       " 320: ('off', 3659),\n",
       " 321: ('age', 3653),\n",
       " 322: ('men', 3643),\n",
       " 323: ('history', 3636),\n",
       " 324: ('black', 3633),\n",
       " 325: ('way', 3632),\n",
       " 326: ('America', 3602),\n",
       " 327: ('never', 3602),\n",
       " 328: ('south', 3590),\n",
       " 329: ('least', 3569),\n",
       " 330: ('rather', 3566),\n",
       " 331: ('north', 3562),\n",
       " 332: ('site', 3544),\n",
       " 333: ('little', 3544),\n",
       " 334: ('women', 3542),\n",
       " 335: ('Press', 3537),\n",
       " 336: ('again', 3531),\n",
       " 337: ('head', 3531),\n",
       " 338: ('side', 3517),\n",
       " 339: ('US', 3508),\n",
       " 340: ('important', 3501),\n",
       " 341: ('main', 3499),\n",
       " 342: ('modern', 3495),\n",
       " 343: ('developed', 3489),\n",
       " 344: ('caused', 3484),\n",
       " 345: ('came', 3476),\n",
       " 346: ('months', 3472),\n",
       " 347: ('One', 3461),\n",
       " 348: ('According', 3435),\n",
       " 349: ('school', 3429),\n",
       " 350: ('great', 3423),\n",
       " 351: ('country', 3422),\n",
       " 352: ('writing', 3422),\n",
       " 353: ('region', 3417),\n",
       " 354: ('lower', 3415),\n",
       " 355: ('feet', 3413),\n",
       " 356: ('20', 3408),\n",
       " 357: ('played', 3406),\n",
       " 358: ('half', 3403),\n",
       " 359: ('style', 3367),\n",
       " 360: ('six', 3346),\n",
       " 361: ('war', 3340),\n",
       " 362: ('suggested', 3332),\n",
       " 363: ('example', 3330),\n",
       " 364: ('King', 3323),\n",
       " 365: ('genus', 3321),\n",
       " 366: ('appeared', 3320),\n",
       " 367: ('James', 3319),\n",
       " 368: ('evidence', 3304),\n",
       " 369: ('others', 3285),\n",
       " 370: ('George', 3273),\n",
       " 371: ('take', 3267),\n",
       " 372: ('support', 3262),\n",
       " 373: ('per', 3259),\n",
       " 374: ('should', 3248),\n",
       " 375: ('throughout', 3244),\n",
       " 376: ('popular', 3235),\n",
       " 377: ('size', 3226),\n",
       " 378: ('remained', 3224),\n",
       " 379: ('generally', 3221),\n",
       " 380: ('5', 3220),\n",
       " 381: ('Some', 3217),\n",
       " 382: ('food', 3213),\n",
       " 383: ('political', 3205),\n",
       " 384: ('season', 3203),\n",
       " 385: ('how', 3200),\n",
       " 386: ('formed', 3163),\n",
       " 387: ('4', 3159),\n",
       " 388: ('making', 3154),\n",
       " 389: ('himself', 3149),\n",
       " 390: ('result', 3128),\n",
       " 391: ('usually', 3120),\n",
       " 392: ('you', 3116),\n",
       " 393: ('tropical', 3111),\n",
       " 394: ('times', 3093),\n",
       " 395: ('former', 3091),\n",
       " 396: ('song', 3091),\n",
       " 397: ('30', 3087),\n",
       " 398: ('various', 3087),\n",
       " 399: ('however', 3085),\n",
       " 400: ('larger', 3078),\n",
       " 401: ('almost', 3076),\n",
       " 402: ('II', 3074),\n",
       " 403: ('created', 3073),\n",
       " 404: ('gave', 3069),\n",
       " 405: ('female', 3066),\n",
       " 406: ('play', 3064),\n",
       " 407: (\"n't\", 3056),\n",
       " 408: ('performance', 3054),\n",
       " 409: ('followed', 3053),\n",
       " 410: ('man', 3046),\n",
       " 411: ('record', 3043),\n",
       " 412: ('island', 3039),\n",
       " 413: ('noted', 3033),\n",
       " 414: ('novel', 3033),\n",
       " 415: ('House', 3029),\n",
       " 416: ('low', 3026),\n",
       " 417: ('established', 3025),\n",
       " 418: ('German', 3023),\n",
       " 419: ('old', 3017),\n",
       " 420: ('point', 3013),\n",
       " 421: ('father', 3007),\n",
       " 422: ('Europe', 2998),\n",
       " 423: ('third', 2995),\n",
       " 424: ('15', 2993),\n",
       " 425: ('Australia', 2990),\n",
       " 426: ('returned', 2987),\n",
       " 427: ('above', 2977),\n",
       " 428: ('particularly', 2968),\n",
       " 429: ('southern', 2965),\n",
       " 430: ('taken', 2963),\n",
       " 431: ('case', 2959),\n",
       " 432: ('final', 2958),\n",
       " 433: ('David', 2952),\n",
       " 434: ('too', 2946),\n",
       " 435: ('City', 2945),\n",
       " 436: ('we', 2929),\n",
       " 437: ('present', 2919),\n",
       " 438: ('sometimes', 2914),\n",
       " 439: ('material', 2905),\n",
       " 440: ('damage', 2903),\n",
       " 441: ('While', 2900),\n",
       " 442: ('cm', 2895),\n",
       " 443: ('success', 2892),\n",
       " 444: ('likely', 2879),\n",
       " 445: ('hurricane', 2877),\n",
       " 446: ('development', 2876),\n",
       " 447: ('stated', 2872),\n",
       " 448: ('art', 2866),\n",
       " 449: ('northern', 2861),\n",
       " 450: ('believed', 2856),\n",
       " 451: ('release', 2851),\n",
       " 452: ('either', 2845),\n",
       " 453: ('Robert', 2833),\n",
       " 454: ('miles', 2824),\n",
       " 455: ('sea', 2822),\n",
       " 456: ('sold', 2803),\n",
       " 457: ('earlier', 2795),\n",
       " 458: ('park', 2787),\n",
       " 459: ('groups', 2783),\n",
       " 460: ('U.S.', 2780),\n",
       " 461: ('songs', 2778),\n",
       " 462: ('company', 2776),\n",
       " 463: ('Thomas', 2775),\n",
       " 464: ('central', 2774),\n",
       " 465: ('probably', 2773),\n",
       " 466: ('12', 2770),\n",
       " 467: ('placed', 2767),\n",
       " 468: ('together', 2766),\n",
       " 469: ('away', 2763),\n",
       " 470: ('An', 2762),\n",
       " 471: ('son', 2758),\n",
       " 472: ('went', 2753),\n",
       " 473: ('instead', 2751),\n",
       " 474: ('coins', 2748),\n",
       " 475: ('West', 2738),\n",
       " 476: ('Charles', 2735),\n",
       " 477: ('sent', 2725),\n",
       " 478: ('best', 2710),\n",
       " 479: ('human', 2700),\n",
       " 480: ('largest', 2699),\n",
       " 481: ('100', 2698),\n",
       " 482: ('does', 2696),\n",
       " 483: ('parts', 2694),\n",
       " 484: ('reached', 2692),\n",
       " 485: ('close', 2686),\n",
       " 486: ('brought', 2684),\n",
       " 487: ('Island', 2680),\n",
       " 488: ('stage', 2680),\n",
       " 489: ('mm', 2655),\n",
       " 490: ('mi', 2649),\n",
       " 491: ('Other', 2635),\n",
       " 492: ('estimated', 2634),\n",
       " 493: ('once', 2629),\n",
       " 494: ('animals', 2620),\n",
       " 495: ('process', 2618),\n",
       " 496: ('order', 2608),\n",
       " 497: ('live', 2606),\n",
       " 498: ('able', 2604),\n",
       " 499: ('control', 2602),\n",
       " 500: ('possible', 2589),\n",
       " 501: ('remains', 2584),\n",
       " 502: ('west', 2579),\n",
       " 503: ('military', 2579),\n",
       " 504: ('increased', 2579),\n",
       " 505: ('male', 2568),\n",
       " 506: ('surface', 2566),\n",
       " 507: ('town', 2563),\n",
       " 508: ('television', 2554),\n",
       " 509: ('lost', 2552),\n",
       " 510: ('open', 2547),\n",
       " 511: ('2007', 2547),\n",
       " 512: ('right', 2546),\n",
       " 513: ('significant', 2543),\n",
       " 514: ('social', 2542),\n",
       " 515: ('musical', 2541),\n",
       " 516: ('east', 2540),\n",
       " 517: ('issue', 2522),\n",
       " 518: ('return', 2518),\n",
       " 519: ('especially', 2513),\n",
       " 520: ('national', 2511),\n",
       " 521: ('worked', 2509),\n",
       " 522: ('features', 2503),\n",
       " 523: ('provided', 2500),\n",
       " 524: ('western', 2497),\n",
       " 525: ('wife', 2493),\n",
       " 526: ('6', 2492),\n",
       " 527: ('far', 2485),\n",
       " 528: ('position', 2480),\n",
       " 529: ('project', 2477),\n",
       " 530: ('eastern', 2476),\n",
       " 531: ('related', 2475),\n",
       " 532: ('smaller', 2472),\n",
       " 533: ('2006', 2470),\n",
       " 534: ('might', 2470),\n",
       " 535: ('court', 2466),\n",
       " 536: ('whose', 2465),\n",
       " 537: ('performed', 2465),\n",
       " 538: ('winds', 2460),\n",
       " 539: ('Royal', 2454),\n",
       " 540: ('films', 2454),\n",
       " 541: ('mother', 2453),\n",
       " 542: ('version', 2452),\n",
       " 543: ('characters', 2448),\n",
       " 544: ('good', 2444),\n",
       " 545: ('total', 2437),\n",
       " 546: ('natural', 2437),\n",
       " 547: ('discovered', 2436),\n",
       " 548: ('required', 2429),\n",
       " 549: ('Street', 2426),\n",
       " 550: ('bird', 2426),\n",
       " 551: ('11', 2417),\n",
       " 552: ('front', 2417),\n",
       " 553: ('breeding', 2417),\n",
       " 554: ('every', 2411),\n",
       " 555: ('career', 2411),\n",
       " 556: ('2008', 2410),\n",
       " 557: ('Mint', 2406),\n",
       " 558: ('strong', 2404),\n",
       " 559: ('Henry', 2404),\n",
       " 560: ('Richard', 2399),\n",
       " 561: ('India', 2399),\n",
       " 562: ('my', 2395),\n",
       " 563: ('Its', 2391),\n",
       " 564: ('lead', 2389),\n",
       " 565: ('B.', 2383),\n",
       " 566: ('elements', 2378),\n",
       " 567: ('European', 2374),\n",
       " 568: ('general', 2371),\n",
       " 569: ('living', 2370),\n",
       " 570: ('red', 2365),\n",
       " 571: ('change', 2365),\n",
       " 572: ('ground', 2364),\n",
       " 573: ('To', 2358),\n",
       " 574: ('25', 2355),\n",
       " 575: ('length', 2352),\n",
       " 576: ('structure', 2350),\n",
       " 577: ('State', 2347),\n",
       " 578: ('magazine', 2340),\n",
       " 579: ('proposed', 2339),\n",
       " 580: ('leading', 2333),\n",
       " 581: ('allowed', 2332),\n",
       " 582: ('killed', 2327),\n",
       " 583: ('C.', 2325),\n",
       " 584: ('Mary', 2323),\n",
       " 585: ('member', 2320),\n",
       " 586: ('2009', 2315),\n",
       " 587: ('addition', 2310),\n",
       " 588: ('16', 2305),\n",
       " 589: ('upon', 2301),\n",
       " 590: ('upper', 2292),\n",
       " 591: ('interest', 2292),\n",
       " 592: ('wide', 2288),\n",
       " 593: ('2005', 2288),\n",
       " 594: ('13', 2284),\n",
       " 595: ('8', 2284),\n",
       " 596: ('A.', 2283),\n",
       " 597: ('working', 2279),\n",
       " 598: ('Indian', 2278),\n",
       " 599: ('2010', 2273),\n",
       " 600: ('longer', 2271),\n",
       " 601: ('eventually', 2265),\n",
       " 602: ('saw', 2265),\n",
       " 603: ('according', 2257),\n",
       " 604: ('Museum', 2247),\n",
       " 605: ('introduced', 2242),\n",
       " 606: ('average', 2242),\n",
       " 607: ('rock', 2241),\n",
       " 608: ('influence', 2240),\n",
       " 609: ('appear', 2239),\n",
       " 610: ('met', 2238),\n",
       " 611: ('soon', 2234),\n",
       " 612: ('towards', 2234),\n",
       " 613: ('Australian', 2227),\n",
       " 614: ('With', 2224),\n",
       " 615: ('felt', 2223),\n",
       " 616: ('line', 2219),\n",
       " 617: ('located', 2205),\n",
       " 618: ('Canada', 2205),\n",
       " 619: ('stories', 2202),\n",
       " 620: ('relationship', 2190),\n",
       " 621: ('Washington', 2189),\n",
       " 622: ('construction', 2187),\n",
       " 623: ('law', 2186),\n",
       " 624: ('Times', 2185),\n",
       " 625: ('18', 2182),\n",
       " 626: ('complete', 2176),\n",
       " 627: ('states', 2171),\n",
       " 628: ('Society', 2169),\n",
       " 629: ('books', 2169),\n",
       " 630: ('M.', 2168),\n",
       " 631: ('!', 2164),\n",
       " 632: ('California', 2157),\n",
       " 633: ('light', 2152),\n",
       " 634: ('All', 2152),\n",
       " 635: ('trees', 2152),\n",
       " 636: ('7', 2151),\n",
       " 637: ('born', 2146),\n",
       " 638: ('14', 2145),\n",
       " 639: ('coin', 2143),\n",
       " 640: ('movement', 2140),\n",
       " 641: ('help', 2138),\n",
       " 642: ('hours', 2137),\n",
       " 643: ('whom', 2133),\n",
       " 644: ('research', 2133),\n",
       " 645: ('Britain', 2131),\n",
       " 646: ('coast', 2121),\n",
       " 647: ('see', 2118),\n",
       " 648: ('numbers', 2114),\n",
       " 649: ('initially', 2111),\n",
       " 650: ('top', 2109),\n",
       " 651: ('associated', 2104),\n",
       " 652: ('latter', 2104),\n",
       " 653: ('2011', 2101),\n",
       " 654: ('opened', 2099),\n",
       " 655: ('East', 2099),\n",
       " 656: ('involved', 2097),\n",
       " 657: ('told', 2095),\n",
       " 658: ('level', 2081),\n",
       " 659: ('lived', 2080),\n",
       " 660: ('Western', 2079),\n",
       " 661: ('County', 2078),\n",
       " 662: ('Great', 2077),\n",
       " 663: ('church', 2076),\n",
       " 664: ('available', 2075),\n",
       " 665: ('tour', 2074),\n",
       " 666: ('higher', 2072),\n",
       " 667: ('director', 2071),\n",
       " 668: ('enough', 2068),\n",
       " 669: ('buildings', 2067),\n",
       " 670: ('Many', 2059),\n",
       " 671: ('shows', 2058),\n",
       " 672: ('decided', 2052),\n",
       " 673: ('lack', 2052),\n",
       " 674: ('originally', 2049),\n",
       " 675: ('successful', 2049),\n",
       " 676: ('added', 2043),\n",
       " 677: ('effects', 2043),\n",
       " 678: ('outside', 2037),\n",
       " 679: ('completed', 2036),\n",
       " 680: ('critics', 2034),\n",
       " 681: ('served', 2033),\n",
       " 682: ('asked', 2033),\n",
       " 683: ('No', 2031),\n",
       " 684: ('Court', 2030),\n",
       " 685: ('passed', 2029),\n",
       " 686: ('previous', 2027),\n",
       " 687: ('2012', 2026),\n",
       " 688: ('Hall', 2022),\n",
       " 689: ('view', 2020),\n",
       " 690: ('Best', 2020),\n",
       " 691: ('weeks', 2020),\n",
       " 692: ('50', 2016),\n",
       " 693: ('events', 2013),\n",
       " 694: ('complex', 2010),\n",
       " 695: ('mostly', 2007),\n",
       " 696: ('designed', 2006),\n",
       " 697: ('P.', 2004),\n",
       " 698: ('struck', 2004),\n",
       " 699: ('heavy', 2003),\n",
       " 700: ('plant', 2002),\n",
       " 701: ('pieces', 2000),\n",
       " 702: ('appearance', 1999),\n",
       " 703: ('percent', 1996),\n",
       " 704: ('full', 1996),\n",
       " 705: ('School', 1994),\n",
       " 706: ('Most', 1993),\n",
       " 707: ('animal', 1991),\n",
       " 708: ('type', 1984),\n",
       " 709: ('specimen', 1984),\n",
       " 710: ('forms', 1983),\n",
       " 711: ('title', 1982),\n",
       " 712: ('fire', 1976),\n",
       " 713: ('changes', 1974),\n",
       " 714: ('Paul', 1967),\n",
       " 715: ('Despite', 1965),\n",
       " 716: ('km/h', 1965),\n",
       " 717: ('base', 1963),\n",
       " 718: ('Africa', 1955),\n",
       " 719: ('cause', 1949),\n",
       " 720: ('air', 1949),\n",
       " 721: ('Lake', 1948),\n",
       " 722: ('whether', 1946),\n",
       " 723: ('studies', 1946),\n",
       " 724: ('France', 1945),\n",
       " 725: ('produce', 1945),\n",
       " 726: ('specimens', 1943),\n",
       " 727: ('bill', 1941),\n",
       " 728: ('put', 1941),\n",
       " 729: ('party', 1941),\n",
       " 730: ('opera', 1940),\n",
       " 731: ('2004', 1937),\n",
       " 732: ('piece', 1935),\n",
       " 733: ('language', 1934),\n",
       " 734: ('rest', 1933),\n",
       " 735: ('spent', 1929),\n",
       " 736: ('compared', 1928),\n",
       " 737: ('teeth', 1925),\n",
       " 738: ('nearly', 1923),\n",
       " 739: ('wanted', 1920),\n",
       " 740: ('find', 1917),\n",
       " 741: ('2013', 1915),\n",
       " 742: ('Act', 1912),\n",
       " 743: ('History', 1912),\n",
       " 744: ('silver', 1912),\n",
       " 745: ('highly', 1910),\n",
       " 746: ('itself', 1908),\n",
       " 747: ('police', 1908),\n",
       " 748: ('replaced', 1906),\n",
       " 749: ('occurred', 1906),\n",
       " 750: ('seven', 1905),\n",
       " 751: ('ever', 1904),\n",
       " 752: ('status', 1901),\n",
       " 753: ('official', 1898),\n",
       " 754: ('studio', 1895),\n",
       " 755: ('me', 1893),\n",
       " 756: ('gold', 1890),\n",
       " 757: ('scene', 1890),\n",
       " 758: ('effect', 1889),\n",
       " 759: ('tail', 1889),\n",
       " 760: ('issued', 1888),\n",
       " 761: ('mph', 1888),\n",
       " 762: ('featured', 1887),\n",
       " 763: ('must', 1886),\n",
       " 764: ('announced', 1881),\n",
       " 765: ('Creek', 1879),\n",
       " 766: ('Chinese', 1878),\n",
       " 767: ('woman', 1876),\n",
       " 768: ('collection', 1875),\n",
       " 769: ('From', 1872),\n",
       " 770: ('identified', 1867),\n",
       " 771: ('nature', 1865),\n",
       " 772: ('summer', 1865),\n",
       " 773: ('won', 1863),\n",
       " 774: ('letter', 1859),\n",
       " 775: ('field', 1851),\n",
       " 776: ('friend', 1851),\n",
       " 777: ('ago', 1851),\n",
       " 778: ('quickly', 1850),\n",
       " 779: ('office', 1849),\n",
       " 780: ('ten', 1849),\n",
       " 781: ('relatively', 1843),\n",
       " 782: ('turned', 1842),\n",
       " 783: ('provide', 1840),\n",
       " 784: ('Two', 1839),\n",
       " 785: ('International', 1839),\n",
       " 786: ('money', 1838),\n",
       " 787: ('Award', 1838),\n",
       " 788: ('artist', 1836),\n",
       " 789: ('previously', 1836),\n",
       " 790: ('Edward', 1834),\n",
       " 791: ('Company', 1832),\n",
       " 792: ('eight', 1828),\n",
       " 793: ('report', 1826),\n",
       " 794: ('difficult', 1826),\n",
       " 795: ('Music', 1826),\n",
       " 796: ('writer', 1825),\n",
       " 797: ('S.', 1822),\n",
       " 798: ('24', 1821),\n",
       " 799: ('Her', 1821),\n",
       " 800: ('Roman', 1820),\n",
       " 801: ('service', 1817),\n",
       " 802: ('better', 1817),\n",
       " 803: ('Union', 1815),\n",
       " 804: ('includes', 1814),\n",
       " 805: ('agreed', 1813),\n",
       " 806: ('beginning', 1813),\n",
       " 807: ('metal', 1810),\n",
       " 808: ('9', 1809),\n",
       " 809: ('mainly', 1807),\n",
       " 810: ('plants', 1807),\n",
       " 811: ('limited', 1806),\n",
       " 812: ('populations', 1805),\n",
       " 813: ('idea', 1804),\n",
       " 814: ('already', 1798),\n",
       " 815: ('below', 1796),\n",
       " 816: ('individuals', 1795),\n",
       " 817: ('President', 1794),\n",
       " 818: ('UK', 1792),\n",
       " 819: ('space', 1788),\n",
       " 820: ('skull', 1788),\n",
       " 821: ('subspecies', 1787),\n",
       " 822: ('contains', 1785),\n",
       " 823: ('2003', 1784),\n",
       " 824: ('?', 1784),\n",
       " 825: ('largely', 1780),\n",
       " 826: ('showed', 1780),\n",
       " 827: ('2014', 1778),\n",
       " 828: ('Congress', 1772),\n",
       " 829: ('Spanish', 1772),\n",
       " 830: ('San', 1772),\n",
       " 831: ('historian', 1771),\n",
       " 832: ('run', 1769),\n",
       " 833: ('subject', 1769),\n",
       " 834: ('activity', 1769),\n",
       " 835: ('17', 1768),\n",
       " 836: ('rights', 1767),\n",
       " 837: ('students', 1760),\n",
       " 838: ('observed', 1755),\n",
       " 839: ('love', 1754),\n",
       " 840: ('covered', 1752),\n",
       " 841: ('cast', 1752),\n",
       " 842: ('tree', 1750),\n",
       " 843: ('response', 1749),\n",
       " 844: ('ship', 1746),\n",
       " 845: ('Michael', 1745),\n",
       " 846: ('destroyed', 1743),\n",
       " 847: ('themselves', 1743),\n",
       " 848: ('date', 1742),\n",
       " 849: ('night', 1741),\n",
       " 850: ('act', 1741),\n",
       " 851: ('Church', 1740),\n",
       " 852: ('Sir', 1739),\n",
       " 853: ('particular', 1734),\n",
       " 854: ('shown', 1731),\n",
       " 855: ('individual', 1731),\n",
       " 856: ('typically', 1731),\n",
       " 857: ('2015', 1729),\n",
       " 858: ('Johnson', 1729),\n",
       " 859: ('separate', 1728),\n",
       " 860: ('come', 1728),\n",
       " 861: ('Greek', 1725),\n",
       " 862: ('thus', 1725),\n",
       " 863: ('prey', 1725),\n",
       " 864: ('names', 1722),\n",
       " 865: ('intended', 1719),\n",
       " 866: ('2000', 1717),\n",
       " 867: ('Pacific', 1717),\n",
       " 868: ('variety', 1716),\n",
       " 869: ('claimed', 1715),\n",
       " 870: ('2001', 1714),\n",
       " 871: ('increase', 1713),\n",
       " 872: ('suggests', 1713),\n",
       " 873: ('painting', 1712),\n",
       " 874: ('presence', 1710),\n",
       " 875: ('conditions', 1710),\n",
       " 876: ('appears', 1709),\n",
       " 877: ('private', 1706),\n",
       " 878: ('river', 1704),\n",
       " 879: ('behind', 1703),\n",
       " 880: ('issues', 1701),\n",
       " 881: ('joined', 1698),\n",
       " 882: ('composer', 1696),\n",
       " 883: ('widely', 1695),\n",
       " 884: ('Peter', 1688),\n",
       " 885: ('forest', 1688),\n",
       " 886: ('cells', 1684),\n",
       " 887: ('Mexico', 1680),\n",
       " 888: ('2016', 1679),\n",
       " 889: ('traditional', 1679),\n",
       " 890: ('started', 1678),\n",
       " 891: ('St', 1673),\n",
       " 892: ('ice', 1670),\n",
       " 893: ('referred', 1664),\n",
       " 894: ('Germany', 1661),\n",
       " 895: ('despite', 1660),\n",
       " 896: ('fish', 1658),\n",
       " 897: ('First', 1655),\n",
       " 898: ('king', 1655),\n",
       " 899: ('trade', 1655),\n",
       " 900: ('changed', 1653),\n",
       " 901: ('bones', 1652),\n",
       " 902: ('yet', 1651),\n",
       " 903: ('give', 1650),\n",
       " 904: ('words', 1647),\n",
       " 905: ('face', 1646),\n",
       " 906: ('supported', 1646),\n",
       " 907: ('stone', 1646),\n",
       " 908: ('source', 1643),\n",
       " 909: ('Paris', 1640),\n",
       " 910: ('Florida', 1638),\n",
       " 911: ('married', 1637),\n",
       " 912: ('blood', 1637),\n",
       " 913: ('males', 1634),\n",
       " 914: ('event', 1632),\n",
       " 915: ('closely', 1632),\n",
       " 916: ('cover', 1632),\n",
       " 917: ('nest', 1630),\n",
       " 918: ('greater', 1628),\n",
       " 919: ('entire', 1617),\n",
       " 920: ('list', 1617),\n",
       " 921: ('21', 1614),\n",
       " 922: ('E.', 1610),\n",
       " 923: ('daughter', 1610),\n",
       " 924: ('approximately', 1609),\n",
       " 925: ('personal', 1606),\n",
       " 926: ('special', 1605),\n",
       " 927: ('team', 1604),\n",
       " 928: ('cases', 1603),\n",
       " 929: ('Oxford', 1603),\n",
       " 930: ('accepted', 1600),\n",
       " 931: ('action', 1597),\n",
       " 932: ('crew', 1596),\n",
       " 933: ('room', 1595),\n",
       " 934: ('raised', 1594),\n",
       " 935: ('eggs', 1594),\n",
       " 936: ('our', 1592),\n",
       " 937: ('sound', 1591),\n",
       " 938: ('China', 1589),\n",
       " 939: ('attempt', 1588),\n",
       " 940: ('deep', 1587),\n",
       " 941: ('create', 1586),\n",
       " 942: ('dollar', 1586),\n",
       " 943: ('feature', 1585),\n",
       " 944: ('Both', 1584),\n",
       " 945: ('active', 1584),\n",
       " 946: ('opening', 1583),\n",
       " 947: ('pressure', 1582),\n",
       " 948: ('winter', 1582),\n",
       " 949: ('brother', 1581),\n",
       " 950: ('St.', 1581),\n",
       " 951: ('notes', 1581),\n",
       " 952: ('2002', 1578),\n",
       " 953: ('records', 1578),\n",
       " 954: ('education', 1578),\n",
       " 955: ('edition', 1576),\n",
       " 956: ('community', 1576),\n",
       " 957: ('critic', 1576),\n",
       " 958: ('commercial', 1575),\n",
       " 959: ('center', 1574),\n",
       " 960: ('40', 1573),\n",
       " 961: ('always', 1573),\n",
       " 962: ('brown', 1573),\n",
       " 963: ('General', 1572),\n",
       " 964: ('H.', 1568),\n",
       " 965: ('force', 1567),\n",
       " 966: ('person', 1566),\n",
       " 967: ('22', 1565),\n",
       " 968: ('2017', 1562),\n",
       " 969: ('fact', 1561),\n",
       " 970: ('fiction', 1561),\n",
       " 971: ('nearby', 1560),\n",
       " 972: ('science', 1559),\n",
       " 973: ('growth', 1557),\n",
       " 974: ('arrived', 1556),\n",
       " 975: ('child', 1556),\n",
       " 976: ('future', 1554),\n",
       " 977: ('rate', 1554),\n",
       " 978: ('slightly', 1552),\n",
       " 979: ('critical', 1549),\n",
       " 980: ('2020', 1546),\n",
       " 981: ('J.', 1545),\n",
       " 982: ('failed', 1545),\n",
       " 983: ('society', 1544),\n",
       " 984: ('adult', 1543),\n",
       " 985: ('means', 1542),\n",
       " 986: ('reduced', 1542),\n",
       " 987: ('native', 1541),\n",
       " 988: ('Kingdom', 1539),\n",
       " 989: ('religious', 1539),\n",
       " 990: ('attention', 1539),\n",
       " 991: ('go', 1539),\n",
       " 992: ('20th', 1538),\n",
       " 993: ('additional', 1537),\n",
       " 994: ('2019', 1536),\n",
       " 995: ('numerous', 1533),\n",
       " 996: ('2021', 1533),\n",
       " 997: ('recording', 1533),\n",
       " 998: ('location', 1532),\n",
       " 999: ('helped', 1532),\n",
       " 1000: ('If', 1530),\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_counter = Counter()\n",
    "for text in all_inst:\n",
    "    vocab_counter.update(text)\n",
    "vocab_counter = dict(sorted(vocab_counter.items(), key=lambda item: item[1], reverse = True))\n",
    "vocab_counter = {i + 1: (token, frequency) for i, (token, frequency) in enumerate(vocab_counter.items())}\n",
    "# most_common = {math.log(i): math.log(items[1]) for i, items in vocab_counter.items() if items[1]>=10000}\n",
    "most_common = {i: items[1] for j, (i, items) in enumerate(vocab_counter.items()) if j>=10000}\n",
    "vocab_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32bf8bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(most_common.values(),most_common.keys())\n",
    "plt.ylabel('frequency')\n",
    "plt.xlabel('rank')\n",
    "plt.title(\"frequency vs rank graph\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85578208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized frequency \n",
    "alpha = 0.1\n",
    "k = 3.65\n",
    "y = k / (np.array([*most_common.values()])**alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "502c466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find line of best fit\n",
    "x = np.array([*most_common.values()])\n",
    "y = np.array([*most_common.keys()])\n",
    "a, b, c = np.polyfit(1/y, x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a4e5c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.62038332e+10, 1.62038332e+10, 1.62038332e+10, ...,\n",
       "       1.03707837e+06, 1.03707837e+06, 1.03707837e+06])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = a*x**2 + b*x + c\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24262320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def f(x, A, B): \n",
    "    return A/(x**B)\n",
    "\n",
    "popt, pcov = curve_fit(f, x, y) # your data x, y to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c98d347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y, color = 'red')\n",
    "plt.plot(x, f(x, *popt))\n",
    "plt.ylabel('frequency')\n",
    "plt.xlabel('rank')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b528f97b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c110a89a",
   "metadata": {},
   "source": [
    "## Problem 1.2 (2 points) - Contextual Embeddings\n",
    "\n",
    "[Deep contextualized word representations (Peters et al., 2018)](https://arxiv.org/pdf/1802.05365.pdf) uses an LSTM-based architecture to generate meaning representations of tokens. \n",
    "\n",
    "Using the linked paper as reference, highlight the differences between using static word embeddings and contextual representations and suggest two reasons how the language-modelling objective helps other NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff24273",
   "metadata": {},
   "source": [
    "Static word emmbeddings are using finite large number of vocab words to emmbed the meaning of each token.\n",
    "\n",
    "The LSTM-based architecture (to be exact the one intrduce in paper biLM is trying to capture deeper sense of the word (like part of speech). It's using the subwords units and character convolutions. The model is learning the linear combination of the vectors stacked above each input word for each end task. \n",
    "\n",
    "As mentioned in the article previous approaches allowed a single context independent representation for each word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06258eed",
   "metadata": {},
   "source": [
    "# Problem 2 - BERT-style Language Models (14 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8ea71",
   "metadata": {},
   "source": [
    "## Problem 2.1 (8 points) - BERT Language Model\n",
    "Using the provided data, train a language model with the [BERT]((https://aclanthology.org/N19-1423.pdf) masked language model objective (NSP prediction task is not reuqired). Select appropriate model size and hyperparameters. \n",
    "\n",
    "* Make the training data yourself\n",
    "\n",
    "* Print a sample of training instances (both the model inputs and expected outputs)\n",
    "\n",
    "* Plot the loss regularly (e.g. after an epoch or fixed number of training steps) on a graph. Report the loss for both the training data and validation data.\n",
    "\n",
    "* Use the `transformers` library implementation of a suitable tokenizer and model for language modelling with BERT. But do not use a pre-trained language model (i.e. start with a randomly initialized model).  \n",
    "\n",
    "Hint: you can use [BERTConfig](https://huggingface.co/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertConfig) to configure your language model, and use [BERTForMaskedLM](https://huggingface.co/docs/transformers/v4.24.0/en/model_doc/bert#transformers.BertForMaskedLM) which is a pre-configured language model. \n",
    "\n",
    "Hint: You should use the [AdamW optimizer](https://huggingface.co/docs/transformers/v4.24.0/en/main_classes/optimizer_schedules#transformers.AdamW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "058d739c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vessl.integration.pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [168], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mvessl\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvessl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegration\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExperimentCallback\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'vessl.integration.pytorch'"
     ]
    }
   ],
   "source": [
    "import vessl\n",
    "from vessl.integration.keras import ExperimentCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vessl.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fc2b0713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\User/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\User/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\User/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\User/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\User/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67239dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\n",
    "  \"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"<S>\", \"<T>\"\n",
    "]\n",
    "# if you want to train the tokenizer on both sets\n",
    "# files = [\"train.txt\", \"test.txt\"]\n",
    "# training the tokenizer on the training set\n",
    "files = [\"C:/Users/User/Desktop/NLP/ass5/wiki.jsonl\"]\n",
    "model_path = \"pretrained-bert\"\n",
    "\n",
    "# 30,522 vocab is BERT's default vocab size, feel free to tweak\n",
    "vocab_size = 30_522\n",
    "# maximum sequence length, lowering will result to faster training (when increasing batch size)\n",
    "max_length = 512\n",
    "# whether to truncate\n",
    "truncate_longer_samples = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1f40a1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8ad91c1a24ac6a16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to C:/Users/User/.cache/huggingface/datasets/json/default-8ad91c1a24ac6a16/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2804dde9104ba6b2c07e4262734021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75a575e58d74520a77c41510966df94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:/Users/User/.cache/huggingface/datasets/json/default-8ad91c1a24ac6a16/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('json', data_files=files, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "81ca5dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7 World Trade Center (7 WTC, WTC-7, or Tower 7) refers to two buildings that have existed at the same location within the World Trade Center site in Lower Manhattan, New York City. The original structure, part of the original World Trade Center, was completed in 1987 and was destroyed in the September 11 attacks in 2001. The current structure opened in May 2006. Both buildings were developed by Larry Silverstein, who holds a ground lease for the site from the Port Authority of New York and New Jersey.\\nThe original 7 World Trade Center was 47 stories tall, clad in red granite masonry, and occupied a trapezoidal footprint. An elevated walkway spanning Vesey Street connected the building to the World Trade Center plaza. The building was situated above a Consolidated Edison power substation, which imposed unique structural design constraints. When the building opened in 1987, Silverstein had difficulties attracting tenants. Salomon Brothers signed a long-term lease in 1988 and became the anchor tenant of 7 WTC.\\nOn September 11, 2001, the structure was substantially damaged by debris when the nearby North Tower of the World Trade Center collapsed. The debris ignited fires on multiple lower floors of the building, which continued to burn uncontrolled throughout the afternoon. The building\\'s internal fire suppression system lacked water pressure to fight the fires. The collapse began when a critical internal column buckled and triggered cascading failure of nearby columns throughout, which was first visible from the exterior with the crumbling of a rooftop penthouse structure at 5:20:33 pm. This initiated progressive collapse of the entire building at 5:21:10 pm, according to FEMA,:\\u200a23\\u200a while the 2008 NIST study placed the final collapse time at 5:20:52 pm.:\\u200a19,\\u200a21,\\u200a50–51\\u200a The collapse made the old 7 World Trade Center the first steel skyscraper known to have collapsed primarily due to uncontrolled fires.Construction of the new 7 World Trade Center began in 2002 and was completed in 2006. The building is 52 stories tall (plus one underground floor), making it the 28th-tallest in New York. It is built on a smaller footprint than the original, and is bounded by Greenwich, Vesey, Washington, and Barclay Streets on the east, south, west, and north, respectively. A small park across Greenwich Street occupies space that was part of the original building\\'s footprint. The current building\\'s design emphasizes safety, with a reinforced concrete core, wider stairways, and thicker fireproofing on steel columns. It also incorporates numerous green design features. The building was the first commercial office building in New York City to receive the U.S. Green Building Council\\'s Leadership in Energy and Environmental Design (LEED) certification, where it won a gold rating. It was also one of the first projects accepted to be part of the council\\'s pilot program for Leadership in Energy and Environmental Design – Core and Shell Development (LEED-CS).\\n\\n\\n\\n\\n\\nThe original 7 World Trade Center was a 47-story building, designed by Emery Roth & Sons, with a red granite facade. The building was 610 feet (190 m) tall, with a trapezoidal footprint that was 330 ft (100 m) long and 140 ft (43 m) wide. Tishman Realty & Construction managed construction of the building. The ground-breaking ceremony was hosted on October 2, 1984. The building opened in May 1987, becoming the seventh structure of the World Trade Center.7 World Trade Center was constructed above a two-story Con Edison substation that had been located on the site since 1967. The substation had a caisson foundation designed to carry the weight of a future building of 25 stories containing 600,000 sq ft (56,000 m2). However, the final design for 7 World Trade Center was for a much larger building than originally planned when the substation was built.:\\u200axxxviii\\u200a The structural design of 7 World Trade Center therefore included a system of gravity column transfer trusses and girders, located between floors 5 and 7, to transfer loads to the smaller foundation.:\\u200a5\\u200a Existing caissons installed in 1967 were used, along with new ones, to accommodate the building. The 5th floor functioned as a structural diaphragm, providing lateral stability and distribution of loads between the new and old caissons. Above the 7th floor,  the building\\'s structure was a typical tube-frame design, with columns in the core and on the perimeter, and lateral loads resisted by perimeter moment frames.A shipping and receiving ramp, which served the entire World Trade Center complex, occupied the eastern quarter of the 7 World Trade Center footprint. The building was open below the 3rd floor, providing space for truck clearance on the shipping ramp. The spray-on fireproofing for structural steel elements was gypsum-based Monokote, which had a two-hour fire rating for steel beams, girders and trusses, and a three-hour rating for columns.:\\u200a11\\u200aMechanical equipment was installed on floors four through seven, including 12 transformers on the 5th floor. Several emergency generators installed in the building were used by the New York City Office of Emergency Management, Salomon Smith Barney, and other tenants.:\\u200a13\\u200a In order to supply the generators, 24,000 gallons (91,000 L) of diesel fuel were stored below ground level. Diesel fuel distribution components were located at ground level, up to the ninth floor.:\\u200a35\\u200a After the World Trade Center bombings of February 26, 1993, New York City mayor Rudy Giuliani decided to situate the emergency command center and associated fuel tanks at 7 World Trade Center. Although this decision was criticized in light of the events of 9/11, the fuel in the building is today not believed to have contributed to the collapse of the building.:\\u200a2\\u200a The roof of the building included a small west penthouse and a larger east mechanical penthouse.Each floor had 47,000 sq ft (4,400 m2) of rentable office space, which made the building\\'s floor plans considerably larger than most office buildings in the city. In all, 7 World Trade Center had 1,868,000 sq ft (173,500 m2) of office space.:\\u200a1\\u200a Two pedestrian bridges connected the main World Trade Center complex, across Vesey Street, to the third floor of 7 World Trade Center. The lobby of 7 World Trade Center held three murals by artist Al Held: The Third Circle, Pan North XII, and Vorces VII.\\n\\n\\n\\nIn June 1986, before construction was completed, developer Larry Silverstein signed Drexel Burnham Lambert as a tenant to lease the entire 7 World Trade Center building for $3 billion over a term of 30 years.\\nIn December 1986, after the Boesky insider-trading scandal, Drexel Burnham Lambert canceled the lease, leaving Silverstein to find other tenants.\\nSpicer & Oppenheim agreed to lease 14 percent of the space, but for more than a year, as Black Monday and other factors adversely affected the Lower Manhattan real estate market, Silverstein was unable to find tenants for the remaining space. By April 1988, he had lowered the rent and made other concessions.In November 1988, Salomon Brothers withdrew from plans to build a large new complex at Columbus Circle in Midtown, instead agreeing to a 20-year lease for the top 19 floors of 7 World Trade Center. The building was extensively renovated in 1989 to accommodate Salomon Brothers, and 7 World Trade Center alternatively became known as the Salomon Brothers building. Most of the three existing floors were removed as tenants continued to occupy other stories, and more than 350 tons (U.S.) of steel were added to construct three double-height trading floors. Nine diesel generators were installed on the 5th floor as part of a backup power station. \"Essentially, Salomon is constructing a building within a building – and it\\'s an occupied building, which complicates the situation\", said a district manager of Silverstein Properties. According to Larry Silverstein, the unusual task was possible because it could allow \"entire portions of floors to be removed without affecting the building\\'s structural integrity, on the assumption that someone might need double-height floors.\"At the time of the September 11, 2001, attacks, Salomon Smith Barney was by far the largest tenant in 7 World Trade Center, occupying 1,202,900 sq ft (111,750 m2) (64 percent of the building) which included floors 28–45.:\\u200a2\\u200a Other major tenants included ITT Hartford Insurance Group (122,590 sq ft/11,400 m2), American Express Bank International (106,117 sq ft/9,900 m2), Standard Chartered Bank (111,398 sq ft/10,350 m2), and the Securities and Exchange Commission (106,117 sq ft/9,850 m2). Smaller tenants included the Internal Revenue Service Regional Council (90,430 sq ft/8,400 m2) and the United States Secret Service (85,343 sq ft/7,900 m2). The smallest tenants included the New York City Office of Emergency Management, National Association of Insurance Commissioners, Federal Home Loan Bank of New York, First State Management Group Inc., Provident Financial Management, and the Immigration and Naturalization Service. The Department of Defense (DOD) and Central Intelligence Agency (CIA) shared the 25th floor with the IRS.:\\u200a2\\u200a (The clandestine CIA office was revealed only after the 9/11 attacks.)  Floors 46–47 were mechanical floors, as were the bottom six floors and part of the seventh floor.:\\u200a2\\u200a\\n\\n\\n\\n\\nAs the North Tower collapsed on September 11, 2001, heavy debris hit 7 World Trade Center, damaging the south face of the building:\\u200a18 (PDF p. 22)\\u200a and starting fires that continued to burn throughout the afternoon.:\\u200a16,\\u200a18\\u200a The collapse also caused damage to the southwest corner between floors 7 and 17 and on the south face between Floor 44 and the roof; other possible structural damage included a large vertical gash near the center of the south face between Floors 24 and 41.:\\u200a17\\u200a The building was equipped with a sprinkler system, but had many single-point vulnerabilities for failure: the sprinkler system required manual initiation of the electrical fire pumps, rather than being a fully automatic system; the floor-level controls had a single connection to the sprinkler water riser, and the sprinkler system required some power for the fire pump to deliver water.:\\u200a11\\u200a Additionally, water pressure was low, with little or no water to feed sprinklers.:\\u200a23–30\\u200aAfter the North Tower collapsed, some firefighters entered 7 World Trade Center to search the building. They attempted to extinguish small pockets of fire, but low water pressure hindered their efforts. Over the course of the day, fires burned out of control on several floors of 7 World Trade Center, the flames visible on the east side of the building. During the afternoon, the fire was also seen on floors 6–10, 13–14, 19–22, and 29–30.:\\u200a24 (PDF p. 28)\\u200a In particular, the fires on floors 7 through 9 and 11 through 13 continued to burn out of control during the afternoon. At approximately 2:00 pm, firefighters noticed a bulge in the southwest corner of 7 World Trade Center between the 10th and 13th floors, a sign that the building was unstable and might collapse. During the afternoon, firefighters also heard creaking sounds coming from the building. Around 3:30 pm, FDNY Chief of Operations Daniel A. Nigro decided to halt rescue operations, surface removal, and searches along the surface of the debris near 7 World Trade Center and evacuate the area due to concerns for the safety of personnel.The fire expanded the girders of the building, causing some to collapse. This led to the northeast corner core column (Column 79), which was especially large, to buckle below the 13th floor. This caused the floors above it to collapse to the transfer floor at the fifth level. The structure also developed cracks in the facade just before the entire building started to fall.:\\u200a21\\u200a According to FEMA, this collapse started at 5:20:33 pm EDT when the east mechanical penthouse started crumbling.:\\u200a23\\u200a Differing times are given as to what time the building completely collapsed: at 5:21:10 pm EDT according to FEMA,:\\u200a23\\u200a and at 5:20:52 pm EDT according to NIST.:\\u200a19,\\u200a21,\\u200a50–51\\u200aThere were no casualties associated with the collapse. NIST found no evidence to support conspiracy theories such as the collapse being the result of explosives; it found that a combination of factors including physical damage, fire, and the building\\'s unusual construction set off a chain-reaction collapse.\\n\\n\\n\\nIn May 2002, the Federal Emergency Management Agency (FEMA) issued a report on the collapse based on a preliminary investigation conducted jointly with the Structural Engineering Institute of the American Society of Civil Engineers under the leadership of Dr. W. Gene Corley, P.E. FEMA made preliminary findings that the collapse was not primarily caused by actual impact damage from the collapse of 1 WTC and 2 WTC but by fires on multiple stories ignited by debris from the other two towers that continued burning unabated due to lack of water for sprinklers or manual firefighting. The report did not reach conclusions about the cause of the collapse and called for further investigation.:\\u200a3\\u200aSubsequently, the National Institute of Standards and Technology (NIST) was authorized to lead an investigation into the structural failure and collapse of the World Trade Center Twin Towers and 7 World Trade Center. The investigation, led by Dr S. Shyam Sunder, drew upon in-house technical expertise as well as the knowledge of several outside private institutions, including the Structural Engineering Institute of the American Society of Civil Engineers (SEI/ASCE); the Society of Fire Protection Engineers (SFPE); the National Fire Protection Association (NFPA); the American Institute of Steel Construction (AISC); the Council on Tall Buildings and Urban Habitat (CTBUH); and the Structural Engineers Association of New York (SEAoNY).\\n\\nThe bulk of the investigation of 7 World Trade Center was delayed until after reports were completed on the Twin Towers. In the meantime, NIST provided a preliminary report about 7 WTC in June 2004, and thereafter released occasional updates on the investigation. According to NIST, the investigation of 7 World Trade Center was delayed for a number of reasons, including that NIST staff who had been working on 7 World Trade Center were assigned full-time from June 2004 to September 2005 to work on the investigation of the collapse of the Twin Towers. In June 2007, Shyam Sunder explained, We are proceeding as quickly as possible while rigorously testing and evaluating a wide range of scenarios to reach the most definitive conclusion possible. The 7 WTC investigation is in some respects just as challenging, if not more so than the study of the towers. However, the current study does benefit greatly from the significant technological advances achieved and lessons learned from our work on the towers.\\n\\nIn November 2008, NIST released its final report on the causes of the collapse of 7 World Trade Center. This followed NIST\\'s August 21, 2008, draft report which included a period for public comments, and was followed in 2012 by a peer-reviewed summary in the Journal of Structural Engineering. In its investigation, NIST utilized ANSYS to model events leading up to collapse initiation and LS-DYNA models to simulate the global response to the initiating events.:\\u200a6–7\\u200a NIST determined that diesel fuel did not play an important role, nor did the structural damage from the collapse of the Twin Towers or the transfer elements (trusses, girders, and cantilever overhangs). The lack of water to fight the fire was an important factor. The fires burned out of control during the afternoon, causing floor beams near column 79 to expand and push a key girder off its seat, triggering the floors to fail around column 79 on Floors 8 to 14. With a loss of lateral support across nine floors, column 79 buckled – pulling the east penthouse and nearby columns down with it. With the buckling of these critical columns, the collapse then progressed east-to-west across the core, ultimately overloading the perimeter support, which buckled between Floors 7 and 17, causing the remaining portion of the building above to fall down as a single unit. The fires, which were fueled by office contents and burned for 7 hours, along with the lack of water, were the key reasons for the collapse.:\\u200a21–22\\u200a At the time, this made the old 7 WTC the only steel skyscraper to have collapsed from fire.When 7 WTC collapsed, debris caused substantial damage and contamination to the Borough of Manhattan Community College\\'s Fiterman Hall building, located adjacent at 30 West Broadway, to the extent that the building was not salvageable. A revised plan called for demolition in 2009 and completion of the new Fiterman Hall in 2012, at a cost of $325 million. The Verizon Building, an art deco building located directly to the west, had extensive damage to its eastern facade from the collapse of 7 World Trade Center, though it was later restored at a cost of US$1.4 billion.\\n\\nFiles relating to numerous federal investigations had been housed in 7 World Trade Center. The Equal Employment Opportunity Commission estimated over 10,000 of its cases were affected. Investigative files in the Secret Service\\'s largest field office were lost, with one Secret Service agent saying, \"All the evidence that we stored at 7 World Trade, in all our cases, went down with the building.\" Copies of emails in connection with the WorldCom scandal that were later requested by the SEC from Salomon Brothers, a subsidiary of Citigroup housed in the building, were also destroyed.The NIST report found no evidence supporting the conspiracy theories that 7 World Trade Center was brought down by controlled demolition. Specifically, the window breakage pattern and blast sounds that would have resulted from the use of explosives were not observed.:\\u200a26–28\\u200a The suggestion that an incendiary material such as thermite was used instead of explosives was considered unlikely by NIST because of the building\\'s structural response to the fire, the nature of the fire, and the unlikelihood that a sufficient amount of thermite could be planted without discovery. Based on its investigation, NIST reiterated several recommendations it had made in its earlier report on the collapse of the Twin Towers.:\\u200a63–73\\u200a It urged immediate action on a further recommendation: that fire resistance should be evaluated under the assumption that sprinklers are unavailable;:\\u200a65–66\\u200a and that the effects of thermal expansion on floor support systems be considered.:\\u200a65,\\u200a69\\u200a  Recognizing that current building codes are drawn to prevent loss of life rather than building collapse, the main point of NIST\\'s recommendations was that buildings should not collapse from fire even if sprinklers are unavailable.:\\u200a63–73\\u200a\\n\\n\\n\\nThe new 7 World Trade Center has 52 stories and is 741 ft (226 m) tall. The building has 42 floors of leasable space, starting at the 11th floor, and a total of 1.7 million sq ft (160,000 m2) of office space. The first ten floors house an electrical substation which provides power to much of Lower Manhattan. The office tower has a narrower footprint at ground level than did its predecessor, so the course of Greenwich Street could be restored to reunite TriBeCa and the Financial District. The original building, on the other hand, had bordered West Broadway on the east, necessitating the destruction of Greenwich Street between Barclay Street and the northern border of the World Trade Center superblock.\\n\\n\\nDavid Childs of Skidmore, Owings and Merrill worked in conjunction with glass artist and designer James Carpenter to create a design that uses ultra-clear, low-iron glass to provide reflectivity and light, with stainless-steel spandrels behind the glass to help reflect sunlight. Stainless steel used in the building façade is molybdenum-containing Type 316, which provides improved resistance to corrosion. To enclose the power substation and improve its aesthetics, the base of the building has a curtain wall with stainless steel louvers that provide ventilation for the machinery. During the day, the curtain wall reflects light, while at night it is illuminated with blue LED lights. The curtain wall around the lobby uses heavily laminated, heat-strengthened glass that meets high standards for blast resistance. At night, a large cube of light above the lobby also emanates blue light, while during the day it provides white light to the lobby, and at dusk, it transitions to violet and back to blue. Inside the main lobby, artist Jenny Holzer created a large light installation with glowing text moving across wide plastic panels. The entire wall, which is 65 ft (20 m) wide and 14 ft (4.3 m) tall, changes color according to the time of day. Holzer worked with Klara Silverstein, the wife of Larry Silverstein, to select poetry for the art installation. The wall is structurally fortified as a security measure.The building is being promoted as the safest skyscraper in the U.S. According to Silverstein Properties, the owner of the building, it \"incorporate[s] a host of life-safety enhancements that will become the prototype for new high-rise construction.\" The building has 2-foot-thick (0.61 m) reinforced-concrete and fireproofed elevator and stairway access shafts. The original building used only drywall to line these shafts. The stairways are wider than in the original building to permit faster egress.7 World Trade Center is equipped with Otis destination elevators. After pressing a destination floor number on a lobby keypad, passengers are grouped and directed to specific elevators that will stop at the selected floor (there are no buttons to press inside the elevators). This system is designed to reduce elevator waiting and travel times. The elevator system is integrated with the lobby turnstile and card reader system that identifies the floor on which a person works as he or she enters and can automatically call the elevator for that floor.Nearly 30 percent of structural steel used in the building consists of recycled steel. Rainwater is collected and used for irrigation of the park and to cool the building. Along with other sustainable design features, the building is designed to allow in plenty of natural light, power is metered to tenants to encourage them to conserve energy, the heating steam is reused to generate some power for the building, and recycled materials are used for insulation and interior materials. WSP Cantor Seinuk served as structural engineer on the project, while Jaros, Baum & Bolles was the MEP engineer.\\n\\n\\n\\nThe construction phase of the new 7 World Trade Center began on May 7, 2002, with the installation of a fence around the construction site. Tishman Construction Corporation of New York began work at the new 7 World Trade Center in 2002, soon after the site was cleared of debris. Restoring the Con Ed electrical substation was an urgent priority to meet power demands of Lower Manhattan. Because 7 World Trade Center is separate from the main 16-acre (6.5 ha) World Trade Center site, Larry Silverstein required approval from only the Port Authority, and rebuilding was able to proceed quickly.Once construction of the power substation was completed in October 2003, work proceeded on building the office tower. An unusual approach was used in constructing the building; erecting the steel frame before adding the concrete core. This approach allowed the construction schedule to be shortened by a few months. Construction was completed in 2006 at a cost of $700 million. Though Silverstein received $861 million from insurance on the old building, he owed more than $400 million on its mortgage. Costs to rebuild were covered by $475 million in Liberty Bonds, which provide tax-exempt financing to help stimulate rebuilding in Lower Manhattan and insurance money that remained after other expenses.A 15,000 sq ft (1,400 m2) triangular park was created between the extended Greenwich Street and West Broadway by David Childs with Ken Smith and his colleague, Annie Weinmayr, of Ken Smith Landscape Architect. The park comprises an open central plaza with a fountain and flanking groves of sweetgum trees and boxwood shrubs. At the center of the fountain, sculptor Jeff Koons created Balloon Flower (Red), whose mirror-polished stainless steel represents a twisted balloon in the shape of a flower.\\n\\n\\n\\n\\nThe building was officially opened at noon on May 23, 2006, with a free concert featuring Suzanne Vega, Citizen Cope, Bill Ware Vibes, Brazilian Girls, Ollabelle, Pharaoh\\'s Daughter, Ronan Tynan (of the Irish Tenors), and special guest Lou Reed. Prior to opening, in March 2006, the new 7 World Trade Center frontage and lobby were used in scenes for the movie Perfect Stranger with Halle Berry and Bruce Willis.After the building opened, several unleased upper floors were used for events such as charity lunches, fashion shows, and black-tie galas. Silverstein Properties allowed space in the new building to be used for these events as a means to draw people to see the building. From September 8 to October 7, 2006, the work of photographer Jonathan Hyman was displayed in \"An American Landscape\", a free exhibit hosted by the World Trade Center Memorial Foundation at 7 World Trade Center. The photographs captured the response of people in New York City and across the United States after the September 11, 2001, attacks. The exhibit took place on the 45th floor while space remained available for lease.\\n\\nBy March 2007, 60 percent of the building had been leased. In September 2006, Moody\\'s signed a 20-year lease to rent 15 floors of 7 World Trade Center. Other tenants that had signed leases in 7 World Trade Center, as of May 2007, included ABN AMRO, Ameriprise Financial Inc., law firm Wilmer Hale, publisher Mansueto Ventures, and the New York Academy of Sciences. Silverstein Properties also has offices and the Silver Suites executive office suites in 7 World Trade Center, along with office space used by the architectural and engineering firms working on 1 World Trade Center, 150 Greenwich Street, 175 Greenwich Street, and 200 Greenwich Street. After AMN AMRO was acquired by the Royal Bank of Scotland, forex services provider FXDD subleased some of the Royal Bank of Scotland\\'s space in 2009.The space occupied by Mansueto Ventures has been designed to use the maximum amount of natural light and has an open floor plan. The space used by the New York Academy of Sciences on the 40th floor, designed by H3 Hardy Collaboration Architecture, works with the parallelogram shape of the building. Keeping with the green design of the building, the NYAS uses recycled materials in many of the office furnishings, has zoned heating and cooling, and motion-detecting lights, which activate automatically when people are present, and adjust according to incoming sunlight.\\n\\n\\nThe building became fully leased in September 2011 after MSCI agreed to occupy 125,000 square feet (11,600 m2) on the top floor. Following this, Silverstein announced in 2012 that he would refinance the building with a $452.8 million Liberty bond issue and a $125 million commercial mortgage-backed security loan. At the time, the building was valued at $940 million, in large part because it was fully occupied. FXDD subleased its space to engineering company Permasteelisa in 2015 and artificial intelligence firm IPsoft in 2016. The building was 94.8 percent occupied by 2017. At the time, roughly three-quarters of the space was occupied by four tenants, including Moody\\'s, the Royal Bank of Scotland, and Wilmer Hale.Wedding planning company Zola and the building\\'s own architecture firm Skidmore, Owings & Merrill both leased space at 7 WTC in early 2019. This was followed in July 2019 by luxury drink brand Moët Hennessy and media company AccuWeather. After publisher Mansueto Ventures and three other firms took space at 7 WTC in April 2022, the building was 97 percent occupied. Shortly afterward, Silverstein Properties refinanced the property with a $458 million loan from Goldman Sachs.\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8c66d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_function(examples):\n",
    "\n",
    "#     text_arrays = [x.split('\\\\n') for x in examples['text']]\n",
    "#     for \n",
    "\n",
    "#     return inputs\n",
    "\n",
    "# dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "edda14c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['title', 'text'],\n",
       "     num_rows: 2622\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['title', 'text'],\n",
       "     num_rows: 292\n",
       " }))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the dataset into training (90%) and testing (10%)\n",
    "d = dataset.train_test_split(test_size=0.1)\n",
    "d[\"train\"], d[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7b1b149f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1739b16a88a54fdc8639c72ad87e56d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5995d92ab044b3adf74afe4e9b610e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def encode_with_truncation(examples):\n",
    "    \"\"\"Mapping function to tokenize the sentences passed with truncation\"\"\"\n",
    "    return bert_tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\",\n",
    "                   max_length=max_length, return_special_tokens_mask=True)\n",
    "\n",
    "def encode_without_truncation(examples):\n",
    "    \"\"\"Mapping function to tokenize the sentences passed without truncation\"\"\"\n",
    "    return bert_tokenizer(examples[\"text\"], return_special_tokens_mask=True)\n",
    "\n",
    "# the encode function will depend on the truncate_longer_samples variable\n",
    "encode = encode_with_truncation if truncate_longer_samples else encode_without_truncation\n",
    "# tokenizing the train dataset\n",
    "train_dataset = d[\"train\"].map(encode, batched=True)\n",
    "# tokenizing the testing dataset\n",
    "test_dataset = d[\"test\"].map(encode, batched=True)\n",
    "if truncate_longer_samples:\n",
    "    # remove other columns and set input_ids and attention_mask as PyTorch tensors\n",
    "    train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "    test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "else:\n",
    "    # remove other columns, and remain them as Python lists\n",
    "    test_dataset.set_format(columns=[\"input_ids\", \"attention_mask\", \"special_tokens_mask\"])\n",
    "    train_dataset.set_format(columns=[\"input_ids\", \"attention_mask\", \"special_tokens_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "53ea0162",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated: return_special_tokens_mask (2725515266.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [152], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    tokenized_inputs = bert_tokenizer(examples[\"text\"], return_special_tokens_mask=True,\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m keyword argument repeated: return_special_tokens_mask\n"
     ]
    }
   ],
   "source": [
    "# def group_texts(examples):\n",
    "#     tokenized_inputs = bert_tokenizer(examples[\"text\"], return_special_tokens_mask=True, \n",
    "#                                       padding=\"max_length\",truncation=True, max_length=max_length,\n",
    "#                                       return_special_tokens_mask=True)\n",
    "#     return tokenized_inputs\n",
    "\n",
    "# # preprocess dataset\n",
    "# tokenized_datasets = d[\"train\"].map(group_texts, batched=True, remove_columns=[\"text\"], num_proc=1)\n",
    "# tokenized_datasets.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d06f40a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'text', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "    num_rows: 292\n",
       "})"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a3729e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f0dd6042b940fbbd053a0a548bcdca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grouping texts in chunks of 512:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654e418ceb6d428f94e9d7e7a843ae0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "# Main data processing function that will concatenate all texts from our dataset and generate chunks of\n",
    "# max_seq_length.\n",
    "# grabbed from: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= max_length:\n",
    "        total_length = (total_length // max_length) * max_length\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + max_length] for i in range(0, total_length, max_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# Note that with `batched=True`, this map processes 1,000 texts together, so group_texts throws away a\n",
    "# remainder for each of those groups of 1,000 texts. You can adjust that batch_size here but a higher value\n",
    "# might be slower to preprocess.\n",
    "#\n",
    "# To speed up this part, we use multiprocessing. See the documentation of the map method for more information:\n",
    "# https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map\n",
    "if not truncate_longer_samples:\n",
    "    train_dataset = train_dataset.map(group_texts, batched=True,\n",
    "                                    desc=f\"Grouping texts in chunks of {max_length}\")\n",
    "    test_dataset = test_dataset.map(group_texts, batched=True,\n",
    "                                  desc=f\"Grouping texts in chunks of {max_length}\")\n",
    "    # convert them from lists to torch tensors\n",
    "    train_dataset.set_format(\"torch\")\n",
    "    test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5c8a9815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32109, 3703)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2aa02e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_tokenized = bert_tokenizer(\n",
    "\n",
    "#     all_inst,\n",
    "\n",
    "#     padding=True,\n",
    "\n",
    "#     truncation=True,\n",
    "\n",
    "#     max_length=512,\n",
    "\n",
    "#     return_tensors=\"pt\",\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "12da2e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the dataset into training (90%) and testing (10%)\n",
    "# split_num = int(0.9*len(all_tokenized['input_ids']))\n",
    "# d = {}\n",
    "# d[\"train\"] = all_tokenized[:split_num]\n",
    "# d[\"test\"] = all_tokenized[split_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "52c56b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model with the config\n",
    "model_config = BertConfig(vocab_size=vocab_size, max_position_embeddings=max_length)\n",
    "model = BertForMaskedLM(config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "96c670ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data collator, randomly masking 20% (default is 15%) of the tokens for the Masked Language\n",
    "# Modeling (MLM) task\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=bert_tokenizer, mlm=True, mlm_probability=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "30d2ee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 1000\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path,          # output directory to where save model checkpoint\n",
    "    evaluation_strategy=\"steps\",    # evaluate each `logging_steps` steps\n",
    "    overwrite_output_dir=True,      \n",
    "    num_train_epochs=10,            # number of training epochs, feel free to tweak\n",
    "    per_device_train_batch_size=10, # the training batch size, put it as high as your GPU memory fits\n",
    "    gradient_accumulation_steps=8,  # accumulating the gradients before updating the weights\n",
    "    per_device_eval_batch_size=64,  # evaluation batch size\n",
    "    logging_steps=1000,             # evaluate, log and save model checkpoints every 1000 step\n",
    "    save_steps=1000,\n",
    "    # load_best_model_at_end=True,  # whether to load the best model (in terms of loss) at the end of training\n",
    "    # save_total_limit=3,           # whether you don't have much space so you let only 3 model weights saved in the disk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e9e206b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the trainer and pass everything to it\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1c076d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: special_tokens_mask. If special_tokens_mask are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 32109\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 80\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 4010\n",
      "  Number of trainable parameters = 109514298\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='4010' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  17/4010 58:40 < 260:17:59, 0.00 it/s, Epoch 0.04/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [166], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\transformers\\trainer.py:1501\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1498\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1500\u001b[0m )\n\u001b[1;32m-> 1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\transformers\\trainer.py:1749\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1747\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1749\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1752\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1755\u001b[0m ):\n\u001b[0;32m   1756\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\transformers\\trainer.py:2508\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2507\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2508\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2511\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\transformers\\trainer.py:2540\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2539\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2540\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   2541\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2542\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1347\u001b[0m, in \u001b[0;36mBertForMaskedLM.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;124;03m    Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;124;03m    config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\u001b[39;00m\n\u001b[0;32m   1342\u001b[0m \u001b[38;5;124;03m    loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1345\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1347\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1361\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1362\u001b[0m prediction_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls(sequence_output)\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1014\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1005\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1007\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1008\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1009\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1027\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:603\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    594\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    595\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    596\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    601\u001b[0m     )\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 603\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:489\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    479\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:419\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    411\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    418\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 419\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    429\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:347\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    344\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    349\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15235351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model checkpoint\n",
    "model = BertForMaskedLM.from_pretrained(os.path.join(model_path, \"checkpoint-10000\"))\n",
    "# load the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ee1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93fd75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1593499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f6f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9f5b10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the dataset into training (90%) and testing (10%)\n",
    "# d = dataset.train_test_split(test_size=0.1)\n",
    "# d[\"train\"], d[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "34394ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in d[\"train\"][\"text\"][:3]:\n",
    "#   print(t)\n",
    "#   print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25f7fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize the WordPiece tokenizer\n",
    "# tokenizer = BertWordPieceTokenizer()\n",
    "# # train the tokenizer\n",
    "# tokenizer.train(files=files, vocab_size=vocab_size, special_tokens=special_tokens)\n",
    "# # enable truncation up to the maximum 512 tokens\n",
    "# tokenizer.enable_truncation(max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fd78a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"pretrained-bert\"\n",
    "# # make the directory if not already there\n",
    "# if not os.path.isdir(model_path):\n",
    "#     os.mkdir(model_path)\n",
    "# # save the tokenizer  \n",
    "# tokenizer.save_model(model_path)\n",
    "# # dumping some of the tokenizer config to config file, \n",
    "# # including special tokens, whether to lower case and the maximum sequence length\n",
    "# with open(os.path.join(model_path, \"config.json\"), \"w\") as f:\n",
    "#     tokenizer_cfg = {\n",
    "#       \"do_lower_case\": True,\n",
    "#       \"unk_token\": \"[UNK]\",\n",
    "#       \"sep_token\": \"[SEP]\",\n",
    "#       \"pad_token\": \"[PAD]\",\n",
    "#       \"cls_token\": \"[CLS]\",\n",
    "#       \"mask_token\": \"[MASK]\",\n",
    "#       \"model_max_length\": max_length,\n",
    "#       \"max_len\": max_length,\n",
    "#     }\n",
    "#     json.dump(tokenizer_cfg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65143d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file pretrained-bert\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"pretrained-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"cls_token\": \"[CLS]\",\n",
      "  \"do_lower_case\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_token\": \"[MASK]\",\n",
      "  \"max_len\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_max_length\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token\": \"[PAD]\",\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token\": \"[SEP]\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"unk_token\": \"[UNK]\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file pretrained-bert\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"pretrained-bert\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"cls_token\": \"[CLS]\",\n",
      "  \"do_lower_case\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_token\": \"[MASK]\",\n",
      "  \"max_len\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_max_length\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token\": \"[PAD]\",\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token\": \"[SEP]\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"unk_token\": \"[UNK]\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # when the tokenizer is trained and configured, load it as BertTokenizerFast\n",
    "# tokenizer = BertTokenizerFast.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc48e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22b491679a74872baa483dccba65c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/638 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def encode_with_truncation(examples):\n",
    "#     \"\"\"Mapping function to tokenize the sentences passed with truncation\"\"\"\n",
    "#     return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\",\n",
    "#                    max_length=max_length, return_special_tokens_mask=True)\n",
    "\n",
    "# def encode_without_truncation(examples):\n",
    "#     \"\"\"Mapping function to tokenize the sentences passed without truncation\"\"\"\n",
    "#     return tokenizer(examples[\"text\"], return_special_tokens_mask=True)\n",
    "\n",
    "# # the encode function will depend on the truncate_longer_samples variable\n",
    "# encode = encode_with_truncation if truncate_longer_samples else encode_without_truncation\n",
    "# # tokenizing the train dataset\n",
    "# train_dataset = d[\"train\"].map(encode, batched=True)\n",
    "# # tokenizing the testing dataset\n",
    "# test_dataset = d[\"test\"].map(encode, batched=True)\n",
    "# if truncate_longer_samples:\n",
    "#     # remove other columns and set input_ids and attention_mask as PyTorch tensors\n",
    "#     train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "#     test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "# else:\n",
    "#     # remove other columns, and remain them as Python lists\n",
    "#     test_dataset.set_format(columns=[\"input_ids\", \"attention_mask\", \"special_tokens_mask\"])\n",
    "#     train_dataset.set_format(columns=[\"input_ids\", \"attention_mask\", \"special_tokens_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f3dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from the run_mlm.py script from the huggingface transformers examples\n",
    "\n",
    "# from itertools import chain\n",
    "# # Main data processing function that will concatenate all texts from our dataset and generate chunks of\n",
    "# # max_seq_length.\n",
    "# # grabbed from: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
    "# def group_texts(examples):\n",
    "#     # Concatenate all texts.\n",
    "#     concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "#     total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "#     # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "#     # customize this part to your needs.\n",
    "#     if total_length >= max_length:\n",
    "#         total_length = (total_length // max_length) * max_length\n",
    "#     # Split by chunks of max_len.\n",
    "#     result = {\n",
    "#         k: [t[i : i + max_length] for i in range(0, total_length, max_length)]\n",
    "#         for k, t in concatenated_examples.items()\n",
    "#     }\n",
    "#     return result\n",
    "\n",
    "# # Note that with `batched=True`, this map processes 1,000 texts together, so group_texts throws away a\n",
    "# # remainder for each of those groups of 1,000 texts. You can adjust that batch_size here but a higher value\n",
    "# # might be slower to preprocess.\n",
    "# #\n",
    "# # To speed up this part, we use multiprocessing. See the documentation of the map method for more information:\n",
    "# # https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map\n",
    "# if not truncate_longer_samples:\n",
    "#     train_dataset = train_dataset.map(group_texts, batched=True,\n",
    "#                                     desc=f\"Grouping texts in chunks of {max_length}\")\n",
    "#     test_dataset = test_dataset.map(group_texts, batched=True,\n",
    "#                                   desc=f\"Grouping texts in chunks of {max_length}\")\n",
    "#     # convert them from lists to torch tensors\n",
    "#     train_dataset.set_format(\"torch\")\n",
    "#     test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e269307d",
   "metadata": {},
   "source": [
    "## Problem 2.2 (2 points) - Hyperparameters\n",
    "Experiment with changing model 3-4 of the model hyperparameters (e.g. sequence length, number of attention heads, hidden dimension, number of layers, etc). How do these change the training behaviour and loss of your model and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd455102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3225de77",
   "metadata": {},
   "source": [
    "## Problem 2.3 (4 points) - BERT vs RoBERTa \n",
    "Identifiy the key similarities and differences between the BERT and RoBERTa language models and discuss how these contribute to RoBERTa being a stronger language model\n",
    "\n",
    "* [BERT](https://aclanthology.org/N19-1423.pdf)\n",
    "* [RoBERTa](https://arxiv.org/abs/1907.11692) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b62a84",
   "metadata": {},
   "source": [
    "The preapering for masking is different between those two models. In BERT model masking is performed only once during the data preparation and RoBERTa is masking during the training proce. We can have multiple verions of masking sentence since it's not prepared before. That's why RoBERTa is more robust, it's not bounted by the static masks like BERT. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbea40d",
   "metadata": {},
   "source": [
    "# Problem 3 - Sequence-to-sequence-language models (10 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7421423a",
   "metadata": {},
   "source": [
    "## Problem 3.1 (4 points) - seq2seq LM training objective\n",
    "Compare the pre-training objectives listed in the [BART](https://aclanthology.org/2020.acl-main.703.pdf) paper and give examples of model inputs and outputs. With these pre-training objectives, compare their effects on downstream NLP tasks. \n",
    "\n",
    "Note: coding is not required for this question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9abfa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebab868b",
   "metadata": {},
   "source": [
    "## Problem 3.2 (6 points) - Infilling Language Model\n",
    "Using the provided data, train a language model with the [BART](https://aclanthology.org/2020.acl-main.703.pdf) **text infilling** objective (other types of pre-training objectives are not reuqired). Select appropriate model size and hyperparameters. \n",
    "\n",
    "* Make the training data yourself\n",
    "\n",
    "* Print a sample of training instances (both the model inputs and expected outputs)\n",
    "\n",
    "* Plot the loss regularly (e.g. after an epoch or fixed number of training steps). Report the loss for both the training data and validation data\n",
    "\n",
    "* Use the `transformers` library implementation of a suitable tokenizer and model for language modelling with BART. But do not use a pre-trained language model (i.e. start with a randomly initialized model).  \n",
    "\n",
    "* It is only required to show convergence of your model for a few epochs\n",
    "\n",
    "Hint: you can sample sequence lengths from the Poisson distribution using the random library in [Numpy](https://numpy.org/doc/stable/reference/random/generated/numpy.random.poisson.html).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b20e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
